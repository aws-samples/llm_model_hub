#!/bin/bash

# Set the directory to check
base_dir="/opt/ml/model/"
file_dir="/tmp/model_file/"
export SAGEMAKER_BIND_TO_PORT=${SAGEMAKER_BIND_TO_PORT:-8080}

# Check if the directory exists
if [ ! -d "$base_dir" ]; then
    echo "Error: $base_dir directory does not exist"
    exit 1
fi

if [ -n "${VLLM_USE_MODELSCOPE}" ]; then
    export VLLM_USE_MODELSCOPE=True
fi

if [ -n "${VLLM_ALLOW_LONG_MAX_MODEL_LEN}" ]; then
    vllm_allow_long_max_model_len=$(expr $VLLM_ALLOW_LONG_MAX_MODEL_LEN + 0)
    export VLLM_ALLOW_LONG_MAX_MODEL_LEN=$vllm_allow_long_max_model_len
fi

# Find the first subdirectory in the base directory
model_dir=$(find "$base_dir" -mindepth 1 -maxdepth 1 -type d -print -quit)

# Get env variable LIMIT_MM_PER_RPOMPT, if none then set a default value image=20,video=2
LIMIT_MM_PER_PROMPT=${LIMIT_MM_PER_PROMPT:-"image=5,video=2"}


# Check if a subdirectory was found
if [ -z "$model_dir" ]; then
    echo "No subdirectory found"
    exit 0
else
    # Set the model_path
    model_path="$model_dir"
    max_model_len=$(expr $MAX_MODEL_LEN + 0)
    max_num_seqs=$(expr $MAX_NUM_SEQS + 0)
    tensor_parallel_size=$(expr $TENSOR_PARALLEL_SIZE + 0)
    dtype="$DTYPE"
    echo "Found model directory" $model_dir
    if [ -f "$model_dir/.env" ]; then
        source $model_dir/.env
    fi

    if [ -f "$model_dir/start.sh" ]; then
        # If start.sh file exists, use its content as model_id
        cd $(dirname "$model_dir/start.sh")
        echo "Running $model_dir/start.sh"
        cp $model_dir/start.sh /app/
        chmod +x /app/start.sh
        /app/start.sh
    else
        # Get model_id from environment variable
        model_id=$HF_MODEL_ID
        s3_model_path=$S3_MODEL_PATH
        #检查是否是s3 url
        if [[ $s3_model_path == s3://* ]]; then
            #检查是否以/结尾，如果是则去掉
            if [[ $s3_model_path == */ ]]; then
                s3_model_path=${s3_model_path%/}
                s3_model_path="${s3_model_path}/*"
            else
                s3_model_path="${s3_model_path}/*"
            fi
            #mv s5cmd to app foler
            cp $model_dir/s5cmd /app/s5cmd
            chmod +x /app/s5cmd
            # If model_id is an S3 address, sync files to base_dir

            echo "Syncing files from S3: $s3_model_path"
            echo "using: $model_id"
            s5cmd sync $s3_model_path $file_dir
            # Set model_id to base_dir for local loading
            echo "Using model: $file_dir"

            command="python3 -m vllm.entrypoints.openai.api_server --port $SAGEMAKER_BIND_TO_PORT --download-dir $file_dir --trust-remote-code --model $file_dir --max-model-len $max_model_len --tensor-parallel-size $tensor_parallel_size --dtype $dtype --max-num-seqs $max_num_seqs --limit-mm-per-prompt $LIMIT_MM_PER_PROMPT"
            
            if [ "${ENABLE_PREFIX_CACHING}" = "1" ]; then
                command="$command --enable-prefix-caching"
            fi

            if [ "${ENFORCE_EAGER}" = "1" ]; then
                command="$command --enforce-eager"
            fi
            
            eval $command
 

        else
            # If model_id file exists, use its content as model_id
            # model_id=$(cat "$model_dir/model_id")
            echo "using: $model_id"
            command="python3 -m vllm.entrypoints.openai.api_server --port $SAGEMAKER_BIND_TO_PORT --trust-remote-code --model $model_id --max-model-len $max_model_len --tensor-parallel-size $tensor_parallel_size --dtype $dtype --max-num-seqs $max_num_seqs --limit-mm-per-prompt $LIMIT_MM_PER_PROMPT"
            
            if [ "${ENABLE_PREFIX_CACHING}" = "1" ]; then
                command="$command --enable-prefix-caching"
            fi

            if [ "${ENFORCE_EAGER}" = "1" ]; then
                command="$command --enforce-eager"
            fi
            
            eval $command
        fi


    fi
fi
