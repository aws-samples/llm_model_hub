{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/workspace/llm_model_hub/miniconda3/envs/py311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environ({'USER': 'ubuntu', 'SSH_CLIENT': '111.198.223.106 58543 22', 'XDG_SESSION_TYPE': 'tty', 'SHLVL': '2', 'HOME': '/home/ubuntu', 'SSL_CERT_FILE': '/usr/lib/ssl/cert.pem', 'DBUS_SESSION_BUS_ADDRESS': 'unix:path=/run/user/1000/bus', 'LOGNAME': 'ubuntu', '_': '/home/ubuntu/workspace/llm_model_hub/miniconda3/envs/py311/bin/python', 'XDG_SESSION_CLASS': 'user', 'VSCODE_CLI_REQUIRE_TOKEN': '08749abe-85df-47fe-a1e0-ea3c34d7468b', 'XDG_SESSION_ID': '2809', 'PATH': '/home/ubuntu/workspace/llm_model_hub/miniconda3/envs/py311/bin:/home/ubuntu/workspace/llm_model_hub/miniconda3/condabin:/home/ubuntu/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/bin/remote-cli:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin', 'VSCODE_AGENT_FOLDER': '/home/ubuntu/.vscode-server', 'XDG_RUNTIME_DIR': '/run/user/1000', 'SSL_CERT_DIR': '/usr/lib/ssl/certs', 'LANG': 'C.UTF-8', 'SHELL': '/bin/bash', 'PWD': '/home/ubuntu', 'SSH_CONNECTION': '111.198.223.106 58543 172.31.38.107 22', 'XDG_DATA_DIRS': '/usr/local/share:/usr/share:/var/lib/snapd/desktop', 'VSCODE_CWD': '/home/ubuntu', 'VSCODE_NLS_CONFIG': '{\"userLocale\":\"en\",\"osLocale\":\"en\",\"resolvedLanguage\":\"en\",\"defaultMessagesFile\":\"/home/ubuntu/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/out/nls.messages.json\",\"locale\":\"en\",\"availableLanguages\":{}}', 'VSCODE_HANDLES_SIGPIPE': 'true', 'LS_COLORS': '', 'LESSCLOSE': '/usr/bin/lesspipe %s %s', 'LESSOPEN': '| /usr/bin/lesspipe %s', 'VSCODE_AMD_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'BROWSER': '/home/ubuntu/.vscode-server/cli/servers/Stable-fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/server/bin/helpers/browser.sh', 'ELECTRON_RUN_AS_NODE': '1', 'VSCODE_IPC_HOOK_CLI': '/run/user/1000/vscode-ipc-b7e5af20-b457-446c-8f67-642a9f2e1fd9.sock', 'PYTHONUNBUFFERED': '1', 'CONDA_EXE': '/home/ubuntu/workspace/llm_model_hub/miniconda3/bin/conda', '_CE_M': '', 'CONDA_ROOT': '/home/ubuntu/workspace/llm_model_hub/miniconda3', 'CONDA_PREFIX': '/home/ubuntu/workspace/llm_model_hub/miniconda3/envs/py311', 'CONDA_PROMPT_MODIFIER': '(py311) ', '_CE_CONDA': '', 'PYTHONIOENCODING': 'utf-8', 'CONDA_SHLVL': '2', 'CONDA_PYTHON_EXE': '/home/ubuntu/workspace/llm_model_hub/miniconda3/bin/python', 'REACT_APP_API_KEY': 'f1e16e1e6214d7c44d078b1f0607b2388f29d729', 'CONDA_DEFAULT_ENV': 'py311', 'CONDA_PREFIX_1': '/home/ubuntu/workspace/llm_model_hub/miniconda3', 'REACT_APP_API_ENDPOINT': 'http://ec2-3-93-192-33.compute-1.amazonaws.com:443/v1', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'PYTHON_FROZEN_MODULES': 'on', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'FORCE_COLOR': '1', 'CLICOLOR_FORCE': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline', 'AK': '', 'SK': '', 'profile': '', 'region': 'us-east-1', 'role': 'arn:aws:iam::434444145045:role/sagemaker-modelhub', 'db_host': '127.0.0.1', 'db_name': 'llm', 'db_user': 'llmdata', 'db_password': 'llmdata', 'api_keys': 'f1e16e1e6214d7c44d078b1f0607b2388f29d729', 'HUGGING_FACE_HUB_TOKEN': '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', 'WANDB_API_KEY': 'e83b1e4fa169b00634e57a8eea9fe60c4a0ffb31', 'vllm_image': '434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/vllm:v0.5.5', 'model_artifact': 's3://sagemaker-us-east-1-434444145045/sagemaker_endpoint/vllm//model.tar.gz'})\n",
      "sagemaker role:arn:aws:iam::434444145045:role/sagemaker-modelhub\n",
      "default_bucket:sagemaker-us-east-1-434444145045\n",
      "[Errno 2] No such file or directory: './utils/supported_models.pkl'\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris, Model\n",
    "import sagemaker\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.config import boto_sess,role,sagemaker_session,DEFAULT_REGION,SUPPORTED_MODELS_FILE,DEFAULT_TEMPLATE_FILE,default_bucket,VLLM_IMAGE,MODEL_ARTIFACT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 0.28.0. Ignoring framework/algorithm version: 0.29.0.\n"
     ]
    }
   ],
   "source": [
    "lmi_image_uri = image_uris.retrieve(framework=\"djl-lmi\", version=\"0.29.0\", region=DEFAULT_REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_path = \"s3://sagemaker-us-east-1-434444145045/Meta-Llama-3-1-8B-Instruct/33dba50f38f34e788ce0abea2ba31743/finetuned_model_merged/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!"
     ]
    }
   ],
   "source": [
    "endpoint_name = sagemaker.utils.name_from_base('llama3.1-8b-mod').replace('.','-').replace('_','-')\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "env={\n",
    "    \"HF_MODEL_ID\": model_path,\n",
    "    \"OPTION_ROLLING_BATCH\":  \"lmi-dist\",\n",
    "    \"TENSOR_PARALLEL_DEGREE\": \"max\",\n",
    "    \"OPTION_TRUST_REMOTE_CODE\": \"true\",\n",
    "     \"HUGGING_FACE_HUB_TOKEN\":os.environ.get('HUGGING_FACE_HUB_TOKEN'),\n",
    "}\n",
    "\n",
    "# Create the SageMaker Model object. In this example we let LMI configure the deployment settings based on the model architecture  \n",
    "model = Model(\n",
    "        image_uri=lmi_image_uri,\n",
    "        role=role,\n",
    "        name=endpoint_name,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        env=env,\n",
    ")\n",
    "\n",
    "model.deploy(\n",
    "    instance_type= instance_type,\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=endpoint_name,\n",
    "    wait=True,\n",
    "    accept_eula=True,\n",
    "    container_startup_health_check_timeout=900\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3,json\n",
    "runtime = boto3.client('runtime.sagemaker',region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two main characters of the movie Titanic are:\n",
      "\n",
      "1. **Jack Dawson** (played by Leonardo DiCaprio): A poor artist who wins his ticket to board the ship in a poker game. He is a free spirit who falls in love with Rose.\n",
      "2. **Rose DeWitt Bukater** (played by Kate Winslet): A high-society woman engaged to marry a wealthy man, Cal Hockley. She falls in love with Jack on the ship.\n",
      "\n",
      "However, if you're asking about the main character, I'd say it's **Rose DeWitt Bukater**. The movie starts with an elderly Rose telling the story of her time on the Titanic to her granddaughter, and the story revolves around her experiences and emotions.\n",
      "\n",
      "But, if you consider the character that drives the plot forward, it's **Jack Dawson**. His character represents the free-spirited and romantic side of the story, and his relationship with Rose is the central theme of the movie.\n",
      "\n",
      "It's worth noting that James Cameron, the director of the movie, has stated that he considers Jack and Rose to be co-main characters, rather than a single main character.\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = 'Meta-Llama-3-1-8B-Instruct-2024-09-04-10-26-26-004'\n",
    "payload = {\n",
    "    # \"model\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "    \"model\":\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hello, who is the main charater of movie Titanic\"\n",
    "    }\n",
    "    ],\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
