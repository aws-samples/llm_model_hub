{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SageMaker Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the container\n",
    "\n",
    "demo codes are in `app/`\n",
    "build and push the docker with following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!bash build_and_push_sglang.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy on SageMaker\n",
    "\n",
    "define the model and deploy on SageMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Init SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install boto3 sagemaker transformers\n",
    "import re\n",
    "import json\n",
    "import os,dotenv\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "print(os.environ)\n",
    "\n",
    "boto_sess = boto3.Session(\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "sess = sagemaker.session.Session(boto_session=boto_sess)\n",
    "# role = sagemaker.get_execution_role()\n",
    "role = os.environ.get('role')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Prepare model file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: deploy vllm by model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar czvf model.tar.gz model_tar/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s3_code_prefix = f\"sagemaker_endpoint/sglang/\"\n",
    "bucket = sess.default_bucket() \n",
    "code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONTAINER='434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/vllm:v0.7.2'\n",
    "\n",
    "env={\n",
    "    \"HF_MODEL_ID\": model_name,\n",
    "    \"DTYPE\": dtype,\n",
    "    \"LIMIT_MM_PER_PROMPT\":extra_params.get('limit_mm_per_prompt',''),\n",
    "    \"S3_MODEL_PATH\":model_path,\n",
    "    \"VLLM_ALLOW_LONG_MAX_MODEL_LEN\":\"1\",\n",
    "    \"HF_TOKEN\":os.environ.get('HUGGING_FACE_HUB_TOKEN'),\n",
    "    \"MAX_MODEL_LEN\":extra_params.get('max_model_len', \"12288\"), \n",
    "    \"ENABLE_PREFIX_CACHING\": \"1\" if extra_params.get('enable_prefix_caching') else \"0\",\n",
    "    \"TENSOR_PARALLEL_SIZE\": extra_params.get('tensor_parallel_size',str(get_auto_tensor_parallel_size(instance_type))),\n",
    "    \"MAX_NUM_SEQS\": extra_params.get('max_num_seqs','256'),\n",
    "    \"ENFORCE_EAGER\": \"1\" if extra_params.get('enforce_eager') else \"0\",\n",
    "\n",
    "        }\n",
    "\n",
    "model = Model(\n",
    "    name=sagemaker.utils.name_from_base(\"sagemaker-vllm\")+\"_model\",\n",
    "    model_data=code_artifact,\n",
    "    image_uri=CONTAINER,\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    env=env,\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 部署模型到endpoint\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"sagemaker-vllm\")+\"_endpoint\"\n",
    "print(f\"endpoint_name: {endpoint_name}\")\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGLANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.enums import EndpointType\n",
    "from sagemaker.compute_resource_requirements.resource_requirements import ResourceRequirements\n",
    "from sagemaker import Predictor\n",
    "from sagemaker import Model\n",
    "\n",
    "\n",
    "CONTAINER='434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/sglang:v0.4.3.post2-cu124'\n",
    "model_path = \"s3://sagemaker-us-east-1-434444145045/Qwen2-5-3B-Instruct/032650faedac452e86f95f3f3b004342/finetuned_model/\"\n",
    "# model_id = 'Qwen/Qwen2-1.5B-Instruct'\n",
    "env={\n",
    "    # \"HF_MODEL_ID\": model_id,\n",
    "    \"S3_MODEL_PATH\":model_path,\n",
    "}\n",
    "\n",
    "model_name = sagemaker.utils.name_from_base(\"sagemaker-sglang\")+\"-model\"\n",
    "\n",
    "model = Model(\n",
    "    name=model_name,\n",
    "    model_data=code_artifact,\n",
    "    image_uri=CONTAINER,\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    env=env,\n",
    "    predictor_cls = Predictor,\n",
    ")\n",
    "\n",
    "\n",
    "# 部署模型到endpoint\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"sagemaker-sglang\")+\"-endpoint\"\n",
    "print(f\"endpoint_name: {endpoint_name}\")\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',\n",
    "    endpoint_name=endpoint_name,\n",
    "    model_name=model_name, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test\n",
    "\n",
    "you can invoke your model with SageMaker SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Message api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime = boto3.client('runtime.sagemaker',region_name='us-east-1')\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"who are you\"\n",
    "    }\n",
    "    ],\n",
    "    \"model\":\"qwen\",\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 Message api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Write a quick sort in python\"\n",
    "    }\n",
    "    ],\n",
    "    \"model\":\"custome\",\n",
    "    \"max_tokens\": 4096,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.span()[1]\n",
    "            print(data[\"choices\"][0][\"delta\"][\"content\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
