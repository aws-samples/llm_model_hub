{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SageMaker Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the container\n",
    "\n",
    "demo codes are in `app/`\n",
    "build and push the docker with following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!bash build_and_push_sglang.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy on SageMaker\n",
    "\n",
    "define the model and deploy on SageMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Init SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install boto3 sagemaker transformers\n",
    "import re\n",
    "import json\n",
    "import os,dotenv\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "print(os.environ)\n",
    "\n",
    "boto_sess = boto3.Session(\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "sess = sagemaker.session.Session(boto_session=boto_sess)\n",
    "# role = sagemaker.get_execution_role()\n",
    "role = os.environ.get('role')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Prepare model file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: deploy vllm by model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar czvf model.tar.gz model_tar/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s3_code_prefix = f\"sagemaker_endpoint/sglang/\"\n",
    "bucket = sess.default_bucket() \n",
    "code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import get_execution_role\n",
    "import time\n",
    "\n",
    "# 初始化\n",
    "# role = get_execution_role()  # 或指定具体 ARN\n",
    "sm_client = boto3.client('sagemaker')\n",
    "logs_client = boto3.client('logs')\n",
    "\n",
    "# 配置\n",
    "endpoint_name = 'qwen-vl-endpoint-test'\n",
    "image_uri = \"434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/vllm:v0.12.0\"\n",
    "\n",
    "print(f\"Using role: {role}\")\n",
    "print(f\"Image URI: {image_uri}\")\n",
    "\n",
    "try:\n",
    "    # 创建模型\n",
    "    model = Model(\n",
    "        image_uri=image_uri,\n",
    "        role=role,\n",
    "        env={\n",
    "            'HF_MODEL_ID': 'Qwen/Qwen3-VL-2B-Thinking',\n",
    "            'MAX_MODEL_LEN': '4096',\n",
    "            'MAX_NUM_SEQS': '256',\n",
    "            'TENSOR_PARALLEL_SIZE': '1',\n",
    "            'ENABLE_PREFIX_CACHING': '1',\n",
    "            'VLLM_ALLOW_LONG_MAX_MODEL_LEN': '1',\n",
    "            'DTYPE': 'auto',\n",
    "            # 添加调试环境变量\n",
    "            'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',  # INFO\n",
    "            'SAGEMAKER_REGION': 'us-east-1'\n",
    "        },\n",
    "        name=f'qwen-vl-model-{int(time.time())}'\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Model object created\")\n",
    "    \n",
    "    # 部署\n",
    "    print(\"Starting deployment...\")\n",
    "    predictor = model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type='ml.g5.2xlarge',\n",
    "        endpoint_name=endpoint_name,\n",
    "        container_startup_health_check_timeout=900,\n",
    "        wait=False  # 不等待，手动检查\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Deployment initiated for endpoint: {endpoint_name}\")\n",
    "    \n",
    "    # 监控部署状态\n",
    "    print(\"\\nMonitoring deployment status...\")\n",
    "    while True:\n",
    "        response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        status = response['EndpointStatus']\n",
    "        print(f\"Status: {status}\")\n",
    "        \n",
    "        if status == 'InService':\n",
    "            print(\"✅ Endpoint is in service!\")\n",
    "            break\n",
    "        elif status == 'Failed':\n",
    "            print(f\"❌ Deployment failed!\")\n",
    "            print(f\"Failure reason: {response.get('FailureReason', 'Unknown')}\")\n",
    "            break\n",
    "        \n",
    "        time.sleep(30)\n",
    "    \n",
    "    # 检查日志\n",
    "    print(\"\\nChecking CloudWatch logs...\")\n",
    "    log_group = f'/aws/sagemaker/Endpoints/{endpoint_name}'\n",
    "    try:\n",
    "        streams = logs_client.describe_log_streams(\n",
    "            logGroupName=log_group,\n",
    "            orderBy='LastEventTime',\n",
    "            descending=True,\n",
    "            limit=5\n",
    "        )\n",
    "        print(f\"Found {len(streams['logStreams'])} log streams\")\n",
    "        \n",
    "        for stream in streams['logStreams']:\n",
    "            print(f\"\\n--- Log Stream: {stream['logStreamName']} ---\")\n",
    "            events = logs_client.get_log_events(\n",
    "                logGroupName=log_group,\n",
    "                logStreamName=stream['logStreamName'],\n",
    "                limit=50\n",
    "            )\n",
    "            for event in events['events']:\n",
    "                print(event['message'])\n",
    "                \n",
    "    except logs_client.exceptions.ResourceNotFoundException:\n",
    "        print(\"⚠️  No CloudWatch logs found yet\")\n",
    "        print(\"This usually means the container failed to start\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during deployment: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONTAINER='434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/vllm:v0.12.0'\n",
    "model_name=\"Qwen/Qwen3-VL-2B-Thinking\"\n",
    "env={\n",
    "    \"HF_MODEL_ID\": model_name,\n",
    "    \"DTYPE\": \"auto\",\n",
    "    \"VLLM_ALLOW_LONG_MAX_MODEL_LEN\":\"1\",\n",
    "    \"MAX_MODEL_LEN\":\"12288\", \n",
    "    \"ENABLE_PREFIX_CACHING\": \"1\" ,\n",
    "    \"TENSOR_PARALLEL_SIZE\": \"1\",\n",
    "    \"MAX_NUM_SEQS\": '256',\n",
    "    \"ENFORCE_EAGER\":  \"0\",\n",
    "    }\n",
    "\n",
    "model = Model(\n",
    "    name=sagemaker.utils.name_from_base(\"sagemaker-vllm\")+\"-model\",\n",
    "    model_data=code_artifact,\n",
    "    image_uri=CONTAINER,\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    env=env,\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 部署模型到endpoint\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"sagemaker-vllm\")+\"-endpoint\"\n",
    "print(f\"endpoint_name: {endpoint_name}\")\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGLANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.enums import EndpointType\n",
    "from sagemaker.compute_resource_requirements.resource_requirements import ResourceRequirements\n",
    "from sagemaker import Predictor\n",
    "from sagemaker import Model\n",
    "\n",
    "\n",
    "CONTAINER='434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/sglang:v0.5.6.post1-cu129-amd64'\n",
    "model_path = \"s3://sagemaker-us-east-1-434444145045/Qwen2-5-3B-Instruct/032650faedac452e86f95f3f3b004342/finetuned_model/\"\n",
    "# model_id = 'Qwen/Qwen2-1.5B-Instruct'\n",
    "env={\n",
    "    # \"HF_MODEL_ID\": model_id,\n",
    "    \"S3_MODEL_PATH\":model_path,\n",
    "}\n",
    "\n",
    "model_name = sagemaker.utils.name_from_base(\"sagemaker-sglang\")+\"-model\"\n",
    "\n",
    "model = Model(\n",
    "    name=model_name,\n",
    "    model_data=code_artifact,\n",
    "    image_uri=CONTAINER,\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    env=env,\n",
    "    predictor_cls = Predictor,\n",
    ")\n",
    "\n",
    "\n",
    "# 部署模型到endpoint\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"sagemaker-sglang\")+\"-endpoint\"\n",
    "print(f\"endpoint_name: {endpoint_name}\")\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',\n",
    "    endpoint_name=endpoint_name,\n",
    "    model_name=model_name, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test\n",
    "\n",
    "you can invoke your model with SageMaker SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Message api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime = boto3.client('runtime.sagemaker',region_name='us-east-1')\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"who are you\"\n",
    "    }\n",
    "    ],\n",
    "    \"model\":\"qwen\",\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 Message api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Write a quick sort in python\"\n",
    "    }\n",
    "    ],\n",
    "    \"model\":\"custome\",\n",
    "    \"max_tokens\": 4096,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.span()[1]\n",
    "            print(data[\"choices\"][0][\"delta\"][\"content\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
