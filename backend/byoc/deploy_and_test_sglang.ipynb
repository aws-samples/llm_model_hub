{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SageMaker Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the container\n",
    "\n",
    "demo codes are in `app/`\n",
    "build and push the docker with following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set -e\n",
      "\n",
      "# This script shows how to build the Docker image and push it to ECR to be ready for use\n",
      "# by SageMaker.\n",
      "\n",
      "# The argument to this script is the region name. \n",
      "# 尝试使用 IMDSv2 获取 token\n",
      "TOKEN=$(curl -X PUT \"http://169.254.169.254/latest/api/token\" -H \"X-aws-ec2-metadata-token-ttl-seconds: 21600\")\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    56  100    56    0     0  45197      0 --:--:-- --:--:-- --:--:-- 56000\n",
      "\n",
      "# Get the current region and write it to the backend .env file\n",
      "region=$(curl -H \"X-aws-ec2-metadata-token: $TOKEN\" -s http://169.254.169.254/latest/meta-data/placement/region)\n",
      "# region=$(aws configure get region)\n",
      "suffix=\"com\"\n",
      "\n",
      "if [[ $region =~ ^cn ]]; then\n",
      "    suffix=\"com.cn\"\n",
      "fi\n",
      "\n",
      "# Get the account number associated with the current IAM credentials\n",
      "account=$(aws sts  get-caller-identity --query Account --output text)\n",
      "\n",
      "SGL_VERSION=latest\n",
      "inference_image=sagemaker_endpoint/sglang\n",
      "inference_fullname=${account}.dkr.ecr.${region}.amazonaws.${suffix}/${inference_image}:${SGL_VERSION}\n",
      "\n",
      "# If the repository doesn't exist in ECR, create it.\n",
      "aws  ecr describe-repositories --repository-names \"${inference_image}\" --region ${region} || aws ecr create-repository --repository-name \"${inference_image}\" --region ${region}\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryArn\": \"arn:aws:ecr:us-east-1:434444145045:repository/sagemaker_endpoint/sglang\",\n",
      "            \"registryId\": \"434444145045\",\n",
      "            \"repositoryName\": \"sagemaker_endpoint/sglang\",\n",
      "            \"repositoryUri\": \"434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/sglang\",\n",
      "            \"createdAt\": 1739108011.378,\n",
      "            \"imageTagMutability\": \"MUTABLE\",\n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            },\n",
      "            \"encryptionConfiguration\": {\n",
      "                \"encryptionType\": \"AES256\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "if [ $? -ne 0 ]\n",
      "then\n",
      "    aws  ecr create-repository --repository-name \"${inference_image}\" --region ${region}\n",
      "fi\n",
      "\n",
      "# Get the login command from ECR and execute it directly\n",
      "aws  ecr get-login-password --region $region | docker login --username AWS --password-stdin $account.dkr.ecr.$region.amazonaws.${suffix}\n",
      "WARNING! Your password will be stored unencrypted in /home/ubuntu/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "aws ecr set-repository-policy \\\n",
      "    --repository-name \"${inference_image}\" \\\n",
      "    --policy-text \"file://ecr-policy.json\" \\\n",
      "    --region ${region}\n",
      "{\n",
      "    \"registryId\": \"434444145045\",\n",
      "    \"repositoryName\": \"sagemaker_endpoint/sglang\",\n",
      "    \"policyText\": \"{\\n  \\\"Version\\\" : \\\"2008-10-17\\\",\\n  \\\"Statement\\\" : [ {\\n    \\\"Sid\\\" : \\\"new statement\\\",\\n    \\\"Effect\\\" : \\\"Allow\\\",\\n    \\\"Principal\\\" : \\\"*\\\",\\n    \\\"Action\\\" : [ \\\"ecr: CompleteLayerUpload\\\", \\\"ecr: InitiateLayerUpload\\\", \\\"ecr: ListImages\\\", \\\"ecr:BatchCheckLayerAvailability\\\", \\\"ecr:BatchGetImage\\\", \\\"ecr:DescribeImages\\\", \\\"ecr:DescribeRepositories\\\", \\\"ecr:GetDownloadUrlForLayer\\\" ]\\n  } ]\\n}\"\n",
      "}\n",
      "\n",
      "# Build the docker image locally with the image name and then push it to ECR\n",
      "# with the full name.\n",
      "\n",
      "docker build  --build-arg SGL_VERSION=${SGL_VERSION} -t ${inference_image}:${SGL_VERSION}  -f Dockerfile.sglang . \n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/2)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (10/11)                                        docker:default\n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile.sglang                0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 953B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/lmsysorg/sglang:latest          0.1s\n",
      "\u001b[0m\u001b[34m => [1/6] FROM docker.io/lmsysorg/sglang:latest@sha256:c693c32445ea938e11  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 103B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/6] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/6] COPY app_sglang/ /app                                     0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/6] COPY requirements.txt /app                                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/6] RUN pip install -r requirements.txt                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [6/6] RUN export PYTHON_SITEPACKAGES=`python3 -c \"import sglan  0.0s\n",
      "\u001b[0m => exporting to image                                                     0.0s\n",
      "\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (11/11) FINISHED                               docker:default\n",
      "\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build definition from Dockerfile.sglang                0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 953B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/lmsysorg/sglang:latest          0.1s\n",
      "\u001b[0m\u001b[34m => [1/6] FROM docker.io/lmsysorg/sglang:latest@sha256:c693c32445ea938e11  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 103B                                          0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/6] WORKDIR /app                                              0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [3/6] COPY app_sglang/ /app                                     0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [4/6] COPY requirements.txt /app                                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [5/6] RUN pip install -r requirements.txt                       0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [6/6] RUN export PYTHON_SITEPACKAGES=`python3 -c \"import sglan  0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:0b487ad1e21e0f0663340ac26742a8d2601830a17f9db  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/sagemaker_endpoint/sglang:latest                0.0s\n",
      "\u001b[0m\u001b[?25h\n",
      "docker tag ${inference_image}:${SGL_VERSION} ${inference_fullname}\n",
      "\n",
      "docker push ${inference_fullname}\n",
      "The push refers to repository [434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/sglang]\n",
      "\n",
      "\u001b[1B44721b19: Preparing \n",
      "\u001b[1B012919ce: Preparing \n",
      "\u001b[1Bbad29619: Preparing \n",
      "\u001b[1B53b18379: Preparing \n",
      "\u001b[1B266298fb: Preparing \n",
      "\u001b[1B9a3b8aa7: Preparing \n",
      "\u001b[1Bc87fedfc: Preparing \n",
      "\u001b[1B7495d60d: Preparing \n",
      "\u001b[1B9895f7cd: Preparing \n",
      "\u001b[1B8bbccdd1: Preparing \n",
      "\u001b[1B73680ef3: Preparing \n",
      "\u001b[1B14258878: Preparing \n",
      "\u001b[1B9ed2f631: Preparing \n",
      "\u001b[1Bda6ba3ae: Preparing \n",
      "\u001b[1B70b9a284: Preparing \n",
      "\u001b[1B88486056: Preparing \n",
      "\u001b[1B7c97ed4d: Preparing \n",
      "\u001b[1B3c3b8514: Preparing \n",
      "\u001b[1Bb7e2d072: Preparing \n",
      "\u001b[1B8f6fcd6a: Preparing \n",
      "\u001b[1Bded77c0c: Layer already exists \u001b[16A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[5A\u001b[2K\u001b[2A\u001b[2Klatest: digest: sha256:273074cde17b788ebc0db084d0f7eb256ad01f6cd5417d125eeabc02b9a1e44b size: 4721\n",
      "# 删除 .env 文件中的 sglang_image= 这一行\n",
      "sed -i '/^sglang_image=/d' /home/ubuntu/llm_model_hub/backend/.env\n",
      "sed: can't read /home/ubuntu/llm_model_hub/backend/.env: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!bash build_and_push_sglang.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy on SageMaker\n",
    "\n",
    "define the model and deploy on SageMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Init SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ubuntu/.config/sagemaker/config.yaml\n",
      "environ({'USER': 'ubuntu', 'SSH_CLIENT': '52.94.133.139 6442 22', 'XDG_SESSION_TYPE': 'tty', 'SHLVL': '2', 'HOME': '/home/ubuntu', 'SSL_CERT_FILE': '/usr/lib/ssl/cert.pem', 'DBUS_SESSION_BUS_ADDRESS': 'unix:path=/run/user/1000/bus', 'LOGNAME': 'ubuntu', '_': '/home/ubuntu/workspace/llm_model_hub/miniconda3/envs/py311/bin/python', 'XDG_SESSION_CLASS': 'user', 'XDG_SESSION_ID': '30380', 'VSCODE_CLI_REQUIRE_TOKEN': 'b9fe4d58-1d0a-4fa7-8f84-71a7c11ae186', 'PATH': '/home/ubuntu/workspace/llm_model_hub/miniconda3/envs/py311/bin:/home/ubuntu/.vscode-server/cli/servers/Stable-cd4ee3b1c348a13bafd8f9ad8060705f6d4b9cba/server/bin/remote-cli:/home/ubuntu/.local/bin:/home/ubuntu/workspace/llm_model_hub/miniconda3/envs/py311/bin:/home/ubuntu/workspace/llm_model_hub/miniconda3/condabin:/home/ubuntu/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin', 'VSCODE_AGENT_FOLDER': '/home/ubuntu/.vscode-server', 'XDG_RUNTIME_DIR': '/run/user/1000', 'SSL_CERT_DIR': '/usr/lib/ssl/certs', 'LANG': 'C.UTF-8', 'SHELL': '/bin/bash', 'PWD': '/home/ubuntu', 'SSH_CONNECTION': '52.94.133.139 6442 172.31.38.107 22', 'XDG_DATA_DIRS': '/usr/local/share:/usr/share:/var/lib/snapd/desktop', 'VSCODE_CWD': '/home/ubuntu', 'VSCODE_NLS_CONFIG': '{\"userLocale\":\"en\",\"osLocale\":\"en\",\"resolvedLanguage\":\"en\",\"defaultMessagesFile\":\"/home/ubuntu/.vscode-server/cli/servers/Stable-cd4ee3b1c348a13bafd8f9ad8060705f6d4b9cba/server/out/nls.messages.json\",\"locale\":\"en\",\"availableLanguages\":{}}', 'VSCODE_HANDLES_SIGPIPE': 'true', 'CONDA_EXE': '/home/ubuntu/workspace/llm_model_hub/miniconda3/bin/conda', '_CE_M': '', 'CONDA_PREFIX': '/home/ubuntu/workspace/llm_model_hub/miniconda3/envs/py311', 'LS_COLORS': '', 'CONDA_PROMPT_MODIFIER': '(py311) ', 'LESSCLOSE': '/usr/bin/lesspipe %s %s', '_CE_CONDA': '', 'LESSOPEN': '| /usr/bin/lesspipe %s', 'CONDA_SHLVL': '2', 'CONDA_PYTHON_EXE': '/home/ubuntu/workspace/llm_model_hub/miniconda3/bin/python', 'CONDA_DEFAULT_ENV': 'py311', 'VSCODE_ESM_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess', 'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true', 'BROWSER': '/home/ubuntu/.vscode-server/cli/servers/Stable-cd4ee3b1c348a13bafd8f9ad8060705f6d4b9cba/server/bin/helpers/browser.sh', 'ELECTRON_RUN_AS_NODE': '1', 'VSCODE_IPC_HOOK_CLI': '/run/user/1000/vscode-ipc-5632fbc6-2791-47aa-82eb-1d9b4abac0ef.sock', '__TELEMETRY_CLIENT_ID': '34b29427-cc66-45ae-ad56-875abb609874', 'VSCODE_L10N_BUNDLE_LOCATION': '', 'PYTHONUNBUFFERED': '1', 'CONDA_ROOT': '/home/ubuntu/workspace/llm_model_hub/miniconda3', 'PYTHONIOENCODING': 'utf-8', 'REACT_APP_CALCULATOR': 'https://aws-gpu-memory-caculator.streamlit.app/', 'REACT_APP_API_KEY': 'f1e16e1e6214d7c44d078b1f0607b2388f29d729', 'CONDA_PREFIX_1': '/home/ubuntu/workspace/llm_model_hub/miniconda3', 'REACT_APP_API_ENDPOINT': 'http://ec2-3-93-192-33.compute-1.amazonaws.com:443/v1', 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1', 'PYTHON_FROZEN_MODULES': 'on', 'PYDEVD_USE_FRAME_EVAL': 'NO', 'TERM': 'xterm-color', 'CLICOLOR': '1', 'FORCE_COLOR': '1', 'CLICOLOR_FORCE': '1', 'PAGER': 'cat', 'GIT_PAGER': 'cat', 'MPLBACKEND': 'module://matplotlib_inline.backend_inline', 'AK': '', 'SK': '', 'profile': '', 'region': 'us-east-1', 'role': 'arn:aws:iam::434444145045:role/sagemaker-modelhub', 'db_host': '127.0.0.1', 'db_name': 'llm', 'db_user': 'llmdata', 'db_password': 'llmdata', 'api_keys': 'f1e16e1e6214d7c44d078b1f0607b2388f29d729', 'HUGGING_FACE_HUB_TOKEN': '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', 'WANDB_API_KEY': '', 'WANDB_BASE_URL': '', 'SWANLAB_API_KEY': 'q9DzTanu9McPqslOnqg6D', 'vllm_image': '434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/vllm:v0.7.2', 'model_artifact': 's3://sagemaker-us-east-1-434444145045/sagemaker_endpoint/vllm/model.tar.gz', 'training_image': '434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker/llamafactory:0.9.2.dev0'})\n"
     ]
    }
   ],
   "source": [
    "# !pip install boto3 sagemaker transformers\n",
    "import re\n",
    "import json\n",
    "import os,dotenv\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "print(os.environ)\n",
    "\n",
    "boto_sess = boto3.Session(\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "sess = sagemaker.session.Session(boto_session=boto_sess)\n",
    "# role = sagemaker.get_execution_role()\n",
    "role = os.environ.get('role')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Prepare model file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: deploy vllm by model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_tar/\n",
      "model_tar/env\n",
      "model_tar/s5cmd\n"
     ]
    }
   ],
   "source": [
    "!tar czvf model.tar.gz model_tar/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-east-1-434444145045/sagemaker_endpoint/sglang//model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "s3_code_prefix = f\"sagemaker_endpoint/sglang/\"\n",
    "bucket = sess.default_bucket() \n",
    "code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3 Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CONTAINER='434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/vllm:v0.5.5'\n",
    "# model = Model(\n",
    "#     name=sagemaker.utils.name_from_base(\"sagemaker-vllm\")+\"_model\",\n",
    "#     model_data=code_artifact,\n",
    "#     image_uri=CONTAINER,\n",
    "#     role=role,\n",
    "#     sagemaker_session=sess,\n",
    "# )\n",
    "\n",
    "# # 部署模型到endpoint\n",
    "# endpoint_name = sagemaker.utils.name_from_base(\"sagemaker-vllm\")+\"_endpoint\"\n",
    "# print(f\"endpoint_name: {endpoint_name}\")\n",
    "# predictor = model.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type='ml.g5.2xlarge',\n",
    "#     endpoint_name=endpoint_name,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test deployment from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint_name: sagemaker-sglang-2025-02-09-15-34-30-904-endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m endpoint_name \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mname_from_base(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msagemaker-sglang\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-endpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mendpoint_name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_instance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mml.g4dn.2xlarge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/llm_model_hub/miniconda3/envs/py311/lib/python3.11/site-packages/sagemaker/model.py:1721\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, accept_eula, endpoint_logging, resources, endpoint_type, managed_instance_scaling, inference_component_name, routing_config, **kwargs)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_explainer_enabled:\n\u001b[1;32m   1719\u001b[0m     explainer_config_dict \u001b[38;5;241m=\u001b[39m explainer_config\u001b[38;5;241m.\u001b[39m_to_request_dict()\n\u001b[0;32m-> 1721\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_from_production_variants\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproduction_variants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mproduction_variant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls:\n\u001b[1;32m   1734\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session)\n",
      "File \u001b[0;32m~/workspace/llm_model_hub/miniconda3/envs/py311/lib/python3.11/site-packages/sagemaker/session.py:5711\u001b[0m, in \u001b[0;36mSession.endpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict, explainer_config_dict, live_logging, vpc_config, enable_network_isolation, role)\u001b[0m\n\u001b[1;32m   5708\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating endpoint-config with name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m   5709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_endpoint_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_options)\n\u001b[0;32m-> 5711\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlive_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5717\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/llm_model_hub/miniconda3/envs/py311/lib/python3.11/site-packages/sagemaker/session.py:4569\u001b[0m, in \u001b[0;36mSession.create_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait, live_logging)\u001b[0m\n\u001b[1;32m   4566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint_arn \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEndpointArn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   4568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 4569\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlive_logging\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m endpoint_name\n",
      "File \u001b[0;32m~/workspace/llm_model_hub/miniconda3/envs/py311/lib/python3.11/site-packages/sagemaker/session.py:5325\u001b[0m, in \u001b[0;36mSession.wait_for_endpoint\u001b[0;34m(self, endpoint, poll, live_logging)\u001b[0m\n\u001b[1;32m   5310\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for an Amazon SageMaker endpoint deployment to complete.\u001b[39;00m\n\u001b[1;32m   5311\u001b[0m \n\u001b[1;32m   5312\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5321\u001b[0m \u001b[38;5;124;03m    dict: Return value from the ``DescribeEndpoint`` API.\u001b[39;00m\n\u001b[1;32m   5322\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m live_logging \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _has_permission_for_live_logging(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboto_session, endpoint):\n\u001b[0;32m-> 5325\u001b[0m     desc \u001b[38;5;241m=\u001b[39m \u001b[43m_wait_until\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_deploy_done\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5327\u001b[0m     cloudwatch_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboto_session\u001b[38;5;241m.\u001b[39mclient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/llm_model_hub/miniconda3/envs/py311/lib/python3.11/site-packages/sagemaker/session.py:8218\u001b[0m, in \u001b[0;36m_wait_until\u001b[0;34m(callable_fn, poll)\u001b[0m\n\u001b[1;32m   8216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   8217\u001b[0m     elapsed_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m poll\n\u001b[0;32m-> 8218\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8219\u001b[0m     result \u001b[38;5;241m=\u001b[39m callable_fn()\n\u001b[1;32m   8220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m botocore\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mClientError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   8221\u001b[0m     \u001b[38;5;66;03m# For initial 5 mins we accept/pass AccessDeniedException.\u001b[39;00m\n\u001b[1;32m   8222\u001b[0m     \u001b[38;5;66;03m# The reason is to await tag propagation to avoid false AccessDenied claims for an\u001b[39;00m\n\u001b[1;32m   8223\u001b[0m     \u001b[38;5;66;03m# access policy based on resource tags, The caveat here is for true AccessDenied\u001b[39;00m\n\u001b[1;32m   8224\u001b[0m     \u001b[38;5;66;03m# cases the routine will fail after 5 mins\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CONTAINER='434444145045.dkr.ecr.us-east-1.amazonaws.com/sagemaker_endpoint/sglang:latest'\n",
    "model_path = \"s3://sagemaker-us-east-1-434444145045/Qwen2-1-5B-Instruct/6d0410c634ea438fa5018072e84c10a6/finetuned_model_merged/\"\n",
    "# model_id=\"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
    "model_id = 'Qwen/Qwen2-1.5B-Instruct'\n",
    "env={\n",
    "    \"HF_MODEL_ID\": model_id,\n",
    "    # \"S3_MODEL_PATH\":model_path,\n",
    "}\n",
    "model = Model(\n",
    "    name=sagemaker.utils.name_from_base(\"sagemaker-sglang\")+\"-model\",\n",
    "    model_data=code_artifact,\n",
    "    image_uri=CONTAINER,\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    env=env,\n",
    ")\n",
    "\n",
    "# 部署模型到endpoint\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"sagemaker-sglang\")+\"-endpoint\"\n",
    "print(f\"endpoint_name: {endpoint_name}\")\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g4dn.2xlarge',\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test\n",
    "\n",
    "you can invoke your model with SageMaker SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Message api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Greetings! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have.\n"
     ]
    }
   ],
   "source": [
    "runtime = boto3.client('runtime.sagemaker',region_name='us-east-1')\n",
    "endpoint_name = \"DeepSeek-R1-Distill-Llama-8B-2025-02-06-13-14-15-806\"\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"who are you\"\n",
    "    }\n",
    "    ],\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 Message api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to write a quick sort in Python. Hmm, I remember that quick sort is a divide-and-conquer algorithm. The idea is to pick a pivot and then partition the array around the pivot. Then recursively sort the subarrays. \n",
      "\n",
      "Wait, first, what's a pivot? Oh right, it's an element in the array. You choose it, then elements less than the pivot go to the left, and those greater go to the right. But how do you choose the pivot? There are a few strategies like choosing the middle element, the first, the last, or even a random element. I think for simplicity, I'll choose the middle element.\n",
      "\n",
      "So, maybe I should write a helper function that takes an array and a low and high index. Inside this function, if the low is greater than high, the subarray is sorted. Otherwise, I choose the middle element as the pivot. Then, I partition the array so that all elements before the pivot are less than or equal, and after are greater or equal.\n",
      "\n",
      "Wait, but in Python, modifying the list in place is more efficient. Should I modify the list or make a copy? Well, for the sake of this code, maybe in-place modification is better to avoid creating new lists.\n",
      "\n",
      "So, steps:\n",
      "\n",
      "1. Function quick_sort(arr, low, high).\n",
      "2. Base case: if low > high, return.\n",
      "3. Choose pivot as arr[low + (high - low)//2].\n",
      "4. Partition the array into left and right where left has elements <= pivot and right has >=.\n",
      "5. Recursively sort left and right.\n",
      "6. Return the sorted array.\n",
      "\n",
      "Wait, how does the partitioning work? I need to actually move elements around in the array. So, I'll have two pointers, left_ptr and right_ptr, initialized to low and low+1.\n",
      "\n",
      "Then, iterate through the array from left_ptr to high. If the element is <= pivot, swap it with left_ptr and increment left_ptr. Then, after the loop, set right_ptr to left_ptr. Then, arr[low:right_ptr] is the left subarray, and arr[right_ptr:high+1] is the right.\n",
      "\n",
      "Wait, but when swapping, I have to make sure that after the swap, left_ptr increases. So, code inside the loop: if arr[i] <= pivot, swap arr[left_ptr], arr[i], then left_ptr +=1.\n",
      "\n",
      "Yes, that should move all elements less than or equal to the pivot to the left side, and others to the right.\n",
      "\n",
      "Then, recursively sort the left and right subarrays. After that, the entire array is sorted.\n",
      "\n",
      "So, putting this all together. Let me think about the code structure.\n",
      "\n",
      "First, the function definition:\n",
      "\n",
      "def quick_sort(arr, low, high):\n",
      "    if low > high:\n",
      "        return\n",
      "    pivot = arr[low + (high - low) // 2]  # Middle element as pivot\n",
      "    left_ptr, right_ptr = low, low +1\n",
      "    while right_ptr <= high:\n",
      "        if arr[right_ptr] <= pivot:\n",
      "            arr[left_ptr], arr[right_ptr] = arr[right_ptr], arr[left_ptr]\n",
      "            left_ptr +=1\n",
      "        right_ptr +=1\n",
      "    # At this point, left is from low to left_ptr-1, right is right_ptr to high.\n",
      "    # So, recursively sort left and right.\n",
      "    quick_sort(arr, low, left_ptr-1)\n",
      "    quick_sort(arr, right_ptr, high)\n",
      "    return\n",
      "\n",
      "Wait, but I should test this. Let me take an example. Say arr is [3,1,2,4]. Let's see what happens.\n",
      "\n",
      "Initial call: quick_sort(arr, 0,3). pivot is index 0 + (3-0)//2=1, so arr[1] which is 1.\n",
      "\n",
      "Partitioning: left_ptr=0, right_ptr=1.\n",
      "\n",
      "Loop: right_ptr is 1. Compare arr[1]=1 <= pivot 1. So swap with arr[0], left_ptr becomes 1. Now arr becomes [1,3,2,4]. Then right_ptr increases to 2.\n",
      "\n",
      "Next iteration: right_ptr=2, check arr[2]=2 <=1? No. So right_ptr increases to3.\n",
      "\n",
      "Now, the loop ends. So left is low=0 to left_ptr-1=0, right is right_ptr=2 to high=3.\n",
      "\n",
      "Recursively sort left (indices 0-0): quick_sort(arr,0,0). Base case, returns.\n",
      "\n",
      "Sort the right (indices 2-3): quick_sort(arr,2,3). Pivot is index 2 + (3-2)//2=2, so arr[2]=2. left_ptr=2, right_ptr=3.\n",
      "\n",
      "Check right_ptr=3: compare arr[3] =4 <=2? No, so right_ptr increases beyond loop. Then, recursively sort left (indices2-2), which is a base case, and right (3-3), same.\n",
      "\n",
      "So, the array becomes [1,3,2,4]. Wait, but that's not sorted. Something's wrong.\n",
      "\n",
      "Wait, no, because after the pivot is 1, the left is [1], which is sorted. The right subarray is [3,2,4]. Wait, no, no, the right subarray is from index 2 to 3, which is [2,4]. But after the partitioning, the right subarray is [3,2,4], but that's not correct. Wait, did I make a mistake in the partitioning step?\n",
      "\n",
      "Wait, after the first quick_sort call with low=0, high=3, pivot is arr[1]=1.\n",
      "\n",
      "Wait no, the array after pivot selection is [3,1,2,4]. Then, during partitioning, initial left_ptr is 0, right_ptr=1.\n",
      "\n",
      "Check right_ptr=1: arr[1] is 1 which is <= pivot. So, swap with left_ptr=0: so arr becomes [1,3,2,4]. left_ptr increments to1, right_ptr increments to2.\n",
      "\n",
      "Now, right_ptr=2: arr[2]=2 <=1? No, so right_ptr increments to3.\n",
      "\n",
      "Loop ends. Now, the left subarray is from low=0 to left_ptr-1=0, which is [1], correctly sorted. The right subarray is from right_ptr=2 to high=3, which is [2,4].\n",
      "\n",
      "Wait, but the right subarray after partitioning is [2,4], which is correctly sorted. So, the quick_sort on the left is done, then the quick_sort on the right.\n",
      "\n",
      "So, quick_sort on the right subarray: low=2, high=3.\n",
      "\n",
      "Pivot is arr[2 + (3-2)//2] = arr[2]=2.\n",
      "\n",
      "Partitioning: left_ptr=2, right_ptr=3.\n",
      "\n",
      "Check right_ptr=3: arr[3]=4 <=2? No, so right_ptr increases. Then, recursively sort left and right.\n",
      "\n",
      "Left is from 2-2 (just [2]), right is from3-3. So, array remains after return as [1,3,2,4]. Oh, but that's not sorted. Or wait, after the recursion, the right subarray is [2,4], which when sorted becomes [2,4]. So the final array should be [1,2,3,4].\n",
      "\n",
      "Wait, but in the code, the right subarray after the first partitioning is [2,4], which is being sorted. So that part should work.\n",
      "\n",
      "Wait, maybe I made a mistake in the original example. Let's walk through the code again.\n",
      "\n",
      "Initial array: [3,1,2,4]\n",
      "\n",
      "step 1: quick_sort(0,3). pivot is index 0+ (3-0)//2=1, so arr[1]=1.\n",
      "\n",
      "Partitioning:\n",
      "\n",
      "left_ptr=0, right_ptr=1.\n",
      "\n",
      "arr[1] is 1 <=1, so swap with left_ptr=0. Now, array is [1,3,2,4]. left_ptr becomes1.\n",
      "\n",
      "right_ptr increments to2.\n",
      "\n",
      "Now, check arr[2]=2 <=1? No. right_ptr increments to3.\n",
      "\n",
      "Check arr[3]=4 <=1? No. right_ptr becomes4, loop ends.\n",
      "\n",
      "So, left subarray is from 0 to 0: [1]. right subarray is from2 to3: [2,4].\n",
      "\n",
      "Sort left: nothing to do.\n",
      "\n",
      "Sort right: quick_sort(2,3).\n",
      "\n",
      "Pivot is arr[2 + (3-2)//2] = arr[2]=2.\n",
      "\n",
      "Partitioning: left_ptr=2, right_ptr=3.\n",
      "\n",
      "arr[3]=4 <=2? No. right_ptr becomes4. So, right is partitioned with elements from3 to3: [4]. left is from2-2: [2].\n",
      "\n",
      "So, the right subarray after sorting is [2,4].\n",
      "\n",
      "So, the overall array after all recursion is [1,2,3,4]. So, why in my previous example, the array wasn't sorted? Oh, perhaps I made a mistake in my manual calculation.\n",
      "\n",
      "So, perhaps the code is correct. Let me test it with another example.\n",
      "\n",
      "Test with [4,3,2,1].\n",
      "\n",
      "First call: quick_sort(0,3).\n",
      "\n",
      "pivot is arr[0 +3//2=1] = arr[1]=3.\n",
      "\n",
      "Partitioning:\n",
      "\n",
      "left_ptr=0, right_ptr=1.\n",
      "\n",
      "Compare arr[1]=3 <=3. Swap with left_ptr=0: array becomes [3,4,2,1]. left_ptr becomes1.\n",
      "\n",
      "right_ptr increments to2.\n",
      "\n",
      "Compare arr[2]=2 <=3: yes. Swap with left_ptr=1. array becomes [3,2,4,1]. left_ptr becomes2.\n",
      "\n",
      "right_ptr increments to3.\n",
      "\n",
      "Compare arr[3]=1 <=3: yes. Swap with left_ptr=2. array becomes [3,2,1,4]. left_ptr becomes3.\n",
      "\n",
      "right_ptr increments to4, loop ends.\n",
      "\n",
      "Now, left subarray is from0 to2: [3,2,1]. Right subarray is from4 to3? Wait, low=0, left_ptr=3, so right subarray is right_ptr=4 to3? That doesn't make sense. Wait, in the code, after partitioning, the right subarray is right_ptr to high.\n",
      "\n",
      "Wait in the code: after the loop, right_ptr is 4, high is3. So, in that case, do we do the right subarray? No, because right_ptr > high, so the function returns. Wait, but that's a problem. Because in the example, the right subarray is from3 to3: [4]. So, how is it handled?\n",
      "\n",
      "Wait, no, in the code, after the loop, the right subarray is from right_ptr to high. So, in this case, right_ptr is4, high is3, so right_ptr>high, so the right subarray is empty. But that's not correct because in the example, we have elements after the pivot.\n",
      "\n",
      "Ah, I think I see the mistake. The initial code only processes the right subarray when right_ptr is less than or equal to high. But in the example, after the loop, right_ptr is4, which is beyond high. So, the right subarray is not processed, but in reality, there are elements to the right of the pivot that haven't been sorted.\n",
      "\n",
      "Wait, no, in the initial example, after the partitioning, all elements <=pivot are to the left, and the rest are to the right. So, after the first pivot, the elements to the right should form the right subarray to be sorted.\n",
      "\n",
      "But in the code, the way the right_ptr is handled may not correctly capture that.\n",
      "\n",
      "Wait, perhaps the code is incorrect. Let's reconsider the partitioning step.\n",
      "\n",
      "When partitioning, the code moves all elements <= pivot to the left, and others to the right. So, the left subarray is from low to left_ptr-1, and the right subarray is from right_ptr to high.\n",
      "\n",
      "But in the code, after the loop, right_ptr is set, but in the recursive step, it's passing right_ptr as the start of the right subarray, but after the loop, right_ptr could be high+1, which is beyond the array.\n",
      "\n",
      "Wait, let me think again. The code uses while right_ptr <= high: inside this, it swaps and moves right_ptr.\n",
      "\n",
      "So, for the example [4,3,2,1], after the pivot is 3, the partitioning step makes:\n",
      "\n",
      "- The left subarray (3,2,1) and the right subarray (4).\n",
      "\n",
      "But in the code, the loop ends when right_ptr is4, high is3. So, the right subarray is from4 to high, which is invalid. Therefore, the code fails to process the right subarray correctly.\n",
      "\n",
      "Wait, that's a problem. So, perhaps the way the right_ptr is handled is incorrect.\n",
      "\n",
      "Wait, perhaps after the loop, the right subarray is from right_ptr to high, but the loop condition is right_ptr <=high. So, in this example, the loop stops when right_ptr is4, which is after high=3. So, the right subarray is right_ptr (4) to high (3), which is an invalid interval.\n",
      "\n",
      "Thus, the code is missing the right subarray in some cases.\n",
      "\n",
      "So, perhaps the code should not just sort the left and right subarrays when the pivot is selected, but in cases where the right_ptr exceeds high, the right subarray is already correctly processed.\n",
      "\n",
      "Wait, but I'm not sure. Maybe I need to fix the partitioning step.\n",
      "\n",
      "Alternative approach: after the loop, the subarray after right_ptr is the right partition, so we can recursively sort from right_ptr to high.\n",
      "\n",
      "Wait, but in the code, in the example with [4,3,2,1], the loop for the initial quick_sort call ends with right_ptr at4, high at3, so the right_ptr is beyond high. Therefore, the code does not call quick_sort on the right subarray, which is [4], because right_ptr > high.\n",
      "\n",
      "That's a problem. So, the code is not handling cases where the right_ptr exceeds high.\n",
      "\n",
      "Similarly, in the initial example, the [3,1,2,4] case worked correctly because the right_ptr was at2, which was within the high=3.\n",
      "\n",
      "But in the [4,3,2,1] case, the right_ptr ended up beyond high, so the right subarray [4] is never sorted.\n",
      "\n",
      "Wait, that's a mistake. So, to fix the code, perhaps after the loop, the right_ptr is the starting index of the right subarray.\n",
      "\n",
      "So, in the code, after the loop, the right subarray is from right_ptr to high. But when right_ptr >high, it's invalid, so we shouldn't process it.\n",
      "\n",
      "Wait, but in the code, in the [4,3,2,1] example, the right subarray is just [4], which needs to be sorted. But since right_ptr is4, high is3, the right subarray is from4 to3, which is invalid. So, the code does not process it, and the array remains [3,2,1,4], which is not sorted.\n",
      "\n",
      "Hmm, that's a problem. So, the issue is that the right_ptr is sometimes set beyond high, but the subarray from right_ptr to high is effectively empty when right_ptr > high. But in reality, in the code, when right_ptr exceeds high, the subarray from right_ptr to high is empty, so nothing needs to be done.\n",
      "\n",
      "Wait, no, because when right_ptr exceeds high, the subarray from right_ptr to high is empty, so the left subarray includes all elements except those in the right subarray. Hmm, not sure. Maybe I need to adjust how the subarrays are defined.\n",
      "\n",
      "Alternatively, perhaps the code is correct, but in the [4,3,2,1] example, the right subarray is properly handled. Let me think again.\n",
      "\n",
      "After partitioning, the code sorts the left and right subarrays. In the initial example, the right subarray was [2,4], which is correctly processed. In the [4,3,2,1] example, after the pivot, the right subarray is [4], but because right_ptr is4, which is greater than high=3, the code doesn't process it, but it should.\n",
      "\n",
      "Wait, no, in the [4,3,2,1] example, after the pivot is3, the left subarray is [3,2,1], and the right subarray is [4]. So, the right subarray is from index3 to3, which is [4]. But in the code, the right_ptr after the loop is4, and high is3. So, the code would not process the right subarray, but it is necessary to do so.\n",
      "\n",
      "Therefore, the code is incorrect because it's missing the right subarray when right_ptr exceeds high.\n",
      "\n",
      "Hmm, how to fix this.\n",
      "\n",
      "Perhaps, in the code, the right subarray should be from right_ptr to high if right_ptr is <=high. But maybe the condition should be <=high.\n",
      "\n",
      "Wait, in the code, after the loop, right_ptr could be high+1. So, perhaps the code should check whether right_ptr is <=high. If so, process the right subarray. Otherwise, it's already processed.\n",
      "\n",
      "Alternatively, perhaps the initial while loop should go until right_ptr <=high, which is correct, but after that, the right subarray is right_ptr to high. If right_ptr is <=high, then process it; else, the subarray is empty.\n",
      "\n",
      "Wait, but in the [4,3,2,1] case, the right subarray is [4], but right_ptr is4, which is >high=3. So, the code doesn't process it, which is incorrect.\n",
      "\n",
      "So, perhaps the code should always process the right subarray regardless of right_ptr's position. Wait, no, because in the initial example, that would cause duplication.\n",
      "\n",
      "Alternatively, perhaps the code is correct, and I made a mistake in the manual calculation.\n",
      "\n",
      "Wait, let me re-examine the [4,3,2,1] case.\n",
      "\n",
      "After the initial quick_sort(0,3), the arr is [3,2,1,4]. Wait, no, that's not correct. Wait, the pivot is3, and the partitioning step.\n",
      "\n",
      "Wait, initial arr is [4,3,2,1]. pivot is3 at index1.\n",
      "\n",
      "Partition step:\n",
      "\n",
      "left_ptr=0, right_ptr=1.\n",
      "\n",
      "Compare arr[1]=3 <=3. So swap with left_ptr=0, arr becomes [3,4,2,1]. left_ptr=1.\n",
      "\n",
      "right_ptr increments to2.\n",
      "\n",
      "Compare arr[2]=2: 2 <=3, swap with left_ptr=1: arr becomes [3,2,4,1]. left_ptr=2.\n",
      "\n",
      "right_ptr increments to3.\n",
      "\n",
      "Compare arr[3]=1 <=3: yes. Swap with left_ptr=2: arr becomes [3,2,1,4]. left_ptr=3.\n",
      "\n",
      "right_ptr increments to4.\n",
      "\n",
      "Loop ends.\n",
      "\n",
      "So, left subarray is from0 to2: [3,2,1]. Right subarray is from4 to3"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"messages\": [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Write a quick sort in python\"\n",
    "    }\n",
    "    ],\n",
    "    \"max_tokens\": 4096,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.span()[1]\n",
    "            print(data[\"choices\"][0][\"delta\"][\"content\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Completion api non-stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-6.7b-instruct\", trust_remote_code=True)\n",
    "messages=[\n",
    "    { 'role': 'user', 'content': \"write a quick sort algorithm in python.\"}\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(json.loads(response['Body'].read())[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Completion api stream mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"model\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "buffer = \"\"\n",
    "for t in response['Body']:\n",
    "    buffer += t[\"PayloadPart\"][\"Bytes\"].decode()\n",
    "    last_idx = 0\n",
    "    for match in re.finditer(r'^data:\\s*(.+?)(\\n\\n)', buffer):\n",
    "        try:\n",
    "            data = json.loads(match.group(1).strip())\n",
    "            last_idx = match.end()\n",
    "            # print(data)\n",
    "            print(data[\"choices\"][0][\"text\"], end=\"\")\n",
    "        except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "            pass\n",
    "    buffer = buffer[last_idx:]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
