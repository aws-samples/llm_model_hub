{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38588742-e08b-41b5-831d-a562a4d143b3",
   "metadata": {},
   "source": [
    "# Hyperpod Inference with KV cache and Intelligent Routing Admin Notebook\n",
    "\n",
    "HyperPod's KV Caching and Intelligent Routing features address key challenges in LLM inference, including high latency for long-context prompts, inefficient resource utilization in multi-turn conversations, redundant computation across similar requests, and poor scaling for concurrent users. Our solution combines advanced caching mechanisms with intelligent request routing to deliver an optimized inference experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deployment-paths",
   "metadata": {},
   "source": [
    "## 1.0 Choose Your Deployment Path\n",
    "\n",
    "This notebook supports two deployment scenarios. **Choose the path that matches your situation:**\n",
    "\n",
    "### Path 1: Console Cluster Creation with Inference Operator\n",
    "**Use this if:** You are creating a new HyperPod cluster\n",
    "**What it does:** Automatically installs inference operator during cluster creation\n",
    "**Skip to:** [Section 10.0 - KV Cache & Intelligent Routing Deployment](#10.0)\n",
    "\n",
    "### Path 2: Install Inference Operator on Existing Cluster\n",
    "**Use this if:** You have an existing HyperPod cluster without inference operator\n",
    "**What it does:** Manually installs all required components\n",
    "**Continue with:** Section 2.0 below\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "path1-console",
   "metadata": {},
   "source": [
    "## PATH 1: Console Cluster Creation\n",
    "\n",
    "### 1.1 Create Cluster via AWS Console\n",
    "\n",
    "This is the simplest path, using the AWS Console with automatic configuration and installation of inference operator and enablement of tiered storage with 20% allocated memory by default.\n",
    "\n",
    "1. Navigate to the SageMaker AI console\n",
    "2. Choose HyperPod Cluster from the left navigation pane and select Cluster Management\n",
    "3. Click Create HyperPod cluster and select Orchestrated by EKS\n",
    "4. Select Quick Setup\n",
    "5. In the Storage Configuration section:\n",
    "   - Enable tiered storage: Check this box\n",
    "   - Memory allocation percentage: 20% (default, recommended for most workloads)\n",
    "   - Adjust based on your caching needs (10-40% range)\n",
    "6. Complete cluster creation\n",
    "7. Once cluster is ready, **skip to [Section 10.0 - KV Cache & Intelligent Routing Deployment](#endpoint-deployment)**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "path2-existing",
   "metadata": {},
   "source": [
    "## PATH 2: Install Inference Operator on Existing Cluster\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "This notebook is to be run by Administrator (with Administrator access) plus sagemaker service in the trust policy, and cluster admin access to EKS cluster\n",
    "\n",
    "For access to EKS cluster:\n",
    "\n",
    "- Go to EKS console and select the cluster you are using\n",
    "- Look in the \"Access\" tab and select \"IAM Access Entries\"\n",
    "- If there is not an entry for your execution role:\n",
    "  - Select \"Create Access Entry\"\n",
    "  - Select the desired execution role and correlate the `AmazonEKSClusterAdminPolicy` with the role\n",
    "\n",
    "**Important:** Ensure the role running this notebook has Admin Access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90da80-eefa-4d48-9e9a-521b2e6d085f",
   "metadata": {},
   "source": [
    "## 2.0 Set up environment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bdb535-aea7-49e9-bd67-692bdb7c96be",
   "metadata": {},
   "source": [
    "### 2.1 Set up environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e26d03-0e54-40f3-92ee-774031026d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Name of your EKS cluster\n",
    "EKS_CLUSTER_NAME=\"modelhub16-eks\"\n",
    "\n",
    "# Region\n",
    "REGION=\"us-east-1\"\n",
    "\n",
    "# Account Id\n",
    "ACCOUNT_ID=\"434444145045\"\n",
    "\n",
    "# Name of Hyperpod cluster\n",
    "HP_CLUSTER_NAME=\"modelhub16\"\n",
    "\n",
    "# ARN of Hyperpod cluster\n",
    "HP_CLUSTER_ARN=\"arn:aws:sagemaker:us-east-1:434444145045:cluster/kapb14yhzsn7\"\n",
    "\n",
    "# ID of HyperPod cluster (last 12 characters of ARN)\n",
    "HP_CLUSTER_ID=\"900cf50a76f6418e83aa1feb1de238b1\"\n",
    "\n",
    "# S3 bucket where tls certificates will be uploaded\n",
    "TLS_BUCKET_NAME=\"llm-modelhub-hyperpod-434444145045-us-east-1\"\n",
    "\n",
    "# VPC Id\n",
    "VPC_ID=\"llm-modelhub-hyperpod-434444145045-us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15fe871-e034-4d08-98a7-cb1a70de5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "LB_CONTROLLER_POLICY_NAME = \"LBControllerPolicy-\" + HP_CLUSTER_ID\n",
    "S3_MOUNT_ACCESS_POLICY_NAME = \"S3MountpointAccessPolicy-\" + HP_CLUSTER_ID\n",
    "S3_CSI_ROLE_NAME = \"S3CSIRole-\" + HP_CLUSTER_ID\n",
    "KEDA_OPERATOR_POLICY_NAME = \"KedaOperatorPolicy-\" + HP_CLUSTER_ID\n",
    "KEDA_OPERATOR_ROLE_NAME = \"KedaOperatorRole-\" + HP_CLUSTER_ID\n",
    "PRESIGNED_URL_ACCESS_POLICY_NAME = \"PresignedUrlAccessPolicy\" + HP_CLUSTER_ID\n",
    "HYPERPOD_INFERENCE_ACCESS_POLICY_NAME = \"HyperpodInferenceAccessPolicy\" + HP_CLUSTER_ID\n",
    "HYPERPOD_INFERENCE_ROLE_NAME = \"HyperpodInferenceRole-\" + HP_CLUSTER_ID\n",
    "HYPERPOD_INFERENCE_SA_NAME=\"hyperpod-inference-operator-controller\"\n",
    "HYPERPOD_INFERENCE_SA_NAMESPACE=\"hyperpod-inference-system\"\n",
    "JUMPSTART_GATED_ROLE_NAME = \"JumpstartGatedRole-\" + HP_CLUSTER_ID\n",
    "FSX_CSI_ROLE_NAME = \"FSxCSIDriverFullAccess-\" + HP_CLUSTER_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec7d7a-7bab-439d-b688-a03edd96c811",
   "metadata": {},
   "source": [
    "### 2.2 Install dependencies \n",
    "\n",
    "Following script downloads and installs Helm, Kubectl and Eksctl if not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/aws/sagemaker-hyperpod-cli.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387e9f0-abf7-4510-8f4d-238f0c42a27b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!chmod +x sagemaker-hyperpod-cli/helm_chart/install_dependencies.sh\n",
    "!./sagemaker-hyperpod-cli/helm_chart/install_dependencies.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcde63eb-516f-4fdd-8697-5825d4ae00a1",
   "metadata": {},
   "source": [
    "## 3.0 Connect to your EKS Cluster (via kubeconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "241e0df1-0399-474b-9f23-19858f532d3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated context arn:aws:eks:us-east-1:434444145045:cluster/modelhub16-eks in /home/ubuntu/.kube/config\n"
     ]
    }
   ],
   "source": [
    "!aws eks update-kubeconfig --name \"$EKS_CLUSTER_NAME\" --region \"$REGION\" --output json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ce108-4017-4c41-819c-a937230dafb2",
   "metadata": {},
   "source": [
    "### 3.1 Confirm Successful Connection to Cluster\n",
    "\n",
    "The below commands should not show any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b52b2da0-8ab4-4154-a6aa-f2a0e9691960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"UserId\": \"AROAWKJXDSGK5D7ZWT4CB:i-0097bd29342c267b7\",\n",
      "    \"Account\": \"434444145045\",\n",
      "    \"Arn\": \"arn:aws:sts::434444145045:assumed-role/admin_role_for_workshop/i-0097bd29342c267b7\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!aws sts get-caller-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c66b05-4888-4a02-bd55-23369b040d57",
   "metadata": {},
   "source": [
    "# create-access-entry\n",
    "\n",
    "For access to EKS cluster with the role above\n",
    "\n",
    "Go to EKS console and select the cluster you are using.\n",
    "Note: The correlated EKS cluster name is shown in the output of the above cell.\n",
    "Look in the \"Access\" tab and select \"IAM Access Entries\"\n",
    "If there is not an entry for your execution role:\n",
    "Select \"Create Access Entry\"\n",
    "Select the desired execution role and correlate the AmazonEKSClusterAdminPolicy with the role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d59456-8bb1-489c-8414-205d73b6af89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:eks:us-east-1:434444145045:cluster/modelhub16-eks\n",
      "NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\n",
      "kubernetes   ClusterIP   172.20.0.1   <none>        443/TCP   5d2h\n"
     ]
    }
   ],
   "source": [
    "!kubectl config current-context\n",
    "!kubectl get svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d53b633-4cfb-4572-8922-9add63d7dc67",
   "metadata": {},
   "source": [
    "### 3.2 Associate IAM OIDC Provider with EKS Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6810f33a-1db5-423f-8aef-81392e61cebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6n\u001b[36m2026-01-12 13:16:32 [ℹ]  IAM Open ID Connect provider is already associated with cluster \"modelhub16-eks\" in \"us-east-1\"\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!eksctl utils associate-iam-oidc-provider --cluster $EKS_CLUSTER_NAME --region $REGION --approve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6615049e-2589-4aaf-ac06-94d3ac355687",
   "metadata": {},
   "source": [
    "## 4.0 Load balancer controller installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cf4dab-3637-467c-a844-60d9ee61ba60",
   "metadata": {},
   "source": [
    "### 4.1 Create IAM Policy for AWSLoadBalancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "637608ac-e277-4319-b122-890ef3601707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  8955  100  8955    0     0   118k      0 --:--:-- --:--:-- --:--:--  119k\n",
      "{\n",
      "    \"Policy\": {\n",
      "        \"PolicyName\": \"LBControllerPolicy-900cf50a76f6418e83aa1feb1de238b1\",\n",
      "        \"PolicyId\": \"ANPAWKJXDSGKS3MCLW74M\",\n",
      "        \"Arn\": \"arn:aws:iam::434444145045:policy/LBControllerPolicy-900cf50a76f6418e83aa1feb1de238b1\",\n",
      "        \"Path\": \"/\",\n",
      "        \"DefaultVersionId\": \"v1\",\n",
      "        \"AttachmentCount\": 0,\n",
      "        \"PermissionsBoundaryUsageCount\": 0,\n",
      "        \"IsAttachable\": true,\n",
      "        \"CreateDate\": \"2026-01-12T13:16:41+00:00\",\n",
      "        \"UpdateDate\": \"2026-01-12T13:16:41+00:00\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -o /tmp/AWSLoadBalancerControllerIAMPolicy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.13.0/docs/install/iam_policy.json\n",
    "!aws iam create-policy --policy-name $LB_CONTROLLER_POLICY_NAME --policy-document file:///tmp/AWSLoadBalancerControllerIAMPolicy.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68318538-ceca-4e1e-9f26-30cdef7adeb4",
   "metadata": {},
   "source": [
    "### 4.2 Create the AWSLoadBalancer Service Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d07835-2443-408c-b19c-34cf9cbbb29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6n\u001b[36m2026-01-12 13:16:54 [ℹ]  1 existing iamserviceaccount(s) (kube-system/aws-load-balancer-controller) will be excluded\n",
      "\u001b[0m\u001b[36m2026-01-12 13:16:54 [ℹ]  1 iamserviceaccount (kube-system/aws-load-balancer-controller) was excluded (based on the include/exclude rules)\n",
      "\u001b[0m\u001b[32m2026-01-12 13:16:54 [!]  metadata of serviceaccounts that exist in Kubernetes will be updated, as --override-existing-serviceaccounts was set\n",
      "\u001b[0m\u001b[36m2026-01-12 13:16:54 [ℹ]  no tasks\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "query = \"'Policies[?PolicyName==`\" + LB_CONTROLLER_POLICY_NAME + \"`].Arn'\"\n",
    "policy_arn_list=!(aws iam list-policies --query $query --output text)\n",
    "\n",
    "policy_arn=policy_arn_list[0]\n",
    "\n",
    "!eksctl create iamserviceaccount \\\n",
    "    --approve \\\n",
    "    --override-existing-serviceaccounts \\\n",
    "    --name= \"aws-load-balancer-controller\" \\\n",
    "    --namespace=kube-system \\\n",
    "    --cluster=$EKS_CLUSTER_NAME \\\n",
    "    --attach-policy-arn=$policy_arn \\\n",
    "    --region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e5390-cd42-434c-acd0-25ee3ec454e4",
   "metadata": {},
   "source": [
    "### 4.3 Apply Tags to all Subnets in your EKS Cluster (public and private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d892c8-8686-4e82-8995-d755d2176863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied tags to following subnets\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "filters = \"'[{\\\"Name\\\":\\\"vpc-id\\\", \\\"Values\\\": [\\\"\" + VPC_ID + \"\\\"]}, {\\\"Name\\\":\\\"map-public-ip-on-launch\\\", \\\"Values\\\":[\\\"true\\\"]}]'\"\n",
    "subnets = !(aws ec2 describe-subnets --filters $filters --output json | jq '.Subnets[]' | jq --raw-output '.SubnetId')\n",
    "!echo \"Applied tags to following subnets\"\n",
    "!echo $subnets\n",
    "for subnet in subnets:\n",
    "    !(aws ec2 create-tags --resources $subnet --tags Key=kubernetes.io/role/elb,Value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7232c7-7ab0-45db-b114-f81fe9e78ec8",
   "metadata": {},
   "source": [
    "## 5.0 Namespace creation\n",
    "\n",
    "\n",
    "### 5.1 KEDA Controller Namespace Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "350cf8cd-bc16-46ed-8f67-9b8271a541d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): namespaces \"keda\" already exists\n"
     ]
    }
   ],
   "source": [
    "!kubectl create namespace keda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1721a935-13dc-4397-846a-f0af99aed91d",
   "metadata": {},
   "source": [
    "### 5.2 Cert Manager Namespace Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "581a1817-3f95-4145-a68b-30b8e1105e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): namespaces \"cert-manager\" already exists\n"
     ]
    }
   ],
   "source": [
    "!kubectl create namespace cert-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b758eb-1074-449d-8f30-17cedd45e8f4",
   "metadata": {},
   "source": [
    "### 5.3 Endpoint creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdbaa05a-6c78-4889-9380-bfcb582768d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils.capture import capture_output\n",
    "\n",
    "with capture_output() as c:\n",
    "    !(aws ec2 describe-route-tables --region $REGION --filters \"Name=vpc-id,Values=$VPC_ID\" --query 'RouteTables[].Associations[].RouteTableId' | jq 'unique' | jq -r 'join (\" \")')\n",
    "ROUTE_TABLE_IDS = c.stdout.strip()\n",
    "\n",
    "SERVICE_NAME=\"com.amazonaws.\" + REGION + \".s3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If vpc endpoint is already created via cloudformation, then remove it\n",
    "import time\n",
    "import subprocess\n",
    "from IPython.utils.capture import capture_output\n",
    "\n",
    "# Check for existing endpoint with corrected query\n",
    "with capture_output() as c:\n",
    "    !(aws ec2 describe-vpc-endpoints \\\n",
    "        --region \"$REGION\" \\\n",
    "        --filters \"Name=vpc-id,Values=$VPC_ID\" \"Name=service-name,Values=$SERVICE_NAME\" \\\n",
    "        --query 'VpcEndpoints[?State!=`deleted`].[VpcEndpointId]' \\\n",
    "        --output text)\n",
    "EXISTING_ENDPOINT = c.stdout.strip()\n",
    "\n",
    "# If endpoint exists and is not empty/None and only delete S3 VPC endpoint , delete it\n",
    "if EXISTING_ENDPOINT and EXISTING_ENDPOINT != \"None\" and \"s3\" in SERVICE_NAME.lower():\n",
    "    print(\"Found existing endpoint, showing details:\")\n",
    "    !(aws ec2 describe-vpc-endpoints --vpc-endpoint-ids \"$EXISTING_ENDPOINT\" --region \"$REGION\")\n",
    "\n",
    "    # Delete the VPC endpoint\n",
    "    !aws ec2 delete-vpc-endpoints --vpc-endpoint-ids {EXISTING_ENDPOINT} --region {REGION}\n",
    "\n",
    "    # Wait until the endpoint is fully deleted\n",
    "    print(\"Waiting for VPC endpoint to be deleted...\")\n",
    "    SLEEP_INTERVAL = 5\n",
    "    while True:\n",
    "        result = subprocess.run(\n",
    "            [\"aws\", \"ec2\", \"describe-vpc-endpoints\", \"--vpc-endpoint-ids\", EXISTING_ENDPOINT, \"--region\", REGION],\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "        )\n",
    "        if result.returncode != 0:\n",
    "            break\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(SLEEP_INTERVAL)\n",
    "    print(f\"VPC endpoint '{EXISTING_ENDPOINT}' has been successfully deleted.\")\n",
    "else:\n",
    "    print(\"No existing endpoint found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1803b8-de49-464a-83c2-76b9f0d70201",
   "metadata": {},
   "outputs": [],
   "source": [
    "!(aws ec2 create-vpc-endpoint --vpc-id $VPC_ID --vpc-endpoint-type \"Gateway\" --service-name $SERVICE_NAME --route-table-ids $ROUTE_TABLE_IDS --region $REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad09362-fdc1-4b13-aa9a-ba975edd8d12",
   "metadata": {},
   "source": [
    "## 6.0 S3 CSI driver installation\n",
    "\n",
    "Setup Role for S3 Mountpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf0973-2244-4968-9e5f-4593587f68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$S3_MOUNT_ACCESS_POLICY_NAME\"\n",
    "\n",
    "cat <<EOF> /tmp/s3-role-policy.json\n",
    "{\n",
    "   \"Version\": \"2012-10-17\",\n",
    "   \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"MountpointFullBucketAccess\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                    \"arn:aws:s3:::*\",\n",
    "                    \"arn:aws:s3:::*/*\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"MountpointFullObjectAccess\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:AbortMultipartUpload\",\n",
    "                \"s3:DeleteObject\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                    \"arn:aws:s3:::*\",\n",
    "                    \"arn:aws:s3:::*/*\"\n",
    "            ]\n",
    "        }\n",
    "   ]\n",
    "}\n",
    "EOF\n",
    "\n",
    "aws iam create-policy --policy-name $1 --policy-document file:///tmp/s3-role-policy.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd14fc-3b54-470a-a56b-08a5ece2b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"'Policies[?PolicyName==`\" + S3_MOUNT_ACCESS_POLICY_NAME + \"`].Arn'\"\n",
    "S3_MOUNT_POLICY_ARN_LIST=!(aws iam list-policies --query $query)\n",
    "S3_MOUNT_POLICY_ARN = S3_MOUNT_POLICY_ARN_LIST[1].strip()\n",
    "\n",
    "print(S3_MOUNT_POLICY_ARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abeb6bc-8a46-480b-9b6f-42d38acdfe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!eksctl create iamserviceaccount \\\n",
    "    --name s3-csi-driver-sa \\\n",
    "    --override-existing-serviceaccounts \\\n",
    "    --namespace kube-system \\\n",
    "    --cluster $EKS_CLUSTER_NAME \\\n",
    "    --attach-policy-arn $S3_MOUNT_POLICY_ARN \\\n",
    "    --approve \\\n",
    "    --role-name $S3_CSI_ROLE_NAME \\\n",
    "    --region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7f989-b3f5-49aa-9f3f-82529426a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl label serviceaccount s3-csi-driver-sa app.kubernetes.io/component=csi-driver app.kubernetes.io/instance=aws-mountpoint-s3-csi-driver app.kubernetes.io/managed-by=EKS app.kubernetes.io/name=aws-mountpoint-s3-csi-driver -n kube-system --overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac86214-ca54-4530-b700-2fb542e87e4a",
   "metadata": {},
   "source": [
    "## 6.0.1 Keda operator role creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff16e7-2d06-48ce-8b7e-68f5fce5d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "OIDC_ID = !aws eks describe-cluster --name $EKS_CLUSTER_NAME --query \"cluster.identity.oidc.issuer\" --output text | cut -d '/' -f 5\n",
    "OIDC_ID = OIDC_ID[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8464ed5-29ae-4c5c-9680-d15d6e629252",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$REGION\" \"$OIDC_ID\" \"$ACCOUNT_ID\" \"$KEDA_OPERATOR_POLICY_NAME\" \"$KEDA_OPERATOR_ROLE_NAME\"\n",
    "\n",
    "REGION=$1\n",
    "OIDC_ID=$2\n",
    "ACCOUNT_ID=$3\n",
    "KEDA_OPERATOR_POLICY_NAME=$4\n",
    "KEDA_OPERATOR_ROLE_NAME=$5\n",
    "\n",
    "# Create trust policy\n",
    "cat <<EOF > /tmp/keda-trust-policy.json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Federated\": \"arn:aws:iam::$ACCOUNT_ID:oidc-provider/oidc.eks.$REGION.amazonaws.com/id/$OIDC_ID\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n",
    "            \"Condition\": {\n",
    "                \"StringLike\": {\n",
    "                    \"oidc.eks.$REGION.amazonaws.com/id/$OIDC_ID:sub\": \"system:serviceaccount:kube-system:keda-operator\",\n",
    "                    \"oidc.eks.$REGION.amazonaws.com/id/$OIDC_ID:aud\": \"sts.amazonaws.com\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "EOF\n",
    " \n",
    "# Create permissions policy\n",
    "cat <<EOF > /tmp/keda-policy.json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"cloudwatch:GetMetricData\",\n",
    "                \"cloudwatch:GetMetricStatistics\",\n",
    "                \"cloudwatch:ListMetrics\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"aps:QueryMetrics\",\n",
    "                \"aps:GetLabels\",\n",
    "                \"aps:GetSeries\",\n",
    "                \"aps:GetMetricMetadata\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "EOF\n",
    " \n",
    "# Create the role\n",
    "aws iam create-role \\\n",
    "    --role-name $KEDA_OPERATOR_ROLE_NAME \\\n",
    "    --assume-role-policy-document file:///tmp/keda-trust-policy.json\n",
    " \n",
    "# Create the policy\n",
    "POLICY_ARN=$(aws iam create-policy \\\n",
    "    --policy-name $KEDA_OPERATOR_POLICY_NAME \\\n",
    "    --policy-document file:///tmp/keda-policy.json \\\n",
    "    --query 'Policy.Arn' \\\n",
    "    --output text)\n",
    " \n",
    "# Attach the policy to the role\n",
    "aws iam attach-role-policy \\\n",
    "    --role-name $KEDA_OPERATOR_ROLE_NAME \\\n",
    "    --policy-arn $POLICY_ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174297d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $REGION $PRESIGNED_URL_ACCESS_POLICY_NAME\n",
    "\n",
    "cat <<EOF> /tmp/presignedurl-policy.json\n",
    "{\n",
    "   \"Version\": \"2012-10-17\",\n",
    "   \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"CreatePresignedUrlAccess\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"sagemaker:CreateHubContentPresignedUrls\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:sagemaker:$1:aws:hub/SageMakerPublicHub\", \n",
    "                \"arn:aws:sagemaker:$1:aws:hub-content/SageMakerPublicHub/*/*\" \n",
    "            ]\n",
    "        }\n",
    "   ]\n",
    "}\n",
    "EOF\n",
    "\n",
    "aws iam create-policy --policy-name \"$2\" --policy-document file:///tmp/presignedurl-policy.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9937fd8f-b14e-44e7-a5fe-bb86f1ead2df",
   "metadata": {},
   "source": [
    "## 7.0 Create execution role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11707632-006a-43a1-ad3d-e80d48d42840",
   "metadata": {},
   "source": [
    "#### 7.1.2 Import the Hyperpod Inference Access Policy to IAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1751d18-734b-466d-8571-1482a2edc17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws iam create-policy --policy-name $HYPERPOD_INFERENCE_ACCESS_POLICY_NAME --policy-document file://inference-resources/hyperpod_inference_operator_policy.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa29251-d2f0-4138-9331-e265952a0aff",
   "metadata": {},
   "source": [
    "#### 7.1.3 Create an IAM role with the Hyperpod Inference Access Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f847133-8feb-453e-abf1-f77588d5582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"'Policies[?PolicyName==`\" + HYPERPOD_INFERENCE_ACCESS_POLICY_NAME + \"`].Arn'\"\n",
    "policy_arn_list=!(aws iam list-policies --query $query --output text)\n",
    "policy_arn=policy_arn_list[0]\n",
    "\n",
    "# Create the IAM role\n",
    "!eksctl create iamserviceaccount --approve --role-only --name=$HYPERPOD_INFERENCE_SA_NAME --namespace=$HYPERPOD_INFERENCE_SA_NAMESPACE --cluster=$EKS_CLUSTER_NAME --attach-policy-arn=$policy_arn --role-name=$HYPERPOD_INFERENCE_ROLE_NAME --region=$REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c3b199-5c22-4577-ba88-c1eff32ff883",
   "metadata": {},
   "source": [
    "### 7.2 Presigned URL support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c77951-33ee-472f-9a9e-4d6e0f72182d",
   "metadata": {},
   "source": [
    "#### 7.2.1 Create role for jumpstart gated model (Optional only for jumpstart gated model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6f407-2134-4800-8148-5232b15344ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "JUMPSTART_GATED_ROLE_NAME=f\"JumpstartGatedRole-{REGION}-{HP_CLUSTER_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1edb150-a70c-4778-ba02-e27ecce0419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$REGION\" \"$OIDC_ID\" \"$ACCOUNT_ID\" \"$JUMPSTART_GATED_ROLE_NAME\" \"$PRESIGNED_URL_ACCESS_POLICY_NAME\"\n",
    "\n",
    "REGION=$1\n",
    "OIDC_ID=$2\n",
    "ACCOUNT_ID=$3\n",
    "JUMPSTART_GATED_ROLE_NAME=$4\n",
    "PRESIGNED_URL_ACCESS_POLICY_NAME=$5\n",
    "\n",
    "# Create trust policy\n",
    "cat <<EOF > /tmp/trust-policy.json\n",
    "{\n",
    "\t\"Version\": \"2012-10-17\",\n",
    "\t\"Statement\": [\n",
    "\t\t{\n",
    "\t\t\t\"Effect\": \"Allow\",\n",
    "\t\t\t\"Principal\": {\n",
    "\t\t\t\t\"Federated\": \"arn:aws:iam::$ACCOUNT_ID:oidc-provider/oidc.eks.$REGION.amazonaws.com/id/$OIDC_ID\"\n",
    "\t\t\t},\n",
    "\t\t\t\"Action\": \"sts:AssumeRoleWithWebIdentity\",\n",
    "\t\t\t\"Condition\": {\n",
    "\t\t\t\t\"StringLike\": {\n",
    "\t\t\t\t\t\"oidc.eks.$REGION.amazonaws.com/id/$OIDC_ID:sub\": \"system:serviceaccount:*:hyperpod-inference-service-account\",\n",
    "\t\t\t\t\t\"oidc.eks.$REGION.amazonaws.com/id/$OIDC_ID:aud\": \"sts.amazonaws.com\"\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t]\n",
    "}\n",
    "EOF\n",
    "\n",
    "# Create the role using existing trust policy\n",
    "aws iam create-role \\\n",
    "    --role-name $JUMPSTART_GATED_ROLE_NAME \\\n",
    "    --assume-role-policy-document file:///tmp/trust-policy.json\n",
    "\n",
    "# Attach the existing PresignedUrlAccessPolicy to the role\n",
    "aws iam attach-role-policy \\\n",
    "    --role-name $JUMPSTART_GATED_ROLE_NAME \\\n",
    "    --policy-arn arn:aws:iam::${ACCOUNT_ID}:policy/$PRESIGNED_URL_ACCESS_POLICY_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc1538-2e3b-45f6-85ab-5f66d4253b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "JUMPSTART_GATED_ROLE_ARN_LIST= !aws iam get-role --role-name=$JUMPSTART_GATED_ROLE_NAME --query \"Role.Arn\" --output text\n",
    "JUMPSTART_GATED_ROLE_ARN = JUMPSTART_GATED_ROLE_ARN_LIST[0]\n",
    "!echo $JUMPSTART_GATED_ROLE_ARN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f83d013-3263-40a8-9235-bda7f2952d37",
   "metadata": {},
   "source": [
    "#### 7.2.2 Update the Trust Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455178d-ef14-4f05-bf24-a263aebbbad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$HYPERPOD_INFERENCE_ROLE_NAME\" \"$HYPERPOD_INFERENCE_SA_NAMESPACE\" \"$HYPERPOD_INFERENCE_SA_NAME\"\n",
    "\n",
    "cat <<EOF> hyperpod_inference_additional_trust_statement.txt\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"sagemaker.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        },\n",
    "EOF\n",
    "\n",
    "aws iam get-role --role-name=$1 --query \"Role\".\"AssumeRolePolicyDocument\" > hyperpod_inference_trust_policy.json\n",
    "if [[ $(diff hyperpod_inference_additional_trust_statement.txt hyperpod_inference_trust_policy.json | grep '^<' -) ]]; then\n",
    "    echo Trust policy missing some permissions. Updating with the permissions above.\n",
    "    { head -n3 hyperpod_inference_trust_policy.json && cat hyperpod_inference_additional_trust_statement.txt && tail -n+4 hyperpod_inference_trust_policy.json; } > /tmp/updated_hyperpod_inference_trust_policy.json\n",
    "    # Also allow any service account to AssumeRoleWithWebIdentity\n",
    "    sed -i '0,/\"StringEquals\": {/{s//\"StringLike\": {/}' /tmp/updated_hyperpod_inference_trust_policy.json\n",
    "    sed -i \"0,/:sub\\\": \\\"system:serviceaccount:${2}:${3}\\\"/{s//:sub\\\": \\\"system:serviceaccount:*:*\\\"/}\" /tmp/updated_hyperpod_inference_trust_policy.json\n",
    "    aws iam update-assume-role-policy --role-name=$1 --policy-document=file:///tmp/updated_hyperpod_inference_trust_policy.json\n",
    "else\n",
    "    echo Trust policy contains all necessary permissions.\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdd54ce-6e28-4c17-8d11-5346387a28c7",
   "metadata": {},
   "source": [
    "### 7.4 Get role arns to be used during installation of operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3133a38-3b59-4b04-af50-8440d9bffba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPOD_INFERENCE_ROLE_ARN_list= !(aws iam get-role --role-name=$HYPERPOD_INFERENCE_ROLE_NAME --query \"Role.Arn\" --output text)\n",
    "HYPERPOD_INFERENCE_ROLE_ARN = HYPERPOD_INFERENCE_ROLE_ARN_list[0]\n",
    "!echo $HYPERPOD_INFERENCE_ROLE_ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189f47e-6860-4c06-8420-0295881b72c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_CSI_ROLE_ARN_LIST= !aws iam get-role --role-name=$S3_CSI_ROLE_NAME --query \"Role.Arn\" --output text\n",
    "S3_CSI_ROLE_ARN = S3_CSI_ROLE_ARN_LIST[0]\n",
    "!echo $S3_CSI_ROLE_ARN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad6ff27-0ac8-443c-b805-fb3ed5abb18c",
   "metadata": {},
   "source": [
    "## 8.0 Install operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a35b2-86cb-41c6-8103-15b8779af71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HELM_CMD=\"helm install hyperpod-inference-operator ./sagemaker-hyperpod-cli/helm_chart/HyperPodHelmChart/charts/inference-operator \\\n",
    "     -n kube-system \\\n",
    "     --set region=\" + REGION + \" \\\n",
    "     --set eksClusterName=\" + EKS_CLUSTER_NAME + \" \\\n",
    "     --set hyperpodClusterArn=\" + HP_CLUSTER_ARN + \" \\\n",
    "     --set executionRoleArn=\" + HYPERPOD_INFERENCE_ROLE_ARN + \" \\\n",
    "     --set s3.serviceAccountRoleArn=\" + S3_CSI_ROLE_ARN + \" \\\n",
    "     --set s3.node.serviceAccount.create=false \\\n",
    "     --set keda.podIdentity.aws.irsa.roleArn=\\\"arn:aws:iam::\" + ACCOUNT_ID + \":role/keda-operator-role\\\" \\\n",
    "     --set tlsCertificateS3Bucket=\" + TLS_BUCKET_NAME + \" \\\n",
    "     --set alb.region=\" + REGION + \" \\\n",
    "     --set alb.clusterName=\" + EKS_CLUSTER_NAME + \" \\\n",
    "     --set alb.vpcId=\" + VPC_ID + \" \\\n",
    "     --set jumpstartGatedModelDownloadRoleArn=\" + JUMPSTART_GATED_ROLE_ARN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f453486-c84d-4e4f-a772-8e122d563c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $HELM_CMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f69ef-51e4-4873-a10c-7b4672e1acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm dependencies update sagemaker-hyperpod-cli/helm_chart/HyperPodHelmChart/charts/inference-operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac72d84-499e-4d79-97c2-1c213f656237",
   "metadata": {},
   "outputs": [],
   "source": [
    "!eval $HELM_CMD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27acf468-661f-4169-b43f-d39473d95b6f",
   "metadata": {},
   "source": [
    "## 9.0 FSx CSI service account update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1f262-b70e-4eaf-a667-b136c4c8a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    " !eksctl create iamserviceaccount \\\n",
    "       --name fsx-csi-controller-sa \\\n",
    "       --override-existing-serviceaccounts \\\n",
    "       --namespace kube-system \\\n",
    "       --cluster $EKS_CLUSTER_NAME \\\n",
    "       --attach-policy-arn arn:aws:iam::aws:policy/AmazonFSxFullAccess \\\n",
    "       --role-name $FSX_CSI_ROLE_NAME \\\n",
    "       --approve \\\n",
    "       --region $REGION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce9a4c",
   "metadata": {},
   "source": [
    "## 10.0 KV Cache and Intelligent Routing Deployment\n",
    "\n",
    "This section provides a complete example of deploying an inference endpoint with KV caching and intelligent routing capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-prereq",
   "metadata": {},
   "source": [
    "### 10.1 Prerequisites for Endpoint Deployment\n",
    "\n",
    "Before proceeding with the deployment, ensure your environment meets the following requirements:\n",
    "\n",
    "- **AWS CLI**: Configured with appropriate IAM permissions for EKS, S3, and SageMaker operations\n",
    "- **kubectl**: Properly configured to communicate with your target EKS cluster\n",
    "- **Helm**: Helm installed for managing Kubernetes applications\n",
    "- **Repository Access**: Clone the SageMaker HyperPod CLI repository from GitHub\n",
    "- **Model Access**: Valid Hugging Face token for accessing gated models \n",
    "\n",
    "Verify your cluster has sufficient instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80610a0",
   "metadata": {},
   "source": [
    "a) Begin by cloning the repository and navigating to the inference operator directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44062746",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/aws/sagemaker-hyperpod-cli.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ba306",
   "metadata": {},
   "source": [
    "b) Determine the namespace of the 'hyperpod-inference-operator' Helm deployment. More often than not this should be 'kube-system'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b025f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperpod-inference-operator\tkube-system\t1       \t2026-01-07 11:03:30.304922715 +0000 UTC\tdeployed\thyperpod-inference-operator-1.1.0\t2.1        \n"
     ]
    }
   ],
   "source": [
    "!helm list -A | grep hyperpod-inference-operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13021099",
   "metadata": {},
   "source": [
    "c) Pipe the values used for setup for an existing cluster to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm get values -n $DEPLOYMENT_NAMESPACE hyperpod-inference-operator -o yaml > $DESIRED_FILE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4099df8b",
   "metadata": {},
   "source": [
    "d) Run 'helm upgrade' using the existing values and the force flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-helm-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm dependency update sagemaker-hyperpod-cli/helm_chart/HyperPodHelmChart/charts/inference-operator/\n",
    "\n",
    "!helm upgrade -n $DEPLOYMENT_NAMESPACE hyperpod-inference-operator sagemaker-hyperpod-cli/helm_chart/HyperPodHelmChart/charts/inference-operator/ -f $DESIRED_FILE_PATH --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-s3-upload",
   "metadata": {},
   "source": [
    "### 10.2 S3 Model Upload\n",
    "\n",
    "We are using Llama-3.1-8B-Instruct. Obtain the model from Hugging Face (authentication may be required for gated models)\n",
    "and ensure the model directory structure includes all necessary files.\n",
    "After downloading, upload the complete model directory to your S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-s3-commands",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the entire model directory to S3\n",
    "!aws s3 cp <your-model-file> <s3://bucket-name/path/>\n",
    "\n",
    "# Verify upload completed\n",
    "!aws s3 ls s3://your-bucket-name/models/Llama-3.1-8B-Instruct/ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-upload-complete",
   "metadata": {},
   "source": [
    "\n",
    "After the model upload is complete and you've verified all files are accessible in S3, proceed with endpoint creation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-config-instructions",
   "metadata": {},
   "source": [
    "### 10.3 Create an Endpoint\n",
    "Specify the name and namespace of the endpoint in the metadata section.\n",
    "Specify your S3 bucketname, region and S3 Uri based on where the model location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-endpoint-yaml",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%` not found.\n"
     ]
    }
   ],
   "source": [
    "%% endpoint-config.yaml\n",
    "apiVersion: inference.sagemaker.aws.amazon.com/v1\n",
    "kind: InferenceEndpointConfig\n",
    "metadata:\n",
    "  name: demo\n",
    "  namespace: default\n",
    "spec:\n",
    "  endpointName: demo-l2-cache   #include endpoint name\n",
    "  modelName: Qwen3-4B-Instruct   #include model name \n",
    "  instanceType: ml.g5.4xlarge          #include desired instance type\n",
    "  invocationEndpoint: v1/chat/completions\n",
    "  replicas: 1\n",
    "  modelSourceConfig:\n",
    "    modelSourceType: s3\n",
    "    s3Storage:\n",
    "      bucketName: sagemaker-us-east-1-434444145045  #include your bucket name\n",
    "      region: us-east-1                  #include your region\n",
    "    modelLocation: s3://sagemaker-us-east-1-434444145045/Qwen3-4B-Instruct-2507/0d0f748bad7a4aa7a3cae5ec42bb4553/finetuned_model_merged/   #include model location \n",
    "    prefetchEnabled: false\n",
    "  kvCacheSpec:\n",
    "    enableL1Cache: true\n",
    "    enableL2Cache: true\n",
    "    l2CacheSpec:\n",
    "     l2CacheBackend: tieredstorage\n",
    "  intelligentRoutingSpec:\n",
    "    enabled: true\n",
    "    routingStrategy: prefixaware\n",
    "  tlsConfig:\n",
    "    tlsCertificateOutputS3Uri: s3://llm-modelhub-hyperpod-434444145045-us-east-1/cert   #include your S3URI\n",
    "  metrics:\n",
    "    enabled: true\n",
    "    modelMetrics:\n",
    "      port: 8000\n",
    "  loadBalancer:\n",
    "    healthCheckPath: /health\n",
    "  worker:\n",
    "    resources:\n",
    "      limits:\n",
    "        nvidia.com/gpu: \"1\"\n",
    "      requests:\n",
    "        cpu: \"6\"\n",
    "        memory: 30Gi\n",
    "        nvidia.com/gpu: \"1\"\n",
    "    image: public.ecr.aws/deep-learning-containers/vllm:0.13.0-gpu-py312-cu129-ubuntu22.04-ec2-v1.0\n",
    "    args:\n",
    "      - \"/opt/ml/model\"\n",
    "      - \"--max-model-len\"\n",
    "      - \"20000\"\n",
    "      - \"--tensor-parallel-size\"\n",
    "      - \"1\"\n",
    "    modelInvocationPort:\n",
    "      containerPort: 8000\n",
    "      name: http\n",
    "    modelVolumeMount:\n",
    "      name: model-weights\n",
    "      mountPath: /opt/ml/model\n",
    "    environmentVariables:\n",
    "      - name: PYTHONHASHSEED\n",
    "        value: \"123\"\n",
    "      - name: OPTION_ROLLING_BATCH\n",
    "        value: \"vllm\"\n",
    "      - name: SAGEMAKER_SUBMIT_DIRECTORY\n",
    "        value: \"/opt/ml/model/code\"\n",
    "      - name: MODEL_CACHE_ROOT\n",
    "        value: \"/opt/ml/model\"\n",
    "      - name: SAGEMAKER_MODEL_SERVER_WORKERS\n",
    "        value: \"1\"\n",
    "      - name: SAGEMAKER_MODEL_SERVER_TIMEOUT\n",
    "        value: \"3600\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-intelligent-routing",
   "metadata": {},
   "source": [
    "#### 10.3.1 Enable Intelligent Routing\n",
    "If you want to enable intelligent routing, you can do that by making the intelligentRoutingSpec as true and you can disable it by marking it false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-routing-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "intelligentRoutingSpec:\n",
    "    enabled: true  #CHANGE HERE\n",
    "    routingStrategy: prefixaware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0476def",
   "metadata": {},
   "source": [
    "##### 10.3.1.1 Change the Routing Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417b8aaa",
   "metadata": {},
   "source": [
    "The intelligent routing system supports four different strategies that can be configured based on your requirements: \"prefixaware\", \"kvaware\", \"session\" , and \"roundrobin\".\n",
    "\n",
    "* **Prefix-aware routing (default)**: Maintains a tree structure to track which prefixes are cached on which endpoints, making it effective for workloads with common prompt prefixes. While it provides good general-purpose performance, it cannot detect when cache entries are evicted from workers, potentially leading to suboptimal routing decisions.\n",
    "* **Round-robin routing**: It is the most straightforward approach, which brute-force distributes requests evenly across all available workers. While simple to implement, it doesn't optimize for cache reuse and is best suited for scenarios where requests are independent and cache sharing isn't critical.\n",
    "* **Session-based routing**: Ensures requests from the same session are consistently routed to the same worker, making it ideal for maintaining conversation context in chatbot applications. However, it limits cache sharing opportunities across different sessions, potentially leading to redundant cache entries across workers.\n",
    "* **KV-aware routing**: Offers the most sophisticated cache management by using a centralized controller to track cache locations and handle cache eviction events. However, it requires tokenizing prompts in the router and currently only supports Hugging Face models. This strategy is best when precise cache control is needed and these limitations are acceptable.\n",
    "\n",
    "This can be done using the \"routingStrategy\" parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "intelligentRoutingSpec:\n",
    "    enabled: true  \n",
    "    routingStrategy: prefixaware  #CHANGE HERE- \"prefixaware\", \"kvaware\", \"session\" , and \"roundrobin\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd64bb6f",
   "metadata": {},
   "source": [
    "For \"session\" and \"kvaware\" routing strategies, you can customize the session identifier by adding a \"SESSION_KEY\" environment variable to your endpoint configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceaf27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "environmentVariables:\n",
    "  - name: SESSION_KEY           \n",
    "    value: \"user_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de06b60",
   "metadata": {},
   "source": [
    "#### 10.3.2 Enable L1 Cache\n",
    "\n",
    "**L1 Cache**: Local CPU memory cache on each node for fastest access to recently computed key-value pairs.\n",
    "\n",
    "If you want to enable L1 cache, you can do that by making the kvCacheSpec true and you can disable it by marking it false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-cache-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "kvCacheSpec:\n",
    "    enableL1Cache: true  #CHANGE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b35f6b",
   "metadata": {},
   "source": [
    "#### 10.3.3 Enable L2 Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d67ff7",
   "metadata": {},
   "source": [
    "**L2Cache**: Remote storage like Redis that enables offloading intermediate states across multiple nodes for shared access to key-value pairs.\n",
    "\n",
    "To enable L2 Cache functionality, ensure the Redis service is running and accessible on the configured port.\n",
    " \n",
    "**Important:** The Redis cluster must be deployed within the same VPC as your HyperPod cluster to ensure network connectivity and maintain data encryption in transit. Verify the Redis pod is running before creating the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3075048e",
   "metadata": {},
   "source": [
    "##### 10.3.3.1 redis.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: redis-config\n",
    "data:\n",
    "  redis.conf: |\n",
    "    # --- Memory ---\n",
    "    maxmemory 75gb\n",
    "    maxmemory-policy allkeys-lfu\n",
    "    # Pure cache mode\n",
    "    appendonly no\n",
    "    save \"\"\n",
    "\n",
    "    # --- Concurrency / networking ---\n",
    "    io-threads 8\n",
    "    io-threads-do-reads yes\n",
    "    tcp-backlog 65535\n",
    "    tcp-keepalive 300\n",
    "    timeout 0\n",
    "\n",
    "    # Protect server at high fan-in (slow consumers, giant replies)\n",
    "    client-output-buffer-limit normal 128mb 64mb 60\n",
    "    client-output-buffer-limit replica 256mb 64mb 60\n",
    "    client-output-buffer-limit pubsub 32mb 8mb 60\n",
    "    client-query-buffer-limit 256mb\n",
    "    proto-max-bulk-len 256mb\n",
    "\n",
    "    # Allow many clients (match to file-descriptor ulimit below)\n",
    "    maxclients 200000\n",
    "\n",
    "    # Misc latency hygiene\n",
    "    dynamic-hz yes\n",
    "    hz 100\n",
    "\n",
    "\n",
    "---\n",
    "# Or keep a standard ClusterIP if you prefer (comment one of the Services out)\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: redis\n",
    "spec:\n",
    "  selector:\n",
    "    app: redis\n",
    "  ports:\n",
    "  - name: redis\n",
    "    port: 6379\n",
    "    targetPort: 6379\n",
    "  type: ClusterIP\n",
    "\n",
    "---\n",
    "apiVersion: apps/v1\n",
    "kind: StatefulSet\n",
    "metadata:\n",
    "  name: redis\n",
    "spec:\n",
    "  serviceName: redis-headless\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels: { app: redis }\n",
    "  template:\n",
    "    metadata:\n",
    "      labels: { app: redis }\n",
    "      annotations:\n",
    "        # Skip service meshes/proxies if present\n",
    "        sidecar.istio.io/inject: \"false\"\n",
    "    spec:\n",
    "      # Fastest path (optional). Remove these two lines if you don't want host networking.\n",
    "      hostNetwork: true\n",
    "      dnsPolicy: ClusterFirstWithHostNet\n",
    "\n",
    "      # Keep Redis on beefy, quiet nodes\n",
    "      nodeSelector:\n",
    "        node.kubernetes.io/instance-type: ml.m5.24xlarge\n",
    "\n",
    "      # Prefer co-location policy (tweak to your topology/keyspace)\n",
    "      topologySpreadConstraints:\n",
    "      - maxSkew: 1\n",
    "        topologyKey: topology.kubernetes.io/zone\n",
    "        whenUnsatisfiable: ScheduleAnyway\n",
    "        labelSelector:\n",
    "          matchLabels:\n",
    "            app: redis\n",
    "\n",
    "      containers:\n",
    "      - name: redis\n",
    "        image: redis:7.2-alpine\n",
    "        imagePullPolicy: IfNotPresent\n",
    "        args: [\"redis-server\", \"/usr/local/etc/redis/redis.conf\"]\n",
    "        env:\n",
    "          - name: PYTHONHASHSEED\n",
    "            value: \"123\"\n",
    "        ports:\n",
    "        - containerPort: 6379\n",
    "          name: redis\n",
    "        resources:\n",
    "          # Reserve real cores; **omit CPU limits** to prevent throttling\n",
    "          requests:\n",
    "            cpu: \"32\"\n",
    "            memory: \"90Gi\"\n",
    "          # Remove limits entirely for best latency, or keep a high memory limit if you must\n",
    "          # limits:\n",
    "          #   memory: \"100Gi\"\n",
    "        readinessProbe:\n",
    "          tcpSocket: { port: 6379 }\n",
    "          initialDelaySeconds: 3\n",
    "          periodSeconds: 3\n",
    "        livenessProbe:\n",
    "          tcpSocket: { port: 6379 }\n",
    "          initialDelaySeconds: 10\n",
    "          periodSeconds: 10\n",
    "        volumeMounts:\n",
    "        - name: cfg\n",
    "          mountPath: /usr/local/etc/redis\n",
    "      volumes:\n",
    "      - name: cfg\n",
    "        configMap:\n",
    "          name: redis-config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151375c4",
   "metadata": {},
   "source": [
    "Apply the above file using kubectl apply, after the pod is running, we can start with enabling L2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2ae4f",
   "metadata": {},
   "source": [
    "##### 10.3.3.2 Enable L2 Cache Field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "enableL2Cache: true     #Change here\n",
    "l2CacheSpec:\n",
    "    l2CacheBackend: redis\n",
    "    l2CacheLocalUrl: redis://redis.default.svc.cluster.local:6379"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23638cc",
   "metadata": {},
   "source": [
    "The l2CacheLocalUrl mentioned above should follow this format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "<redis-service-name>.<namespace>.svc.cluster.local:6379"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-apply-file",
   "metadata": {},
   "source": [
    "### 10.4 Apply the File\n",
    "To apply the above file, use the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sample-kubectl-apply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenceendpointconfig.inference.sagemaker.aws.amazon.com/demo created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f endpoint-config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-view-pods",
   "metadata": {},
   "source": [
    "### 10.5 View the Pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sample-verify-commands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                      AGE\n",
      "demo                                      7m24s\n",
      "qwen3-4b-instruct-2507-2026-01-13-06-42   6m34s\n",
      "Name:         demo\n",
      "Namespace:    default\n",
      "Labels:       <none>\n",
      "Annotations:  <none>\n",
      "API Version:  inference.sagemaker.aws.amazon.com/v1\n",
      "Kind:         InferenceEndpointConfig\n",
      "Metadata:\n",
      "  Creation Timestamp:  2026-01-13T06:41:38Z\n",
      "  Finalizers:\n",
      "    inference.sagemaker.aws.InferenceEndpointConfigFinalizer\n",
      "    inference.sagemaker.aws.amazon.com/metrics-configmap\n",
      "  Generation:        2\n",
      "  Resource Version:  2552047\n",
      "  UID:               166060b7-96cc-49c7-8813-1da6158a2d0a\n",
      "Spec:\n",
      "  Auto Scaling Spec:\n",
      "    Cloud Watch Trigger:\n",
      "      Activation Target Value:       0\n",
      "      Metric Collection Period:      300\n",
      "      Metric Collection Start Time:  300\n",
      "      Metric Stat:                   Average\n",
      "      Metric Type:                   Average\n",
      "      Min Value:                     0\n",
      "      Use Cached Metrics:            true\n",
      "    Cooldown Period:                 300\n",
      "    Initial Cooldown Period:         300\n",
      "    Max Replica Count:               5\n",
      "    Min Replica Count:               1\n",
      "    Polling Interval:                30\n",
      "    Prometheus Trigger:\n",
      "      Activation Target Value:      0\n",
      "      Metric Type:                  Average\n",
      "      Use Cached Metrics:           true\n",
      "    Scale Down Stabilization Time:  300\n",
      "    Scale Up Stabilization Time:    0\n",
      "  Endpoint Name:                    demo-l2-cache\n",
      "  Instance Type:                    ml.g5.4xlarge\n",
      "  Intelligent Routing Spec:\n",
      "    Auto Scaling Spec:\n",
      "      Cloud Watch Trigger:\n",
      "        Activation Target Value:       0\n",
      "        Metric Collection Period:      300\n",
      "        Metric Collection Start Time:  300\n",
      "        Metric Stat:                   Average\n",
      "        Metric Type:                   Average\n",
      "        Min Value:                     0\n",
      "        Use Cached Metrics:            true\n",
      "      Cooldown Period:                 300\n",
      "      Initial Cooldown Period:         300\n",
      "      Max Replica Count:               5\n",
      "      Min Replica Count:               1\n",
      "      Polling Interval:                30\n",
      "      Prometheus Trigger:\n",
      "        Activation Target Value:      0\n",
      "        Metric Type:                  Average\n",
      "        Use Cached Metrics:           true\n",
      "      Scale Down Stabilization Time:  300\n",
      "      Scale Up Stabilization Time:    0\n",
      "    Enabled:                          true\n",
      "    Routing Strategy:                 prefixaware\n",
      "  Invocation Endpoint:                v1/chat/completions\n",
      "  Kv Cache Spec:\n",
      "    enableL1Cache:  true\n",
      "    enableL2Cache:  false\n",
      "    l2CacheSpec:\n",
      "      l2CacheBackend:   tieredstorage\n",
      "      l2CacheLocalUrl:  \n",
      "  Load Balancer:\n",
      "    Health Check Path:         /health\n",
      "    Routing Algorithm:         least_outstanding_requests\n",
      "  Max Deploy Time In Seconds:  3600\n",
      "  Metrics:\n",
      "    Enabled:                          true\n",
      "    Metrics Scrape Interval Seconds:  15\n",
      "    Model Metrics:\n",
      "      Path:    /metrics\n",
      "      Port:    8000\n",
      "  Model Name:  Qwen3-4B-Instruct\n",
      "  Model Source Config:\n",
      "    Fsx Storage:\n",
      "      File System Id:   \n",
      "    Model Location:     Qwen3-4B-Instruct-2507/0d0f748bad7a4aa7a3cae5ec42bb4553/finetuned_model_merged/\n",
      "    Model Source Type:  s3\n",
      "    Prefetch Enabled:   false\n",
      "    s3Storage:\n",
      "      Bucket Name:  sagemaker-us-east-1-434444145045\n",
      "      Region:       us-east-1\n",
      "  Model Version:    \n",
      "  Replicas:         1\n",
      "  Tls Config:\n",
      "    tlsCertificateOutputS3Uri:  s3://llm-modelhub-hyperpod-434444145045-us-east-1/cert\n",
      "  Worker:\n",
      "    Args:\n",
      "      /opt/ml/model\n",
      "      --max-model-len\n",
      "      20000\n",
      "      --tensor-parallel-size\n",
      "      1\n",
      "    Environment Variables:\n",
      "      Name:   PYTHONHASHSEED\n",
      "      Value:  123\n",
      "      Name:   OPTION_ROLLING_BATCH\n",
      "      Value:  vllm\n",
      "      Name:   SAGEMAKER_SUBMIT_DIRECTORY\n",
      "      Value:  /opt/ml/model/code\n",
      "      Name:   MODEL_CACHE_ROOT\n",
      "      Value:  /opt/ml/model\n",
      "      Name:   SAGEMAKER_MODEL_SERVER_WORKERS\n",
      "      Value:  1\n",
      "      Name:   SAGEMAKER_MODEL_SERVER_TIMEOUT\n",
      "      Value:  3600\n",
      "    Image:    public.ecr.aws/deep-learning-containers/vllm:0.13.0-gpu-py312-cu129-ubuntu22.04-ec2-v1.0\n",
      "    Model Invocation Port:\n",
      "      Container Port:  8000\n",
      "      Name:            http\n",
      "    Model Volume Mount:\n",
      "      Mount Path:  /opt/ml/model\n",
      "      Name:        model-weights\n",
      "    Resources:\n",
      "      Limits:\n",
      "        nvidia.com/gpu:  1\n",
      "      Requests:\n",
      "        Cpu:             6\n",
      "        Memory:          30Gi\n",
      "        nvidia.com/gpu:  1\n",
      "Status:\n",
      "  Conditions:\n",
      "    Last Transition Time:  2026-01-13T06:47:34Z\n",
      "    Message:               Deployment and SageMaker endpoint registration for model have been created successfully\n",
      "    Reason:                Success\n",
      "    Status:                True\n",
      "    Type:                  DeploymentComplete\n",
      "  Deployment Status:\n",
      "    Deployment Object Overall State:  DeploymentComplete\n",
      "    Last Updated:                     2026-01-13T06:47:34Z\n",
      "    Name:                             demo\n",
      "    Reason:                           NativeDeploymentObjectFound\n",
      "    Status:\n",
      "      Available Replicas:  1\n",
      "      Conditions:\n",
      "        Last Transition Time:  2026-01-13T06:43:58Z\n",
      "        Last Update Time:      2026-01-13T06:43:58Z\n",
      "        Message:               Deployment has minimum availability.\n",
      "        Reason:                MinimumReplicasAvailable\n",
      "        Status:                True\n",
      "        Type:                  Available\n",
      "        Last Transition Time:  2026-01-13T06:41:48Z\n",
      "        Last Update Time:      2026-01-13T06:43:58Z\n",
      "        Message:               ReplicaSet \"demo-5bb6d57dd6\" has successfully progressed.\n",
      "        Reason:                NewReplicaSetAvailable\n",
      "        Status:                True\n",
      "        Type:                  Progressing\n",
      "      Observed Generation:     1\n",
      "      Ready Replicas:          1\n",
      "      Replicas:                1\n",
      "      Updated Replicas:        1\n",
      "  Endpoints:\n",
      "    Sagemaker:\n",
      "      Endpoint Arn:  arn:aws:sagemaker:us-east-1:434444145045:endpoint/demo-l2-cache\n",
      "      State:         CreationCompleted\n",
      "  Metrics Status:\n",
      "    Enabled:                          true\n",
      "    Metrics Scrape Interval Seconds:  15\n",
      "    Model Metrics:\n",
      "      Path:  /metrics\n",
      "      Port:  8000\n",
      "    State:   Enabled\n",
      "  Replicas:  1\n",
      "  Selector:  app=demo,deploying-service=hyperpod-inference\n",
      "  State:     DeploymentComplete\n",
      "  Tls Certificate:\n",
      "    Certificate ARN:  arn:aws:acm:us-east-1:434444145045:certificate/eb259961-bfc7-4435-bb2b-53d912eb663e\n",
      "    Certificate Domain Names:\n",
      "      internal-k8s-hyperpod-albdemod-48037dc148-603692612-1768286517.us-east-1.elb.amazonaws.com\n",
      "    Certificate Name:  demo-certificate\n",
      "    Imported Certificates:\n",
      "      arn:aws:acm:us-east-1:434444145045:certificate/eb259961-bfc7-4435-bb2b-53d912eb663e\n",
      "    Issuer Name:                   demo-issuer\n",
      "    Last Cert Expiry Time:         2027-01-13T06:41:57Z\n",
      "    tlsCertificateOutputS3Bucket:  llm-modelhub-hyperpod-434444145045-us-east-1\n",
      "    tlsCertificateS3Keys:\n",
      "      cert/kapb14yhzsn7/default-demo-1768286498/demo-certificate-1799822517.pem\n",
      "Events:  <none>\n"
     ]
    }
   ],
   "source": [
    "!kubectl get inferenceendpointconfig -n default  # List all inference endpoints\n",
    "!kubectl describe inferenceendpointconfig demo -n default  # Show detailed deployment info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-completion-note",
   "metadata": {},
   "source": [
    "When the pod status shows \"Running\", the deployment is complete and ready to serve inference requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef7fe5",
   "metadata": {},
   "source": [
    "### 10.6 Invoke the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1ffe8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.42.26-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting botocore<1.43.0,>=1.42.26 (from boto3)\n",
      "  Downloading botocore-1.42.26-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.17.0,>=0.16.0 (from boto3)\n",
      "  Using cached s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ubuntu/.local/lib/python3.12/site-packages (from botocore<1.43.0,>=1.42.26->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/lib/python3/dist-packages (from botocore<1.43.0,>=1.42.26->boto3) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.local/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.43.0,>=1.42.26->boto3) (1.17.0)\n",
      "Downloading boto3-1.42.26-py3-none-any.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.42.26-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached s3transfer-0.16.0-py3-none-any.whl (86 kB)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.42.26 botocore-1.42.26 jmespath-1.0.1 s3transfer-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c782d9c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\"error\":\"Model /opt/ml/model not found or vLLM engine is sleeping.\"}\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/demo-l2-cache in account 434444145045 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModelError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      6\u001b[39m runtime = boto3.client(\u001b[33m\"\u001b[39m\u001b[33msagemaker-runtime\u001b[39m\u001b[33m\"\u001b[39m, region_name=\u001b[33m\"\u001b[39m\u001b[33mus-east-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m payload = {\n\u001b[32m      9\u001b[39m          \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m/opt/ml/model\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msession_123\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Add this field for \"session\" and \"kvaware\" routing\u001b[39;00m\n\u001b[32m     19\u001b[39m         }\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m response = \u001b[43mruntime\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEndpointName\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mContentType\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mBody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m\"\u001b[39m\u001b[33mBody\u001b[39m\u001b[33m\"\u001b[39m].read().decode())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/botocore/client.py:602\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    599\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    600\u001b[39m     )\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/botocore/client.py:1078\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1074\u001b[39m     error_code = request_context.get(\n\u001b[32m   1075\u001b[39m         \u001b[33m'\u001b[39m\u001b[33merror_code_override\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1076\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1077\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1080\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mModelError\u001b[39m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\"error\":\"Model /opt/ml/model not found or vLLM engine is sleeping.\"}\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/demo-l2-cache in account 434444145045 for more information."
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "endpoint_name = \"demo-l2-cache\"\n",
    "# endpoint_name = \"qwen3-4b-instruct-2507-2026-01-13-06-05\"\n",
    "runtime = boto3.client(\"sagemaker-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "payload = {\n",
    "         \"model\": \"/opt/ml/model\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"What is machine learning?\"\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 50,\n",
    "            \"temperature\": 0,\n",
    "            \"user_id\": \"session_123\"  # Add this field for \"session\" and \"kvaware\" routing\n",
    "        }\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "print(response[\"Body\"].read().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2a84a-3a5d-4e2c-ace0-d76d883baa67",
   "metadata": {},
   "source": [
    "## 11 Uninstallation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746bb98-182a-4a69-90eb-961fb946a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm uninstall hyperpod-inference-operator -n kube-system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26199e6",
   "metadata": {},
   "source": [
    "## 12 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e82e0c",
   "metadata": {},
   "source": [
    "KV Cache and Intelligent Routing in SageMaker HyperPod Model Deployment help you optimize LLM inference performance and costs through efficient memory management and smart request routing. You can get started today by adding these configurations to your HyperPod model deployments in all AWS Regions where SageMaker HyperPod is available."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
