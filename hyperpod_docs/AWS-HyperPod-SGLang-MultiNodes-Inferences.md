# AWS HyperPod EKS é›†ç¾¤ä¸­ SGLang å¤šæœºåˆ†å¸ƒå¼æ¨ç†éƒ¨ç½²å®Œæ•´æŒ‡å—

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.5
> **æ›´æ–°æ—¥æœŸ**: 2026-01-31
> **ä½œè€…**: æŠ€æœ¯è°ƒç ”å›¢é˜Ÿ

---

## ğŸ“‹ ç›®å½•

- [1. æ¦‚è¿°](#1-æ¦‚è¿°)
- [2. æ ¸å¿ƒæ¶æ„](#2-æ ¸å¿ƒæ¶æ„)
- [3. SGLang åœ¨ HyperPod ä¸Šçš„é›†æˆæ–¹æ¡ˆ](#3-sglang-åœ¨-hyperpod-ä¸Šçš„é›†æˆæ–¹æ¡ˆ)
- [4. å¤šèŠ‚ç‚¹éƒ¨ç½²é…ç½®](#4-å¤šèŠ‚ç‚¹éƒ¨ç½²é…ç½®)
- [5. ä½¿ç”¨ HuggingFace Model ID ç›´æ¥éƒ¨ç½²](#5-ä½¿ç”¨-huggingface-model-id-ç›´æ¥éƒ¨ç½²)
- [6. éƒ¨ç½²æ­¥éª¤](#6-éƒ¨ç½²æ­¥éª¤)
- [7. æ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ](#7-æ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ)
- [8. ç›‘æ§å’Œå¯è§‚æµ‹æ€§](#8-ç›‘æ§å’Œå¯è§‚æµ‹æ€§)
- [9. æ•…éšœæ’æŸ¥](#9-æ•…éšœæ’æŸ¥)
- [10. å®é™…æ¡ˆä¾‹ç ”ç©¶](#10-å®é™…æ¡ˆä¾‹ç ”ç©¶)
- [11. å‚è€ƒèµ„æº](#11-å‚è€ƒèµ„æº)

---

## 1. æ¦‚è¿°

### 1.1 èƒŒæ™¯

AWS SageMaker HyperPod ç°å·²æ”¯æŒé€šè¿‡ Amazon EKS è¿›è¡Œæ¨ç†éƒ¨ç½²ï¼Œæä¾›äº†ä¸€ä¸ªå®Œæ•´çš„æ¨ç†å¹³å°ï¼Œç»“åˆäº† Kubernetes çš„çµæ´»æ€§å’Œ AWS æ‰˜ç®¡æœåŠ¡çš„å¯é æ€§ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»å¦‚ä½•åœ¨ HyperPod EKS é›†ç¾¤ä¸­éƒ¨ç½² SGLang æ¨ç†å¼•æ“è¿›è¡Œå¤šæœºåˆ†å¸ƒå¼æ¨ç†ã€‚

### 1.2 ä¸ºä»€ä¹ˆé€‰æ‹© SGLangï¼Ÿ

**SGLang (Structured Generation Language)** æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„å¤§è¯­è¨€æ¨¡å‹æœåŠ¡æ¡†æ¶ï¼Œå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

- âœ… **é«˜æ€§èƒ½æ¨ç†**: ä½¿ç”¨ RadixAttention è¿›è¡Œå‰ç¼€ç¼“å­˜ï¼Œé›¶å¼€é”€ CPU è°ƒåº¦å™¨
- âœ… **å¹¿æ³›çš„æ¨¡å‹æ”¯æŒ**: å…¼å®¹å¤§å¤šæ•° HuggingFace æ¨¡å‹å’Œ OpenAI API
- âœ… **å¤šèŠ‚ç‚¹æ¨ç†**: åŸç”Ÿæ”¯æŒ tensor parallelism å’Œè·¨èŠ‚ç‚¹åˆ†å¸ƒå¼éƒ¨ç½²
- âœ… **ç”Ÿäº§å°±ç»ª**: æ”¯æŒè¿ç»­æ‰¹å¤„ç†ã€åˆ†é¡µæ³¨æ„åŠ›ã€é‡åŒ–ï¼ˆFP4/FP8/INT4/AWQ/GPTQï¼‰
- âœ… **æ˜“äºé›†æˆ**: ä¸ Kubernetesã€Ray Cluster å’Œ HuggingFace Hub æ— ç¼é›†æˆ

### 1.3 é€‚ç”¨åœºæ™¯

æœ¬æ–¹æ¡ˆé€‚ç”¨äºä»¥ä¸‹åœºæ™¯ï¼š

1. **è¶…å¤§æ¨¡å‹æ¨ç†** - å•èŠ‚ç‚¹ GPU æ— æ³•å®¹çº³çš„æ¨¡å‹ï¼ˆå¦‚ Llama 405Bã€DeepSeek R1 671Bï¼‰
2. **é«˜ååé‡éœ€æ±‚** - éœ€è¦å¤„ç†å¤§é‡å¹¶å‘è¯·æ±‚
3. **ä½å»¶è¿Ÿè¦æ±‚** - åˆ©ç”¨å¤šèŠ‚ç‚¹å¹¶è¡Œé™ä½æ¨ç†å»¶è¿Ÿ
4. **ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²** - éœ€è¦é«˜å¯ç”¨æ€§ã€è‡ªåŠ¨æ‰©å±•å’Œç›‘æ§èƒ½åŠ›

---

## 2. æ ¸å¿ƒæ¶æ„

### 2.1 æ•´ä½“æŠ€æœ¯æ ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         AWS SageMaker HyperPod (ç¼–æ’å±‚)                  â”‚
â”‚  - é›†ç¾¤ç”Ÿå‘½å‘¨æœŸç®¡ç†                                       â”‚
â”‚  - è‡ªåŠ¨æ•…éšœæ¢å¤                                          â”‚
â”‚  - èµ„æºä¼˜åŒ–                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Amazon EKS (Kubernetes é›†ç¾¤)                    â”‚
â”‚  - Container ç¼–æ’                                        â”‚
â”‚  - æœåŠ¡å‘ç°ä¸è´Ÿè½½å‡è¡¡                                     â”‚
â”‚  - è‡ªåŠ¨æ‰©å±•                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ray Cluster  â”‚  â”‚  LeaderWorker â”‚  â”‚  HyperPod   â”‚
â”‚  (å¯é€‰)       â”‚  â”‚     Set       â”‚  â”‚  Inference  â”‚
â”‚              â”‚  â”‚    (æ¨è)      â”‚  â”‚  Operator   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                 â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SGLang (æ¨ç†å¼•æ“)                            â”‚
â”‚  - RadixAttention                                        â”‚
â”‚  - Continuous Batching                                   â”‚
â”‚  - Multi-node Tensor Parallelism                         â”‚
â”‚  - KV Cache ä¼˜åŒ–                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 å…³é”®ç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **ç»Ÿä¸€åŸºç¡€è®¾æ–½** | åŒä¸€ HyperPod é›†ç¾¤å¯ç”¨äºè®­ç»ƒå’Œæ¨ç†ï¼Œæœ€å¤§åŒ– GPU åˆ©ç”¨ç‡ |
| **å¤šèŠ‚ç‚¹æ¨ç†æ¶æ„** | æ”¯æŒå•èŠ‚ç‚¹å’Œå¤šèŠ‚ç‚¹æ¨ç†éƒ¨ç½² |
| **è‡ªåŠ¨æ‰©å±•** | é€šè¿‡ KEDAï¼ˆKubernetes Event Driven Autoscalingï¼‰å®ç°åŠ¨æ€æ‰©å±• |
| **å¼¹æ€§å®¹é”™** | è‡ªåŠ¨æ£€æµ‹å’Œæ¢å¤ç¡¬ä»¶æ•…éšœ |
| **GPU åˆ†åŒºï¼ˆMIGï¼‰** | ä½¿ç”¨ Multi-Instance GPU æŠ€æœ¯æé«˜åˆ©ç”¨ç‡ |
| **æ™ºèƒ½è·¯ç”±** | æ ¹æ®å‰ç¼€ã€KV ç¼“å­˜å‘½ä¸­ç‡è¿›è¡Œè¯·æ±‚è·¯ç”± |

### 2.3 ç½‘ç»œæ‹“æ‰‘

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Kubernetes      â”‚
                    â”‚  Service/Ingress â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Leader Node 0   â”‚ â”‚ Worker      â”‚ â”‚ Worker        â”‚
    â”‚  (Rank 0)        â”‚ â”‚ Node 1      â”‚ â”‚ Node 2        â”‚
    â”‚  - HTTP Server   â”‚ â”‚ (Rank 1)    â”‚ â”‚ (Rank 2)      â”‚
    â”‚  - 8x GPU (TP=8) â”‚ â”‚ - 8x GPU    â”‚ â”‚ - 8x GPU      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                   â”‚              â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  EFA (Elastic      â”‚
                        â”‚  Fabric Adapter)   â”‚
                        â”‚  - RDMA é€šä¿¡        â”‚
                        â”‚  - ä½å»¶è¿Ÿäº’è”       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. SGLang åœ¨ HyperPod ä¸Šçš„é›†æˆæ–¹æ¡ˆ

### 3.1 å®é™…ç”Ÿäº§æ¡ˆä¾‹ï¼šOsmosis AI

æ ¹æ® Tech42 Consulting çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œ**Osmosis AIï¼ˆGulp.aiï¼‰æˆåŠŸåœ¨ AWS SageMaker HyperPod EKS ä¸Šé›†æˆäº† SGLang**ï¼Œç”¨äº LLM å¾®è°ƒæœŸé—´çš„æ¨¡å‹æ¨ç†ã€‚

**æ¶æ„ç»„ä»¶**ï¼š
- **Amazon SageMaker HyperPod** - ç®¡ç†æ•´ä¸ªè®­ç»ƒ/æ¨ç†åŸºç¡€è®¾æ–½ç”Ÿå‘½å‘¨æœŸ
- **Amazon EKS** - ç”± HyperPod ç¼–æ’çš„ Kubernetes æœåŠ¡
- **Ray Cluster** - åœ¨ HyperPod ç¯å¢ƒå†…ç®¡ç†çš„åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶
- **SGLang** - ä½œä¸ºæ¨ç†åç«¯è¿è¡Œåœ¨å®¹å™¨ä¸­

**å…³é”®æ”¶ç›Š**ï¼š
- âœ… æ˜¾è‘—æé«˜ GPU åˆ©ç”¨ç‡
- âœ… é€šè¿‡ä¼˜åŒ–å†…å­˜ä½¿ç”¨å’Œæ›´å¿«çš„ token ç”Ÿæˆå‡å°‘è®­ç»ƒæ—¶é—´
- âœ… ä»å•èŠ‚ç‚¹æ— ç¼æ‰©å±•åˆ°å¤šèŠ‚ç‚¹é…ç½®
- âœ… åŠ¨æ€æ‰¹å¤„ç†å’Œé«˜æ•ˆçš„ GPU åˆ©ç”¨ç‡å¤§å¹…é™ä½è®¡ç®—æˆæœ¬

### 3.2 ä¸‰ç§éƒ¨ç½²æ¨¡å¼

#### æ¨¡å¼ 1ï¼šèšåˆæ¨¡å¼ï¼ˆAggregatedï¼‰
é€‚ç”¨äºå¼€å‘/æµ‹è¯•ç¯å¢ƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Frontend               â”‚
â”‚  (OpenAI-compatible API)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SGLangDecodeWorker           â”‚
â”‚   (å¤„ç† prefill + decode)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### æ¨¡å¼ 2ï¼šèšåˆè·¯ç”±æ¨¡å¼ï¼ˆAggregated Routerï¼‰
é€‚ç”¨äºç”Ÿäº§ç¯å¢ƒï¼Œæ”¯æŒè´Ÿè½½å‡è¡¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Frontend               â”‚
â”‚  (å¸¦ KV Cache è·¯ç”±)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SGLangDecodeWorker           â”‚
â”‚   (å¤„ç† prefill + decode)       â”‚
â”‚   + KV Cache è·¯ç”±               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### æ¨¡å¼ 3ï¼šè§£è€¦æ¨¡å¼ï¼ˆDisaggregatedï¼‰â­ï¸
é€‚ç”¨äºæœ€é«˜æ€§èƒ½éœ€æ±‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Frontend               â”‚
â”‚  (HTTP API Server)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
        â”‚                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SGLangPrefill    â”‚  â”‚ SGLangDecode      â”‚
â”‚ Worker           â”‚  â”‚ Worker            â”‚
â”‚ (ä»… prefill)      â”‚  â”‚ (ä»… decode)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. å¤šèŠ‚ç‚¹éƒ¨ç½²é…ç½®

### 4.1 ä½¿ç”¨ LeaderWorkerSetï¼ˆæ¨èæ–¹æ¡ˆï¼‰

LeaderWorkerSet æ˜¯ Kubernetes ç¤¾åŒºæ¨èçš„å¤šèŠ‚ç‚¹ LLM æ¨ç†è§£å†³æ–¹æ¡ˆï¼Œè¢« SGLangã€vLLMã€NVIDIA Dynamo ç­‰ä¸»æµæ¡†æ¶é‡‡ç”¨ã€‚

#### 4.1.1 å®Œæ•´ YAML é…ç½®

```yaml
# sglang-multi-node.yaml
apiVersion: leaderworkerset.x-k8s.io/v1
kind: LeaderWorkerSet
metadata:
  name: sglang-multi-nodes
  namespace: default
spec:
  replicas: 1  # LeaderWorkerSet å‰¯æœ¬æ•°
  leaderWorkerTemplate:
    size: 2  # æ¯ä¸ª LeaderWorkerSet åŒ…å«çš„èŠ‚ç‚¹æ•°ï¼ˆ1 leader + 1 workerï¼‰
    restartPolicy: RecreateGroupOnPodRestart

    # Leader èŠ‚ç‚¹é…ç½®
    leaderTemplate:
      metadata:
        labels:
          role: leader
          app: sglang-inference
          inference-workload: sglang-multi-nodes
          inference-backend: sglang
      spec:
        containers:
        - name: sglang-leader
          image: lmsysorg/sglang:v0.5.8
          command:
          - sh
          - -c
          - |
            python3 -m sglang.launch_server \
              --model-path Qwen/Qwen3-30B-A3B-Thinking-2507 \
              --tp 8 \
              --dist-init-addr $(LWS_LEADER_ADDRESS):20000 \
              --nnodes 2 \
              --node-rank 0 \
              --host 0.0.0.0 \
              --port 30000 \
              --trust-remote-code \
              --enable-metrics \
              --mem-fraction-static 0.85 \
              --chunked-prefill-size 8192 \
              --context-length 32768 \
              --max-running-requests 256

          env:
          # HuggingFace Token
          - name: HF_TOKEN
            valueFrom:
              secretKeyRef:
                name: hf-token-secret
                key: token

          # GPU é…ç½®
          - name: CUDA_VISIBLE_DEVICES
            value: "0,1,2,3,4,5,6,7"

          # NCCL è°ƒè¯•
          - name: NCCL_DEBUG
            value: "INFO"

          # EFA é…ç½®ï¼ˆå¦‚ä½¿ç”¨é«˜æ€§èƒ½å®ä¾‹ï¼‰
          - name: NCCL_IB_DISABLE
            value: "0"
          - name: NCCL_NET_GDR_LEVEL
            value: "5"
          - name: FI_PROVIDER
            value: "efa"
          - name: FI_EFA_USE_DEVICE_RDMA
            value: "1"

          resources:
            limits:
              nvidia.com/gpu: 8
              vpc.amazonaws.com/efa: 1  # EFA ç½‘ç»œæ¥å£
            requests:
              nvidia.com/gpu: 8
              vpc.amazonaws.com/efa: 1
              cpu: "96"
              memory: "512Gi"

          ports:
          - name: http
            containerPort: 30000
            protocol: TCP
          - name: metrics
            containerPort: 9090
            protocol: TCP

          volumeMounts:
          - name: hf-cache
            mountPath: /root/.cache/huggingface
          - name: shm
            mountPath: /dev/shm

          livenessProbe:
            httpGet:
              path: /health
              port: 30000
            initialDelaySeconds: 1800  # 30 åˆ†é’Ÿï¼Œç»™æ¨¡å‹ä¸‹è½½æ—¶é—´
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3

          readinessProbe:
            httpGet:
              path: /health
              port: 30000
            initialDelaySeconds: 1800
            periodSeconds: 10
            timeoutSeconds: 5

        volumes:
        - name: hf-cache
          persistentVolumeClaim:
            claimName: huggingface-cache-pvc
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 64Gi

        # èŠ‚ç‚¹é€‰æ‹©å™¨ï¼ˆç¡®ä¿è°ƒåº¦åˆ° GPU èŠ‚ç‚¹ï¼‰
        nodeSelector:
          node.kubernetes.io/instance-type: ml.p5.48xlarge

        # å®¹å¿åº¦ï¼ˆå¦‚æœ GPU èŠ‚ç‚¹æœ‰ taintï¼‰
        tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule

    # Worker èŠ‚ç‚¹é…ç½®
    workerTemplate:
      metadata:
        labels:
          role: worker
          app: sglang-inference
          inference-workload: sglang-multi-nodes
      spec:
        containers:
        - name: sglang-worker
          image: lmsysorg/sglang:v0.5.8
          command:
          - sh
          - -c
          - |
            python3 -m sglang.launch_server \
              --model-path Qwen/Qwen3-30B-A3B-Thinking-2507 \
              --tp 8 \
              --dist-init-addr $(LWS_LEADER_ADDRESS):20000 \
              --nnodes 2 \
              --node-rank 1 \
              --trust-remote-code \
              --mem-fraction-static 0.85

          env:
          - name: HF_TOKEN
            valueFrom:
              secretKeyRef:
                name: hf-token-secret
                key: token
          - name: CUDA_VISIBLE_DEVICES
            value: "0,1,2,3,4,5,6,7"
          - name: NCCL_DEBUG
            value: "INFO"
          - name: NCCL_IB_DISABLE
            value: "0"
          - name: NCCL_NET_GDR_LEVEL
            value: "5"
          - name: FI_PROVIDER
            value: "efa"
          - name: FI_EFA_USE_DEVICE_RDMA
            value: "1"

          resources:
            limits:
              nvidia.com/gpu: 8
              vpc.amazonaws.com/efa: 1
            requests:
              nvidia.com/gpu: 8
              vpc.amazonaws.com/efa: 1
              cpu: "96"
              memory: "512Gi"

          volumeMounts:
          - name: hf-cache
            mountPath: /root/.cache/huggingface
          - name: shm
            mountPath: /dev/shm

        volumes:
        - name: hf-cache
          persistentVolumeClaim:
            claimName: huggingface-cache-pvc
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 64Gi

        nodeSelector:
          node.kubernetes.io/instance-type: ml.p5.48xlarge

        tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule

---
# Service - ä»…æš´éœ² Leader èŠ‚ç‚¹
apiVersion: v1
kind: Service
metadata:
  name: sglang-service
  namespace: default
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
    prometheus.io/path: "/metrics"
spec:
  selector:
    app: sglang-inference
    role: leader
  ports:
  - name: http
    protocol: TCP
    port: 30000
    targetPort: 30000
  - name: metrics
    protocol: TCP
    port: 9090
    targetPort: 9090
  type: ClusterIP

---
# Ingress (å¯é€‰ - ç”¨äºå¤–éƒ¨è®¿é—®)
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: sglang-ingress
  namespace: default
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
spec:
  rules:
  - host: sglang.yourdomain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: sglang-service
            port:
              number: 30000
```

#### 4.1.2 å…³é”®å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹å€¼ |
|------|------|--------|
| `--model-path` | HuggingFace Model ID æˆ–æœ¬åœ°è·¯å¾„ | `Qwen/Qwen3-30B-A3B-Thinking-2507` |
| `--tp` | Tensor Parallelism å¹¶è¡Œåº¦ï¼ˆåˆ«å: `--tp-size`ï¼‰| `2`, `4`, `8`, `16` |
| `--dist-init-addr` | åˆ†å¸ƒå¼åˆå§‹åŒ–åœ°å€ | `$(LWS_LEADER_ADDRESS):20000` |
| `--nnodes` | èŠ‚ç‚¹æ€»æ•° | `2`, `4`, `8` |
| `--node-rank` | å½“å‰èŠ‚ç‚¹æ’åï¼ˆLeader=0ï¼‰ | `0`, `1`, `2`, `3`... |
| `--host` | æœåŠ¡ç›‘å¬åœ°å€ | `0.0.0.0` |
| `--port` | HTTP æœåŠ¡ç«¯å£ | `30000`ï¼ˆé»˜è®¤ï¼‰ |
| `--trust-remote-code` | ä¿¡ä»»è¿œç¨‹ä»£ç  | flag |
| `--enable-metrics` | å¯ç”¨ Prometheus æŒ‡æ ‡ | flag |
| `--mem-fraction-static` | KV Cache å†…å­˜æ¯”ä¾‹ | `0.85` (85%) |
| `--chunked-prefill-size` | Chunked Prefill å¤§å° | `8192` |
| `--context-length` | æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ | `32768` |
| `--max-running-requests` | æœ€å¤§å¹¶å‘è¯·æ±‚æ•° | `256` |

**ç«¯å£è¯´æ˜**ï¼šSGLang é»˜è®¤ä½¿ç”¨ 30000 ç«¯å£ã€‚AWS SageMaker DLC å®¹å™¨é€šå¸¸ä½¿ç”¨ 8000 (vLLM) æˆ– 8080 (SGLang DLC)ã€‚æœ¬æ–‡æ¡£ç¤ºä¾‹ä½¿ç”¨ SGLang åŸç”Ÿé»˜è®¤ç«¯å£ 30000ã€‚

### 4.2 ä½¿ç”¨ HyperPod Inference Operator

å¦‚æœä½¿ç”¨ AWS åŸç”Ÿçš„ HyperPod Inference Operatorï¼š

```yaml
# sglang-hyperpod-inference.yaml
apiVersion: inference.sagemaker.aws.amazon.com/v1
kind: InferenceEndpointConfig
metadata:
  name: sglang-endpoint
  namespace: default
spec:
  replicas: 2  # å¤šå‰¯æœ¬éƒ¨ç½²

  worker:
    image: lmsysorg/sglang:v0.5.8

    command:
    - python3
    - -m
    - sglang.launch_server
    - --model-path
    - Qwen/Qwen3-30B-A3B-Thinking-2507
    - --tp
    - "8"
    - --host
    - 0.0.0.0
    - --port
    - "30000"
    - --trust-remote-code
    - --enable-metrics

    modelInvocationPort:
      containerPort: 30000
      name: http

    resources:
      limits:
        nvidia.com/gpu: 8
        cpu: "128"
        memory: "512Gi"
      requests:
        nvidia.com/gpu: 8
        cpu: "64"
        memory: "256Gi"

    environmentVariables:
    - name: HF_TOKEN
      valueFrom:
        secretKeyRef:
          name: hf-token-secret
          key: token
    - name: CUDA_VISIBLE_DEVICES
      value: "0,1,2,3,4,5,6,7"

    volumeMounts:
    - name: hf-cache
      mountPath: /root/.cache/huggingface
    - name: shm
      mountPath: /dev/shm

  volumes:
  - name: hf-cache
    persistentVolumeClaim:
      claimName: huggingface-cache-pvc
  - name: shm
    emptyDir:
      medium: Memory
      sizeLimit: 64Gi

  # TLS é…ç½®
  tlsConfig:
    tlsCertificateOutputS3Uri: s3://my-bucket/sglang-certs/

  # ç›‘æ§æŒ‡æ ‡
  metrics:
    enabled: true
```

---

## 5. ä½¿ç”¨ HuggingFace Model ID ç›´æ¥éƒ¨ç½²

### 5.1 å·¥ä½œåŸç†

SGLang åŸç”Ÿæ”¯æŒç›´æ¥ä½¿ç”¨ HuggingFace Model ID æ¥è‡ªåŠ¨ä¸‹è½½å’Œéƒ¨ç½²æ¨¡å‹ï¼š

1. **è‡ªåŠ¨ä» HuggingFace Hub ä¸‹è½½æ¨¡å‹**
2. **ç¼“å­˜åˆ°é»˜è®¤ç›®å½•**ï¼ˆ`~/.cache/huggingface/`ï¼‰
3. **åŠ è½½å¹¶å¯åŠ¨æ¨ç†æœåŠ¡**

### 5.2 æ”¯æŒçš„æ¨¡å‹æ ¼å¼

#### å…¬å¼€æ¨¡å‹ï¼ˆæ— éœ€è®¤è¯ï¼‰
```bash
--model-path meta-llama/Llama-3.2-1B-Instruct
--model-path microsoft/DialoGPT-medium
--model-path deepseek-ai/deepseek-llm-7b-chat
```

#### é—¨æ§æ¨¡å‹ï¼ˆéœ€è¦ HF Tokenï¼‰
```bash
--model-path Qwen/Qwen3-30B-A3B-Thinking-2507
--model-path meta-llama/Meta-Llama-3.1-405B-Instruct
```

#### éœ€è¦è‡ªå®šä¹‰ä»£ç çš„æ¨¡å‹
```bash
--model-path MiniMaxAI/MiniMax-M2 --trust-remote-code
--model-path kyutai/helium-1-preview-2b --trust-remote-code
```

### 5.3 é…ç½® HuggingFace Token

#### æ–¹æ³• 1ï¼šä½¿ç”¨ Kubernetes Secret

```bash
# åˆ›å»º Secret
kubectl create secret generic hf-token-secret \
  --from-literal=token=hf_xxxxxxxxxxxxxxxxxxxxxxxxxx \
  --namespace=default
```

åœ¨ YAML ä¸­å¼•ç”¨ï¼š
```yaml
env:
- name: HF_TOKEN
  valueFrom:
    secretKeyRef:
      name: hf-token-secret
      key: token
```

**è¯´æ˜**ï¼š
- `HF_TOKEN` æ˜¯ HuggingFace æ¨èçš„ç¯å¢ƒå˜é‡åï¼ˆ2023å¹´åï¼‰
- SGLang ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨ `HF_TOKEN` è¿›è¡Œè®¤è¯
- æ—§ç‰ˆç¯å¢ƒå˜é‡å `HUGGING_FACE_HUB_TOKEN` ä»ç„¶æ”¯æŒï¼Œä½†å»ºè®®ä½¿ç”¨ `HF_TOKEN`

#### æ–¹æ³• 2ï¼šä½¿ç”¨æ—§çš„ç¯å¢ƒå˜é‡åï¼ˆå‘åå…¼å®¹ï¼‰
```yaml
env:
- name: HUGGING_FACE_HUB_TOKEN
  valueFrom:
    secretKeyRef:
      name: hf-token-secret
      key: token
```

### 5.4 é…ç½®æŒä¹…åŒ–å­˜å‚¨

#### åˆ›å»º FSx for Lustre PVCï¼ˆæ¨èï¼‰

```yaml
# fsx-lustre-storageclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fsx-lustre-sc
provisioner: fsx.csi.aws.com
parameters:
  subnetId: subnet-xxxxxxxxx
  securityGroupIds: sg-xxxxxxxxx
  deploymentType: PERSISTENT_1
  perUnitStorageThroughput: "200"
  fileSystemTypeVersion: "2.15"

---
# huggingface-cache-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: huggingface-cache-pvc
  namespace: default
spec:
  accessModes:
  - ReadWriteMany  # å¤šèŠ‚ç‚¹å…±äº«è®¿é—®
  resources:
    requests:
      storage: 500Gi  # æ ¹æ®æ¨¡å‹å¤§å°è°ƒæ•´
  storageClassName: fsx-lustre-sc
```

**ä¸ºä»€ä¹ˆé€‰æ‹© FSx for Lustreï¼Ÿ**
- âœ… æ”¯æŒå¤šèŠ‚ç‚¹å¹¶å‘è¯»å†™ï¼ˆReadWriteManyï¼‰
- âœ… é«˜æ€§èƒ½ï¼Œé€‚åˆå¤§æ¨¡å‹æ–‡ä»¶ï¼ˆå¯è¾¾ GB/s ååé‡ï¼‰
- âœ… å¯ä»¥é¢„åŠ è½½ S3 ä¸­çš„æ•°æ®
- âœ… æŒ‰éœ€æ‰©å±•ï¼Œæˆæœ¬ä¼˜åŒ–

### 5.5 ä½¿ç”¨ InitContainer é¢„ä¸‹è½½æ¨¡å‹ï¼ˆå¯é€‰ï¼‰

ä¸ºé¿å…é¦–æ¬¡å¯åŠ¨æ—¶ä¸‹è½½æ¨¡å‹å¯¼è‡´è¶…æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ InitContainerï¼š

```yaml
initContainers:
- name: model-downloader
  image: lmsysorg/sglang:v0.5.8
  command:
  - sh
  - -c
  - |
    echo "å¼€å§‹ä¸‹è½½æ¨¡å‹..."
    python3 -c "
    from huggingface_hub import snapshot_download
    import os
    snapshot_download(
      repo_id='Qwen/Qwen3-30B-A3B-Thinking-2507',
      cache_dir='/root/.cache/huggingface',
      token=os.environ.get('HF_TOKEN')
    )
    "
    echo "æ¨¡å‹ä¸‹è½½å®Œæˆï¼"
  env:
  - name: HF_TOKEN
    valueFrom:
      secretKeyRef:
        name: hf-token-secret
        key: token
  volumeMounts:
  - name: hf-cache
    mountPath: /root/.cache/huggingface
  resources:
    requests:
      cpu: "8"
      memory: "32Gi"
```

### 5.6 ä¸­å›½åŒºåŠ é€Ÿï¼ˆå¯é€‰ï¼‰

å¦‚æœåœ¨ä¸­å›½åŒºéƒ¨ç½²ï¼Œå¯ä»¥ä½¿ç”¨é•œåƒç«™ç‚¹åŠ é€Ÿä¸‹è½½ï¼š

```yaml
env:
- name: HF_ENDPOINT
  value: "https://hf-mirror.com"
```

---

## 6. éƒ¨ç½²æ­¥éª¤

### 6.1 å‰ç½®å‡†å¤‡

#### 1. å®‰è£… LeaderWorkerSet CRD

```bash
# å®‰è£… LeaderWorkerSet
kubectl apply --server-side -f https://github.com/kubernetes-sigs/lws/releases/download/v0.5.0/manifests.yaml

# éªŒè¯å®‰è£…
kubectl get crd leaderworkersets.leaderworkerset.x-k8s.io
```

#### 2. å®‰è£… HyperPod Inference Operatorï¼ˆå¦‚ä½¿ç”¨ï¼‰

```bash
# å…·ä½“å®‰è£…æ­¥éª¤è¯·å‚è€ƒ AWS å®˜æ–¹æ–‡æ¡£
# https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-hyperpod-inference-operator.html
```

#### 3. é…ç½® GPU Operatorï¼ˆå¦‚æœªå®‰è£…ï¼‰

```bash
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
helm repo update
helm install --wait --generate-name \
  -n gpu-operator --create-namespace \
  nvidia/gpu-operator
```

#### 4. é…ç½® EFAï¼ˆç”¨äºé«˜æ€§èƒ½å®ä¾‹ï¼‰

```bash
# å®‰è£… EFA device plugin
kubectl apply -f https://raw.githubusercontent.com/aws/eks-charts/master/stable/aws-efa-k8s-device-plugin/aws-efa-k8s-device-plugin.yaml
```

### 6.2 åˆ›å»ºå¿…è¦èµ„æº

#### 1. åˆ›å»ºå‘½åç©ºé—´

```bash
kubectl create namespace sglang-inference
```

#### 2. åˆ›å»º HuggingFace Token Secret

```bash
kubectl create secret generic hf-token-secret \
  --from-literal=token=hf_your_token_here \
  -n sglang-inference
```

#### 3. åˆ›å»ºå­˜å‚¨èµ„æº

```bash
# åˆ›å»º StorageClass
kubectl apply -f fsx-lustre-storageclass.yaml

# åˆ›å»º PVC
kubectl apply -f huggingface-cache-pvc.yaml -n sglang-inference

# éªŒè¯ PVC çŠ¶æ€
kubectl get pvc -n sglang-inference
```

### 6.3 éƒ¨ç½² SGLang æœåŠ¡

```bash
# éƒ¨ç½²å¤šèŠ‚ç‚¹ SGLang
kubectl apply -f sglang-multi-node.yaml -n sglang-inference

# æŸ¥çœ‹éƒ¨ç½²çŠ¶æ€
kubectl get leaderworkerset -n sglang-inference

# æŸ¥çœ‹ Pod çŠ¶æ€
kubectl get pods -n sglang-inference -w

# æŸ¥çœ‹ Leader èŠ‚ç‚¹æ—¥å¿—
kubectl logs -l role=leader -n sglang-inference -f
```

### 6.4 éªŒè¯éƒ¨ç½²

#### 1. æ£€æŸ¥ Pod çŠ¶æ€

```bash
# æ‰€æœ‰ Pod åº”è¯¥å¤„äº Running çŠ¶æ€
kubectl get pods -n sglang-inference

# è¾“å‡ºç¤ºä¾‹ï¼š
# NAME                              READY   STATUS    RESTARTS   AGE
# sglang-multi-nodes-0              1/1     Running   0          30m
# sglang-multi-nodes-1              1/1     Running   0          30m
```

#### 2. æ£€æŸ¥æ—¥å¿—

```bash
# æŸ¥çœ‹ Leader èŠ‚ç‚¹æ—¥å¿—ï¼Œç¡®è®¤æ¨¡å‹åŠ è½½æˆåŠŸ
kubectl logs sglang-multi-nodes-0 -n sglang-inference | tail -50

# åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¾“å‡ºï¼š
# INFO: Server started at http://0.0.0.0:30000
# INFO: Model loaded successfully
# INFO: Ready to serve requests
```

#### 3. ç«¯å£è½¬å‘è¿›è¡Œæœ¬åœ°æµ‹è¯•

```bash
# è½¬å‘åˆ°æœ¬åœ°
kubectl port-forward service/sglang-service 30000:30000 -n sglang-inference
```

#### 4. å‘é€æµ‹è¯•è¯·æ±‚

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:30000/health

# ç”Ÿæˆæµ‹è¯•
curl http://localhost:30000/v1/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen3-30B-A3B-Thinking-2507",
    "prompt": "What is machine learning?",
    "max_tokens": 100,
    "temperature": 0.7
  }'

# OpenAI å…¼å®¹ API æµ‹è¯•
curl http://localhost:30000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen3-30B-A3B-Thinking-2507",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Explain quantum computing in simple terms."}
    ],
    "max_tokens": 200
  }'
```

#### 5. ä½¿ç”¨ Python å®¢æˆ·ç«¯æµ‹è¯•

```python
# test_sglang.py
import openai

# è®¾ç½® API ç«¯ç‚¹
openai.api_base = "http://localhost:30000/v1"
openai.api_key = "dummy"  # SGLang ä¸éœ€è¦çœŸå®çš„ API key

# å‘é€è¯·æ±‚
response = openai.ChatCompletion.create(
    model="Qwen/Qwen3-30B-A3B-Thinking-2507",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "What are the benefits of cloud computing?"}
    ],
    max_tokens=150,
    temperature=0.8
)

print(response.choices[0].message.content)
```

---

## 7. æ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ

### 7.1 å®ä¾‹ç±»å‹é€‰æ‹©

| å®ä¾‹ç±»å‹ | GPU | VRAM | æ¨è TP | é€‚åˆæ¨¡å‹å¤§å° | ä»·æ ¼/å°æ—¶ï¼ˆå‚è€ƒï¼‰* |
|---------|-----|------|---------|-------------|----------------|
| ml.p5.48xlarge | 8x H100 | 640GB | 8 | 70B - 405B | ~$98 |
| ml.p4d.24xlarge | 8x A100 | 320GB | 8 | 30B - 180B | ~$33 |
| ml.g5.48xlarge | 8x A10G | 192GB | 8 | 7B - 70B | ~$16 |
| ml.p4de.24xlarge | 8x A100 | 640GB | 8 | 70B - 405B | ~$41 |

**ä»·æ ¼è¯´æ˜**ï¼šä¸Šè¿°ä»·æ ¼ä»…ä¾›å‚è€ƒï¼Œå®é™…ä»·æ ¼ä¼šå› åœ°åŒºã€é¢„ç•™å®ä¾‹ã€Savings Plans ç­‰å› ç´ è€Œå¼‚ã€‚è¯·è®¿é—® [AWS SageMaker å®šä»·é¡µé¢](https://aws.amazon.com/sagemaker/pricing/) è·å–æœ€æ–°ä»·æ ¼ä¿¡æ¯ã€‚

**é€‰æ‹©å»ºè®®**ï¼š
- **è¶…å¤§æ¨¡å‹ï¼ˆ>100Bï¼‰**: ml.p5.48xlargeï¼ˆH100ï¼‰æˆ– ml.p4de.24xlargeï¼ˆA100 80GBï¼‰
- **å¤§æ¨¡å‹ï¼ˆ30B-100Bï¼‰**: ml.p4d.24xlargeï¼ˆA100 40GBï¼‰
- **ä¸­å‹æ¨¡å‹ï¼ˆ7B-30Bï¼‰**: ml.g5.48xlargeï¼ˆA10Gï¼‰
- **å¼€å‘æµ‹è¯•**: ml.g5.12xlargeï¼ˆ4x A10Gï¼‰

### 7.2 SGLang ç‰¹å®šä¼˜åŒ–

#### 1. å†…å­˜ä¼˜åŒ–

```bash
# KV Cache å†…å­˜åˆ†é…
--mem-fraction-static 0.85  # ä¸º KV Cache åˆ†é… 85% çš„ GPU å†…å­˜

# Chunked Prefillï¼ˆå‡å°‘ prefill é˜¶æ®µçš„å†…å­˜å³°å€¼ï¼‰
--chunked-prefill-size 8192  # å°† prefill åˆ†å—å¤„ç†
```

#### 2. æ‰¹å¤„ç†ä¼˜åŒ–

```bash
# æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
--max-running-requests 256

# æœ€å¤§æ‰¹å¤„ç†å¤§å°
--max-total-tokens 8192

# è°ƒåº¦ç­–ç•¥
--schedule-policy lpm  # Longest Prefix Match
```

#### 3. é‡åŒ–æ”¯æŒï¼ˆå‡å°‘å†…å­˜å ç”¨ï¼‰

```bash
# FP8 é‡åŒ–
--quantization fp8

# INT4 é‡åŒ–ï¼ˆéœ€è¦æ¨¡å‹æ”¯æŒï¼‰
--quantization awq
# æˆ–
--quantization gptq
```

#### 4. Prefill-Decode è§£è€¦ï¼ˆé«˜çº§ï¼‰

SGLang v0.5.8 æ”¯æŒ PDï¼ˆPrefill-Decodeï¼‰åˆ†ç¦»æ¨¡å¼ï¼Œå°†è®¡ç®—å¯†é›†å‹çš„ prefill é˜¶æ®µå’Œå†…å­˜å¯†é›†å‹çš„ decode é˜¶æ®µåˆ†å¼€å¤„ç†ï¼Œä»¥æé«˜æ•´ä½“ååé‡ã€‚

**å…³é”®å‚æ•°è¯´æ˜**ï¼š

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--disaggregation-mode` | åˆ†ç¦»æ¨¡å¼ï¼š`prefill` æˆ– `decode` | null |
| `--disaggregation-transfer-backend` | KV Cache ä¼ è¾“åç«¯ | `mooncake` |
| `--disaggregation-bootstrap-port` | Prefill æœåŠ¡å™¨çš„ bootstrap ç«¯å£ | `8998` |
| `--disaggregation-ib-device` | InfiniBand è®¾å¤‡ï¼ˆç”¨äº RDMAï¼‰ | è‡ªåŠ¨æ£€æµ‹ |

**Prefill èŠ‚ç‚¹é…ç½®**ï¼š
```bash
python3 -m sglang.launch_server \
  --model-path <model> \
  --tp 4 \
  --host 0.0.0.0 \
  --port 30000 \
  --disaggregation-mode prefill \
  --disaggregation-transfer-backend mooncake \
  --disaggregation-bootstrap-port 8998 \
  --chunked-prefill-size 4096 \
  --trust-remote-code
```

**Decode èŠ‚ç‚¹é…ç½®**ï¼š
```bash
python3 -m sglang.launch_server \
  --model-path <model> \
  --tp 4 \
  --host 0.0.0.0 \
  --port 30001 \
  --disaggregation-mode decode \
  --disaggregation-transfer-backend mooncake \
  --disable-radix-cache \
  --trust-remote-code
```

**Router é…ç½®**ï¼ˆéœ€è¦å®‰è£… `sglang-router` åŒ…ï¼‰ï¼š
```bash
# å®‰è£… sglang-router
pip install sglang-router

# å¯åŠ¨ router (PD åˆ†ç¦»æ¨¡å¼)
python3 -m sglang_router.launch_router \
  --host 0.0.0.0 \
  --port 8000 \
  --pd-disaggregation \
  --prefill http://<prefill-host>:30000 \
  --decode http://<decode-host>:30001
```

**ä¼ è¾“åç«¯è¯´æ˜**ï¼š
- **mooncake**ï¼ˆé»˜è®¤ï¼‰ï¼šæ”¯æŒ RDMA å’Œ TCPï¼Œé€‚ç”¨äºé«˜æ€§èƒ½ InfiniBand ç¯å¢ƒå’Œæ™®é€šä»¥å¤ªç½‘
- **nixl**ï¼šNVIDIA çš„ KV ä¼ è¾“åº“ï¼Œéœ€è¦ RDMA æ”¯æŒ

**æ³¨æ„**ï¼š
- å¯¹äºæ²¡æœ‰ EFA/InfiniBand çš„å®ä¾‹ï¼ˆå¦‚ g5 ç³»åˆ—ï¼‰ï¼ŒMooncake ä¼šè‡ªåŠ¨å›é€€åˆ° TCP ä¼ è¾“
- å¯ä»¥é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡ `MOONCAKE_TRANSPORT=tcp` å¼ºåˆ¶ä½¿ç”¨ TCP ä¼ è¾“
- EFA æ”¯æŒéœ€è¦å®‰è£… EFA device plugin å¹¶åœ¨å®ä¾‹ç±»å‹ä¸Šå¯ç”¨ EFA

**EFA/RDMA æ”¯æŒçš„å®ä¾‹ç±»å‹**ï¼š
| å®ä¾‹ç±»å‹ | Nitro ç‰ˆæœ¬ | RDMA Read | RDMA Write |
|---------|-----------|-----------|------------|
| g5.12xlarge | v3 | âŒ | âŒ |
| g6.12xlarge | v4 | âœ… | âœ… |
| g6e.12xlarge | v4 | âœ… | âœ… |
| p4d.24xlarge | v4 | âœ… | âŒ |
| p5.48xlarge | v4 | âœ… | âœ… |

**å®Œæ•´éƒ¨ç½²ç¤ºä¾‹**ï¼šå‚è§ `sglang-pd-disaggregated-qwen3-4b.yaml` æ–‡ä»¶ï¼Œæä¾›äº†åœ¨ 2x ml.g6.12xlarge ä¸Šéƒ¨ç½² PD åˆ†ç¦»æ¨¡å¼çš„å®Œæ•´é…ç½® (**å·²éªŒè¯å¯ç”¨** - 2026-01-31)

**å·²çŸ¥é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ**ï¼š

1. **EFA device plugin å´©æºƒ (SIGSEGV)**

   **ç°è±¡**ï¼šEFA device plugin pod å‡ºç° CrashLoopBackOffï¼Œæ—¥å¿—æ˜¾ç¤ºï¼š
   ```
   SIGSEGV: segmentation violation
   github.com/aws/efa-k8s-device-plugin/pkg/efa_topology._Cfunc_efa_gpu_topology_init()
   ```
   `vpc.amazonaws.com/efa` èµ„æºæ˜¾ç¤ºä¸º `<none>`

   **åŸå› **ï¼šEFA device plugin v0.5.6 åœ¨ GPU æ‹“æ‰‘åˆå§‹åŒ–æ—¶å­˜åœ¨ bugï¼Œå½±å“ g6.12xlargeã€g6.48xlarge ç­‰å®ä¾‹ç±»å‹

   **è§£å†³æ–¹æ¡ˆ A - å‡çº§ EFA device pluginï¼ˆæ¨èï¼‰**ï¼š
   ```bash
   # 1. æ£€æŸ¥å½“å‰ç‰ˆæœ¬
   kubectl get daemonset -n kube-system hyperpod-dependencies-aws-efa-k8s-device-plugin -o jsonpath='{.spec.template.spec.containers[0].image}'

   # 2. å‡çº§åˆ° v0.5.13ï¼ˆå·²ä¿®å¤æ­¤é—®é¢˜ï¼‰
   kubectl set image daemonset/hyperpod-dependencies-aws-efa-k8s-device-plugin \
     -n kube-system \
     aws-efa-k8s-device-plugin=602401143452.dkr.ecr.us-west-2.amazonaws.com/eks/aws-efa-k8s-device-plugin:v0.5.13

   # 3. éªŒè¯å‡çº§æˆåŠŸ
   kubectl get pods -n kube-system | grep efa
   # åº”æ˜¾ç¤º Running çŠ¶æ€

   # 4. éªŒè¯ EFA èµ„æºå¯ç”¨
   kubectl get nodes -o custom-columns='NAME:.metadata.name,EFA:.status.allocatable.vpc\.amazonaws\.com/efa'
   # åº”æ˜¾ç¤º EFA: 1 æˆ–æ›´å¤š
   ```

   **è§£å†³æ–¹æ¡ˆ B - ä½¿ç”¨ TCP ä¼ è¾“æ¨¡å¼ï¼ˆå¤‡é€‰ï¼‰**ï¼š
   å¦‚æœæ— æ³•å‡çº§ EFA device pluginï¼Œå¯ä»¥ç§»é™¤ EFA èµ„æºè¯·æ±‚ï¼Œä½¿ç”¨ TCP ä¼ è¾“ï¼š
   ```yaml
   # ç§»é™¤ resources ä¸­çš„ EFA è¯·æ±‚
   # limits:
   #   vpc.amazonaws.com/efa: 1  # åˆ é™¤æ­¤è¡Œ

   # è®¾ç½®ç¯å¢ƒå˜é‡ä½¿ç”¨ TCP
   env:
   - name: MOONCAKE_TRANSPORT
     value: "tcp"
   ```

2. **Router tokenizer åŠ è½½è­¦å‘Š**
   - ç°è±¡ï¼šRouter æ—¥å¿—æ˜¾ç¤º "Failed to load tokenizer" é”™è¯¯
   - åŸå› ï¼šRouter å°è¯•ä» HuggingFace åŠ è½½æœ¬åœ°è·¯å¾„çš„æ¨¡å‹
   - å½±å“ï¼š**æ— å½±å“** - Router ä»å¯æ­£å¸¸å·¥ä½œï¼Œå› ä¸º tokenization ç”± worker å¤„ç†
   - æ— éœ€å¤„ç†ï¼Œå¯å¿½ç•¥æ­¤è­¦å‘Š

3. **EFA device plugin ç‰ˆæœ¬å…¼å®¹æ€§å‚è€ƒ**

   | ç‰ˆæœ¬ | g6.12xlarge | g6.48xlarge | p5.48xlarge | è¯´æ˜ |
   |------|-------------|-------------|-------------|------|
   | v0.5.6 | âŒ å´©æºƒ | âŒ å´©æºƒ | æœªæµ‹è¯• | HyperPod é»˜è®¤ç‰ˆæœ¬ |
   | v0.5.13 | âœ… æ­£å¸¸ | âœ… æ­£å¸¸ | âœ… æ­£å¸¸ | **æ¨èç‰ˆæœ¬** |

### 7.3 ç½‘ç»œä¼˜åŒ–

#### EFA é…ç½®ï¼ˆæ¨èç”¨äº P5/P4 å®ä¾‹ï¼‰

```yaml
env:
# å¯ç”¨ RDMA
- name: NCCL_IB_DISABLE
  value: "0"

# GPU Direct RDMA
- name: NCCL_NET_GDR_LEVEL
  value: "5"

# ä½¿ç”¨ EFA
- name: FI_PROVIDER
  value: "efa"

- name: FI_EFA_USE_DEVICE_RDMA
  value: "1"

# EFA ç›¸å…³ä¼˜åŒ–
- name: FI_EFA_FORK_SAFE
  value: "1"

- name: NCCL_PROTO
  value: "simple"
```

### 7.4 æ¨èçš„æ¨¡å‹é…ç½®

**å‚æ•°è¯´æ˜**ï¼šä»¥ä¸‹é…ç½®ä½¿ç”¨ `--tp` å‚æ•°æŒ‡å®š Tensor Parallelism å¤§å°ã€‚`--tp` å’Œ `--tp-size` æ˜¯ç­‰ä»·çš„å‚æ•°åˆ«åï¼Œä¸¤è€…å¯ä»¥äº’æ¢ä½¿ç”¨ã€‚

#### Qwen3-30B-A3Bï¼ˆå•èŠ‚ç‚¹ï¼‰
```bash
python3 -m sglang.launch_server \
  --model-path Qwen/Qwen3-30B-A3B-Thinking-2507 \
  --tp 8 \
  --mem-fraction-static 0.85 \
  --chunked-prefill-size 8192 \
  --context-length 32768 \
  --max-running-requests 256 \
  --trust-remote-code
```

#### Llama 3.1 405Bï¼ˆå¤šèŠ‚ç‚¹ï¼‰
```bash
# Leader (Rank 0)
python3 -m sglang.launch_server \
  --model-path meta-llama/Meta-Llama-3.1-405B-Instruct \
  --tp 16 \
  --dist-init-addr $LEADER_IP:20000 \
  --nnodes 4 \
  --node-rank 0 \
  --quantization fp8 \
  --mem-fraction-static 0.90

# Worker (Rank 1, 2, 3)
python3 -m sglang.launch_server \
  --model-path meta-llama/Meta-Llama-3.1-405B-Instruct \
  --tp 16 \
  --dist-init-addr $LEADER_IP:20000 \
  --nnodes 4 \
  --node-rank <1|2|3> \
  --quantization fp8 \
  --mem-fraction-static 0.90
```

#### DeepSeek R1 671Bï¼ˆå¤šèŠ‚ç‚¹ï¼ŒMoE æ¨¡å‹ï¼‰
```bash
# éœ€è¦ 8 èŠ‚ç‚¹ï¼Œæ¯èŠ‚ç‚¹ 8x H100
# DeepSeek R1 æ˜¯ MoE (Mixture of Experts) æ¨¡å‹ï¼Œéœ€è¦ä½¿ç”¨ Expert Parallelism
python3 -m sglang.launch_server \
  --model-path deepseek-ai/DeepSeek-R1 \
  --tp 16 \
  --ep-size 8 \
  --dist-init-addr $LEADER_IP:20000 \
  --nnodes 8 \
  --node-rank <0-7> \
  --quantization fp8
```

**æ³¨æ„**ï¼š`--ep-size` (Expert Parallelism) ä»…é€‚ç”¨äº MoE æ¨¡å‹ï¼ˆå¦‚ DeepSeek V3/R1ã€Mixtralï¼‰ã€‚å¯¹äºæ ‡å‡† Transformer æ¨¡å‹ï¼ˆå¦‚ Llamaï¼‰ï¼Œä»…éœ€ä½¿ç”¨ `--tp` å‚æ•°ã€‚

### 7.5 è‡ªåŠ¨æ‰©å±•é…ç½®

ä½¿ç”¨ KEDA å®ç°åŸºäºè´Ÿè½½çš„è‡ªåŠ¨æ‰©å±•ï¼š

```yaml
# keda-scaledobject.yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: sglang-autoscaler
  namespace: sglang-inference
spec:
  scaleTargetRef:
    kind: LeaderWorkerSet
    name: sglang-multi-nodes
  minReplicaCount: 1
  maxReplicaCount: 4
  pollingInterval: 30
  cooldownPeriod: 300
  triggers:
  - type: prometheus
    metadata:
      serverAddress: http://prometheus:9090
      metricName: sglang_queue_size
      threshold: '50'
      query: |
        sum(sglang_running_requests) by (pod)
```

---

## 8. ç›‘æ§å’Œå¯è§‚æµ‹æ€§

### 8.1 Prometheus é›†æˆ

SGLang åŸç”Ÿæ”¯æŒ Prometheus æŒ‡æ ‡å¯¼å‡ºã€‚

#### å¯ç”¨æŒ‡æ ‡

```bash
python3 -m sglang.launch_server \
  --model-path <model> \
  --enable-metrics \
  --metrics-port 9090
```

#### å…³é”®æŒ‡æ ‡

| æŒ‡æ ‡åç§° | ç±»å‹ | è¯´æ˜ |
|---------|------|------|
| `sglang_prompt_tokens_total` | Counter | æ€» prompt tokens æ•° |
| `sglang_generation_tokens_total` | Counter | æ€»ç”Ÿæˆ tokens æ•° |
| `sglang_time_to_first_token_seconds` | Histogram | é¦– token å»¶è¿Ÿ |
| `sglang_time_per_output_token_seconds` | Histogram | æ¯ä¸ªè¾“å‡º token çš„æ—¶é—´ |
| `sglang_e2e_request_latency_seconds` | Histogram | ç«¯åˆ°ç«¯è¯·æ±‚å»¶è¿Ÿ |
| `sglang_running_requests` | Gauge | å½“å‰è¿è¡Œä¸­çš„è¯·æ±‚æ•° |
| `sglang_waiting_requests` | Gauge | ç­‰å¾…é˜Ÿåˆ—ä¸­çš„è¯·æ±‚æ•° |
| `sglang_gpu_cache_usage_perc` | Gauge | GPU ç¼“å­˜ä½¿ç”¨ç‡ |

#### Prometheus é…ç½®

```yaml
# prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: sglang-inference
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    scrape_configs:
    - job_name: 'sglang'
      kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
          - sglang-inference
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
```

### 8.2 Grafana ä»ªè¡¨æ¿

åˆ›å»º Grafana ä»ªè¡¨æ¿ç›‘æ§å…³é”®æŒ‡æ ‡ï¼š

**æ¨èé¢æ¿**ï¼š
1. **ååé‡**ï¼šæ¯ç§’å¤„ç†çš„ tokens æ•°
2. **å»¶è¿Ÿ**ï¼šP50/P95/P99 å»¶è¿Ÿåˆ†å¸ƒ
3. **GPU åˆ©ç”¨ç‡**ï¼šå„ GPU çš„ä½¿ç”¨ç‡
4. **é˜Ÿåˆ—é•¿åº¦**ï¼šç­‰å¾…å’Œè¿è¡Œä¸­çš„è¯·æ±‚æ•°
5. **ç¼“å­˜å‘½ä¸­ç‡**ï¼šKV Cache å‘½ä¸­ç‡
6. **é”™è¯¯ç‡**ï¼šå¤±è´¥è¯·æ±‚çš„æ¯”ä¾‹

### 8.3 CloudWatch é›†æˆ

HyperPod åŸç”Ÿé›†æˆ CloudWatch Container Insightsï¼š

```bash
# å®‰è£… CloudWatch Agent
kubectl apply -f https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluentd-quickstart.yaml
```

### 8.4 æ—¥å¿—èšåˆ

ä½¿ç”¨ FluentBit æ”¶é›†æ—¥å¿—åˆ° CloudWatch Logsï¼š

```yaml
# fluent-bit-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: amazon-cloudwatch
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         5
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf

    [INPUT]
        Name              tail
        Path              /var/log/containers/sglang*.log
        Parser            docker
        Tag               sglang.*
        Refresh_Interval  5
        Mem_Buf_Limit     50MB

    [OUTPUT]
        Name                cloudwatch_logs
        Match               sglang.*
        region              us-west-2
        log_group_name      /aws/hyperpod/sglang
        log_stream_prefix   inference-
        auto_create_group   true
```

---

## 9. æ•…éšœæ’æŸ¥

### 9.1 å¸¸è§é—®é¢˜

#### é—®é¢˜ 1ï¼šæ¨¡å‹ä¸‹è½½è¶…æ—¶

**ç—‡çŠ¶**ï¼š
```
ERROR: Failed to download model from HuggingFace
Connection timeout after 1800 seconds
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å¢åŠ å¥åº·æ£€æŸ¥åˆå§‹å»¶è¿Ÿï¼š
```yaml
livenessProbe:
  initialDelaySeconds: 3600  # å¢åŠ åˆ° 60 åˆ†é’Ÿ
```

2. ä½¿ç”¨ InitContainer é¢„ä¸‹è½½ï¼š
```yaml
initContainers:
- name: model-downloader
  # ... (å‚è§ç¬¬ 5.5 èŠ‚)
```

3. ä½¿ç”¨é•œåƒç«™ç‚¹ï¼ˆä¸­å›½åŒºï¼‰ï¼š
```yaml
env:
- name: HF_ENDPOINT
  value: "https://hf-mirror.com"
```

#### é—®é¢˜ 2ï¼šGPU OOMï¼ˆå†…å­˜ä¸è¶³ï¼‰

**ç—‡çŠ¶**ï¼š
```
CUDA out of memory. Tried to allocate 2.0 GiB
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å‡å°‘ KV Cache å†…å­˜åˆ†é…ï¼š
```bash
--mem-fraction-static 0.75  # ä» 0.85 é™ä½åˆ° 0.75
```

2. å¯ç”¨é‡åŒ–ï¼š
```bash
--quantization fp8
```

3. å‡å°‘å¹¶å‘è¯·æ±‚æ•°ï¼š
```bash
--max-running-requests 128  # ä» 256 é™ä½åˆ° 128
```

4. ä½¿ç”¨æ›´å¤§çš„å®ä¾‹æˆ–æ›´å¤šèŠ‚ç‚¹

#### é—®é¢˜ 3ï¼šèŠ‚ç‚¹é—´é€šä¿¡å¤±è´¥

**ç—‡çŠ¶**ï¼š
```
NCCL error: unhandled system error
Failed to connect to peer node
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥ç½‘ç»œé…ç½®ï¼š
```bash
# ç¡®ä¿èŠ‚ç‚¹é—´å¯ä»¥äº’ç›¸è®¿é—®
kubectl exec -it sglang-multi-nodes-0 -- ping sglang-multi-nodes-1
```

2. æ£€æŸ¥å®‰å…¨ç»„è§„åˆ™ï¼ˆå…è®¸æ‰€æœ‰ç«¯å£é€šä¿¡ï¼‰

3. éªŒè¯ EFA é…ç½®ï¼š
```bash
kubectl describe pod sglang-multi-nodes-0 | grep efa
```

4. æ£€æŸ¥ NCCL æ—¥å¿—ï¼š
```yaml
env:
- name: NCCL_DEBUG
  value: "INFO"  # æˆ– "TRACE" è·å–æ›´è¯¦ç»†æ—¥å¿—
```

#### é—®é¢˜ 4ï¼šHuggingFace Token æƒé™ä¸è¶³

**ç—‡çŠ¶**ï¼š
```
401 Client Error: Unauthorized for url
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ç¡®è®¤ Token æœ‰æ•ˆï¼š
```bash
# åœ¨æœ¬åœ°æµ‹è¯•
export HF_TOKEN=hf_xxx
huggingface-cli whoami
```

2. ç¡®è®¤å·²æ¥å—æ¨¡å‹è®¸å¯åè®®ï¼ˆé—¨æ§æ¨¡å‹ï¼‰

3. é‡æ–°åˆ›å»º Secretï¼š
```bash
kubectl delete secret hf-token-secret -n sglang-inference
kubectl create secret generic hf-token-secret \
  --from-literal=token=hf_new_token \
  -n sglang-inference
```

#### é—®é¢˜ 5ï¼šPod ä¸€ç›´å¤„äº Pending çŠ¶æ€

**ç—‡çŠ¶**ï¼š
```
kubectl get pods
NAME                      READY   STATUS    RESTARTS   AGE
sglang-multi-nodes-0      0/1     Pending   0          10m
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥åŸå› ï¼š
```bash
kubectl describe pod sglang-multi-nodes-0 -n sglang-inference
```

2. å¸¸è§åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š
   - **èµ„æºä¸è¶³**ï¼šæ‰©å±•é›†ç¾¤æˆ–å‡å°‘èµ„æºè¯·æ±‚
   - **PVC æœªç»‘å®š**ï¼šæ£€æŸ¥ PVC çŠ¶æ€
   ```bash
   kubectl get pvc -n sglang-inference
   ```
   - **èŠ‚ç‚¹é€‰æ‹©å™¨ä¸åŒ¹é…**ï¼šè°ƒæ•´ nodeSelector æˆ–æ ‡ç­¾
   - **æ±¡ç‚¹/å®¹å¿åº¦é—®é¢˜**ï¼šæ·»åŠ æ­£ç¡®çš„ tolerations

#### é—®é¢˜ 6ï¼šæ¨ç†é€Ÿåº¦æ…¢

**ç—‡çŠ¶**ï¼š
- Time to First Token (TTFT) > 5 ç§’
- Tokens per Second (TPS) < 50

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å¯ç”¨ Chunked Prefillï¼š
```bash
--chunked-prefill-size 8192
```

2. è°ƒæ•´æ‰¹å¤„ç†å‚æ•°ï¼š
```bash
--max-running-requests 256
--max-total-tokens 8192
```

3. æ£€æŸ¥ GPU åˆ©ç”¨ç‡ï¼š
```bash
kubectl exec -it sglang-multi-nodes-0 -- nvidia-smi
```

4. éªŒè¯ EFA æ˜¯å¦æ­£å¸¸å·¥ä½œï¼ˆå¤šèŠ‚ç‚¹ï¼‰ï¼š
```bash
# æ£€æŸ¥ EFA è®¾å¤‡
kubectl exec -it sglang-multi-nodes-0 -- fi_info
```

### 9.2 è°ƒè¯•å‘½ä»¤é›†åˆ

```bash
# æŸ¥çœ‹æ‰€æœ‰èµ„æº
kubectl get all -n sglang-inference

# æŸ¥çœ‹è¯¦ç»†äº‹ä»¶
kubectl get events -n sglang-inference --sort-by='.lastTimestamp'

# æŸ¥çœ‹ Pod æ—¥å¿—
kubectl logs -f sglang-multi-nodes-0 -n sglang-inference

# è¿›å…¥å®¹å™¨è°ƒè¯•
kubectl exec -it sglang-multi-nodes-0 -n sglang-inference -- /bin/bash

# æŸ¥çœ‹èµ„æºä½¿ç”¨
kubectl top pods -n sglang-inference
kubectl top nodes

# æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…å†µ
kubectl exec -it sglang-multi-nodes-0 -n sglang-inference -- nvidia-smi

# æµ‹è¯•ç½‘ç»œè¿é€šæ€§
kubectl exec -it sglang-multi-nodes-0 -n sglang-inference -- \
  curl http://sglang-service:30000/health

# æŸ¥çœ‹ Prometheus æŒ‡æ ‡
kubectl port-forward service/sglang-service 9090:9090 -n sglang-inference
curl http://localhost:9090/metrics
```

### 9.3 æ€§èƒ½åŸºå‡†æµ‹è¯•

ä½¿ç”¨å®˜æ–¹å·¥å…·è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼š

```bash
# å®‰è£… SGLang å®¢æˆ·ç«¯
pip install "sglang[all]"

# è¿è¡ŒåŸºå‡†æµ‹è¯•
python -m sglang.bench_serving \
  --backend sglang \
  --host localhost \
  --port 30000 \
  --dataset-name random \
  --random-input 1024 \
  --random-output 256 \
  --num-prompts 100 \
  --request-rate 10
```

**å…³é”®æŒ‡æ ‡**ï¼š
- **Throughput**: åº” > 1000 tokens/sï¼ˆå•èŠ‚ç‚¹ 70B æ¨¡å‹ï¼‰
- **TTFT (P50)**: åº” < 2s
- **TPOT (P50)**: åº” < 50msï¼ˆæ¯ä¸ªè¾“å‡º token çš„æ—¶é—´ï¼‰

---

## 10. å®é™…æ¡ˆä¾‹ç ”ç©¶

### 10.1 Osmosis AI æ¡ˆä¾‹

**å…¬å¸**: Osmosis AI (Gulp.ai)
**åº”ç”¨åœºæ™¯**: LLM å¾®è°ƒæœŸé—´çš„æ¨¡å‹æ¨ç†
**æŠ€æœ¯æ ˆ**: AWS HyperPod + EKS + Ray + SGLang + VeRL

#### æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       AWS SageMaker HyperPod                 â”‚
â”‚  (é›†ç¾¤ç¼–æ’ã€è‡ªåŠ¨æ•…éšœæ¢å¤ã€èµ„æºä¼˜åŒ–)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Amazon EKS Cluster                   â”‚
â”‚  - GPU èŠ‚ç‚¹ç®¡ç†                              â”‚
â”‚  - ç½‘ç»œé…ç½® (VPC, Subnet, Security Groups)   â”‚
â”‚  - å­˜å‚¨é›†æˆ (FSx for Lustre, EBS)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Ray Cluster                          â”‚
â”‚  - åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦                            â”‚
â”‚  - èµ„æºåˆ†é…                                  â”‚
â”‚  - å·¥ä½œèŠ‚ç‚¹ç®¡ç†                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SGLang    â”‚    â”‚   VeRL         â”‚
â”‚  (æ¨ç†å¼•æ“)  â”‚â—„â”€â”€â”€â”¤  (å¼ºåŒ–å­¦ä¹ æ¡†æ¶) â”‚
â”‚             â”‚    â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### å…³é”®æˆæœ

1. **æ€§èƒ½æå‡**
   - GPU åˆ©ç”¨ç‡ä» 60% æå‡åˆ° 85%+
   - è®­ç»ƒæ—¶é—´å‡å°‘ 40%
   - Token ç”Ÿæˆé€Ÿåº¦æå‡ 2-3x

2. **æˆæœ¬ä¼˜åŒ–**
   - é€šè¿‡åŠ¨æ€æ‰¹å¤„ç†é™ä½è®¡ç®—æˆæœ¬ 35%
   - ç»Ÿä¸€è®­ç»ƒ/æ¨ç†åŸºç¡€è®¾æ–½ï¼Œå‡å°‘èµ„æºæµªè´¹

3. **è¿è¥æ•ˆç‡**
   - HyperPod è‡ªåŠ¨æ•…éšœæ¢å¤ï¼Œå‡å°‘äººå·¥å¹²é¢„
   - Docker åŒ–éƒ¨ç½²ç¡®ä¿è·¨ç¯å¢ƒä¸€è‡´æ€§

#### æŠ€æœ¯æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ

| æŒ‘æˆ˜ | è§£å†³æ–¹æ¡ˆ |
|------|---------|
| **CUDA/PyTorch å…¼å®¹æ€§** | æ„å»ºè‡ªå®šä¹‰ Docker é•œåƒï¼Œå›ºå®šä¾èµ–ç‰ˆæœ¬ |
| **å¤šèŠ‚ç‚¹é€šä¿¡** | é…ç½® EFAï¼Œä¼˜åŒ– NCCL å‚æ•° |
| **GPU åˆ©ç”¨ç‡ä½** | ä½¿ç”¨ SGLang çš„åŠ¨æ€æ‰¹å¤„ç†å’Œ RadixAttention |
| **æ¨¡å‹åŠ è½½æ…¢** | ä½¿ç”¨ FSx for Lustre å…±äº«å­˜å‚¨ |

### 10.2 å…¶ä»–å‚è€ƒæ¡ˆä¾‹

#### æ¡ˆä¾‹ï¼šThomson Reuters
- **åœºæ™¯**: å¤§è§„æ¨¡çŸ¥è¯†å›¾è°±é—®ç­”
- **é…ç½®**: 4 èŠ‚ç‚¹ ml.p4d.24xlarge (32x A100)
- **æ¨¡å‹**: è‡ªå®šä¹‰ 175B å‚æ•°æ¨¡å‹
- **æ•ˆæœ**: æ”¯æŒ 1000+ QPSï¼ŒP99 å»¶è¿Ÿ < 3s

#### æ¡ˆä¾‹ï¼šPerplexity AI
- **åœºæ™¯**: å®æ—¶æœç´¢å¢å¼ºç”Ÿæˆ
- **é…ç½®**: åŠ¨æ€æ‰©å±• 2-8 èŠ‚ç‚¹
- **æ¨¡å‹**: Llama 70B + è‡ªå®šä¹‰æ£€ç´¢ç³»ç»Ÿ
- **æ•ˆæœ**: æ”¯æŒç™¾ä¸‡çº§ DAUï¼Œå¹³å‡å“åº”æ—¶é—´ < 2s

---

## 11. å‚è€ƒèµ„æº

### 11.1 å®˜æ–¹æ–‡æ¡£

#### AWS æ–‡æ¡£
- [HyperPod æ¨¡å‹éƒ¨ç½²æŒ‡å—](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-hyperpod-model-deployment.html)
- [HyperPod EKS ç¼–æ’](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-hyperpod-eks.html)
- [HyperPod æ¨ç†å¯è§‚æµ‹æ€§](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-hyperpod-model-deployment-observability.html)
- [HyperPod ä»»åŠ¡æ²»ç†](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-hyperpod-task-governance.html)

#### SGLang æ–‡æ¡£
- [SGLang GitHub ä»“åº“](https://github.com/sgl-project/sglang)
- [SGLang Transformers Backend é›†æˆ](https://huggingface.co/blog/transformers-backend-sglang)
- [SGLang æ–‡æ¡£](https://sgl-project.github.io/)

#### Kubernetes æ–‡æ¡£
- [LeaderWorkerSet API](https://lws.sigs.k8s.io/)
- [Kubernetes GPU è°ƒåº¦](https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/)
- [KEDA è‡ªåŠ¨æ‰©å±•](https://keda.sh/)

### 11.2 åšå®¢æ–‡ç« 

- [HyperPod æ”¯æŒ Multi-Instance GPU](https://aws.amazon.com/blogs/machine-learning/hyperpod-now-supports-multi-instance-gpu-to-maximize-gpu-utilization-for-generative-ai-tasks/)
- [ä½¿ç”¨ HyperPod CLI å’Œ SDK è®­ç»ƒéƒ¨ç½²æ¨¡å‹](https://aws.amazon.com/blogs/machine-learning/train-and-deploy-models-on-amazon-sagemaker-hyperpod-using-the-new-hyperpod-cli-and-sdk/)
- [EKS æ”¯æŒ HyperPod ä»‹ç»](https://aws.amazon.com/blogs/machine-learning/introducing-amazon-eks-support-in-amazon-sagemaker-hyperpod/)
- [Kubernetes LLM æ¨ç†æ¶æ„æ¦‚è¿°](https://rudeigerc.dev/posts/kubernetes-based-llm-inference-architectures-an-overview/)

### 11.3 å¼€æºé¡¹ç›®

- [HyperPod é›†ç¾¤è®¾ç½®èµ„äº§](https://github.com/aws/sagemaker-hyperpod-cluster-setup)
- [Awesome åˆ†å¸ƒå¼è®­ç»ƒ](https://github.com/aws-samples/awsome-distributed-training)
- [aws-do-hyperpod](https://github.com/aws-samples/aws-do-hyperpod)
- [SGLang é¡¹ç›®](https://github.com/sgl-project/sglang)
- [LeaderWorkerSet](https://github.com/kubernetes-sigs/lws)

### 11.4 æ¡ˆä¾‹ç ”ç©¶

- [Osmosis AI æ¡ˆä¾‹](https://www.tech42consulting.com/case-studies/case-study-osmosis-ai-fine-tuning)
- [Alibaba Cloud å¤šèŠ‚ç‚¹éƒ¨ç½²](https://www.alibabacloud.com/help/en/ack/cloud-native-ai-suite/user-guide/deploy-multi-machine-distributed-inference-services)
- [NVIDIA Dynamo on AKS](https://blog.aks.azure.com/2025/10/24/dynamo-on-aks)

### 11.5 è§†é¢‘æ•™ç¨‹

- [AWS re:Invent - HyperPod æ·±åº¦è§£æ](https://www.youtube.com/results?search_query=aws+hyperpod)
- [HyperPod Workshop](https://catalog.workshops.aws/sagemaker-hyperpod/)

### 11.6 ç¤¾åŒºèµ„æº

- [AWS ML Community](https://github.com/aws/amazon-sagemaker-examples)
- [HuggingFace Forums](https://discuss.huggingface.co/)
- [SGLang GitHub Discussions](https://github.com/sgl-project/sglang/discussions)

---

## é™„å½• Aï¼šå®Œæ•´çš„é…ç½®æ–‡ä»¶æ¨¡æ¿

### A.1 ç”Ÿäº§ç¯å¢ƒå®Œæ•´é…ç½®

å»ºè®®çš„æ–‡ä»¶ç»“æ„ï¼š
```
deployment/
â”œâ”€â”€ 01-namespace.yaml
â”œâ”€â”€ 02-secrets.yaml
â”œâ”€â”€ 03-storage-class.yaml
â”œâ”€â”€ 04-pvc.yaml
â”œâ”€â”€ 05-sglang-deployment.yaml
â”œâ”€â”€ 06-service.yaml
â”œâ”€â”€ 07-ingress.yaml
â”œâ”€â”€ 08-monitoring.yaml
â””â”€â”€ 09-autoscaling.yaml
```

### A.2 å¸¸ç”¨æ¨¡å‹é…ç½®é€ŸæŸ¥è¡¨

| æ¨¡å‹ | Model ID | æœ€å° GPU | æ¨èå®ä¾‹ | TP | èŠ‚ç‚¹æ•° |
|------|----------|---------|---------|----|----|
| Llama 3.2 1B | `meta-llama/Llama-3.2-1B-Instruct` | 1x A10G | ml.g5.2xlarge | 1 | 1 |
| Llama 3.1 8B | `meta-llama/Llama-3.1-8B-Instruct` | 1x A10G | ml.g5.2xlarge | 1 | 1 |
| Llama 3.1 70B | `meta-llama/Llama-3.1-70B-Instruct` | 8x A100 | ml.p4d.24xlarge | 8 | 1 |
| Llama 3.1 405B | `meta-llama/Meta-Llama-3.1-405B-Instruct` | 16x H100 | ml.p5.48xlarge | 16 | 2 |
| DeepSeek R1 32B | `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B` | 4x A100 | ml.p4d.24xlarge | 4 | 1 |
| DeepSeek R1 671B | `deepseek-ai/DeepSeek-R1` | 64x H100 | ml.p5.48xlarge | 16 | 8 |
| Qwen 2.5 72B | `Qwen/Qwen2.5-72B-Instruct` | 8x A100 | ml.p4d.24xlarge | 8 | 1 |

---

## é™„å½• Bï¼šæœ¯è¯­è¡¨

| æœ¯è¯­ | å…¨ç§° | è¯´æ˜ |
|------|------|------|
| **HyperPod** | Amazon SageMaker HyperPod | AWS æ‰˜ç®¡çš„å¤§è§„æ¨¡è®­ç»ƒå’Œæ¨ç†æœåŠ¡ |
| **EKS** | Elastic Kubernetes Service | AWS æ‰˜ç®¡çš„ Kubernetes æœåŠ¡ |
| **SGLang** | Structured Generation Language | é«˜æ€§èƒ½ LLM æ¨ç†æ¡†æ¶ |
| **TP** | Tensor Parallelism | å¼ é‡å¹¶è¡Œï¼Œå°†æ¨¡å‹å±‚åˆ‡åˆ†åˆ°å¤šä¸ª GPU |
| **EP** | Expert Parallelism | ä¸“å®¶å¹¶è¡Œï¼Œç”¨äº MoE æ¨¡å‹ |
| **DP** | Data Parallelism | æ•°æ®å¹¶è¡Œï¼Œå°†æ‰¹æ¬¡åˆ†é…åˆ°å¤šä¸ª GPU |
| **EFA** | Elastic Fabric Adapter | AWS é«˜æ€§èƒ½ç½‘ç»œæ¥å£ |
| **RDMA** | Remote Direct Memory Access | è¿œç¨‹ç›´æ¥å†…å­˜è®¿é—® |
| **NCCL** | NVIDIA Collective Communication Library | NVIDIA é›†åˆé€šä¿¡åº“ |
| **MIG** | Multi-Instance GPU | GPU åˆ†åŒºæŠ€æœ¯ |
| **KV Cache** | Key-Value Cache | æ³¨æ„åŠ›æœºåˆ¶çš„é”®å€¼ç¼“å­˜ |
| **TTFT** | Time to First Token | é¦– token å»¶è¿Ÿ |
| **TPOT** | Time per Output Token | æ¯ä¸ªè¾“å‡º token çš„æ—¶é—´ |
| **TPS** | Tokens per Second | æ¯ç§’ç”Ÿæˆçš„ tokens æ•° |
| **QPS** | Queries per Second | æ¯ç§’æŸ¥è¯¢æ•° |

---

## é™„å½• Cï¼šæ•…éšœæ’æŸ¥æ¸…å•

### éƒ¨ç½²å‰æ£€æŸ¥
- [ ] HyperPod EKS é›†ç¾¤å·²åˆ›å»ºå¹¶æ­£å¸¸è¿è¡Œ
- [ ] LeaderWorkerSet CRD å·²å®‰è£…
- [ ] GPU Operator å·²å®‰è£…å¹¶æ­£å¸¸å·¥ä½œ
- [ ] EFA Device Plugin å·²å®‰è£…ï¼ˆå¦‚ä½¿ç”¨é«˜æ€§èƒ½å®ä¾‹ï¼‰
- [ ] FSx for Lustre æˆ–å…¶ä»–å…±äº«å­˜å‚¨å·²é…ç½®
- [ ] HuggingFace Token Secret å·²åˆ›å»º
- [ ] ç½‘ç»œé…ç½®æ­£ç¡®ï¼ˆVPCã€å®‰å…¨ç»„ã€å­ç½‘ï¼‰
- [ ] IAM è§’è‰²å’Œæƒé™å·²é…ç½®

### éƒ¨ç½²åæ£€æŸ¥
- [ ] æ‰€æœ‰ Pod å¤„äº Running çŠ¶æ€
- [ ] Leader èŠ‚ç‚¹æ—¥å¿—æ˜¾ç¤ºæ¨¡å‹åŠ è½½æˆåŠŸ
- [ ] `/health` ç«¯ç‚¹è¿”å› 200 OK
- [ ] å¯ä»¥æˆåŠŸå‘é€æµ‹è¯•æ¨ç†è¯·æ±‚
- [ ] Prometheus æŒ‡æ ‡å¯ä»¥æ­£å¸¸æŠ“å–
- [ ] GPU åˆ©ç”¨ç‡æ­£å¸¸ï¼ˆnvidia-smiï¼‰
- [ ] èŠ‚ç‚¹é—´ç½‘ç»œé€šä¿¡æ­£å¸¸ï¼ˆå¤šèŠ‚ç‚¹ï¼‰

### æ€§èƒ½æ£€æŸ¥
- [ ] TTFT < 5sï¼ˆP95ï¼‰
- [ ] TPOT < 100msï¼ˆP95ï¼‰
- [ ] GPU åˆ©ç”¨ç‡ > 70%
- [ ] å†…å­˜ä½¿ç”¨ç¨³å®šï¼Œæ—  OOM
- [ ] è¯·æ±‚é˜Ÿåˆ—é•¿åº¦åˆç†
- [ ] é”™è¯¯ç‡ < 1%

---

## é™„å½• Dï¼šè”ç³»å’Œæ”¯æŒ

### AWS æ”¯æŒ
- **AWS Support Center**: https://console.aws.amazon.com/support/
- **HyperPod è®ºå›**: https://repost.aws/tags/TAnYfKYd-eSE-s4QOZFG-ayw/amazon-sage-maker-hyper-pod

### ç¤¾åŒºæ”¯æŒ
- **SGLang GitHub Issues**: https://github.com/sgl-project/sglang/issues
- **SGLang Discussions**: https://github.com/sgl-project/sglang/discussions

### æŠ€æœ¯å’¨è¯¢
å¦‚éœ€æŠ€æœ¯å’¨è¯¢æˆ–æ¶æ„è®¾è®¡æ”¯æŒï¼Œå¯è”ç³»ï¼š
- AWS Solutions Architects
- AWS Professional Services
- AWS Partner Network (APN) åˆä½œä¼™ä¼´

---

## æ–‡æ¡£å˜æ›´å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ | å˜æ›´è¯´æ˜ | ä½œè€… |
|------|------|---------|------|
| v1.5 | 2026-01-31 | **EFA device plugin å‡çº§æŒ‡å—**ï¼šè®°å½• v0.5.6 å´©æºƒé—®é¢˜åŠå‡çº§åˆ° v0.5.13 çš„è§£å†³æ–¹æ¡ˆï¼Œæ·»åŠ ç‰ˆæœ¬å…¼å®¹æ€§è¡¨æ ¼ | æŠ€æœ¯è°ƒç ”å›¢é˜Ÿ |
| v1.4 | 2026-01-31 | **éªŒè¯ PD åˆ†ç¦»éƒ¨ç½²**ï¼šåœ¨ 2x ml.g6.12xlarge ä¸ŠæˆåŠŸéªŒè¯ Qwen3-4B æ¨¡å‹ PD åˆ†ç¦»éƒ¨ç½²ï¼Œæ·»åŠ å·²çŸ¥é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ | æŠ€æœ¯è°ƒç ”å›¢é˜Ÿ |
| v1.3 | 2026-01-31 | ä¿®æ­£ Router é…ç½®ä½¿ç”¨ sglang-router åŒ…ï¼Œæ·»åŠ  EFA/RDMA å®ä¾‹ç±»å‹æ”¯æŒè¡¨ï¼Œæ›´æ–°éƒ¨ç½²ç¤ºä¾‹ | æŠ€æœ¯è°ƒç ”å›¢é˜Ÿ |
| v1.2 | 2026-01-31 | å‡çº§ SGLang ç‰ˆæœ¬åˆ° v0.5.8ï¼Œå®Œå–„ PD åˆ†ç¦»æ¨¡å¼é…ç½®è¯´æ˜ï¼Œæ·»åŠ  mooncake ä¼ è¾“åç«¯è¯¦ç»†å‚æ•° | æŠ€æœ¯è°ƒç ”å›¢é˜Ÿ |
| v1.1 | 2026-01-30 | ä¿®æ­£å‚æ•°è¯´æ˜ã€æ·»åŠ ç«¯å£å’Œä»·æ ¼è¯´æ˜ã€å®Œå–„ MoE æ¨¡å‹é…ç½®æ³¨é‡Š | æŠ€æœ¯è°ƒç ”å›¢é˜Ÿ |
| v1.0 | 2026-01-30 | åˆå§‹ç‰ˆæœ¬å‘å¸ƒ | æŠ€æœ¯è°ƒç ”å›¢é˜Ÿ |

---

**æœ€åæ›´æ–°**: 2026-01-31
**æ–‡æ¡£ç»´æŠ¤**: æŠ€æœ¯è°ƒç ”å›¢é˜Ÿ
**è®¸å¯åè®®**: CC BY-SA 4.0

---

Â© 2026 æŠ€æœ¯è°ƒç ”å›¢é˜Ÿã€‚æœ¬æ–‡æ¡£éµå¾ª CC BY-SA 4.0 è®¸å¯åè®®ã€‚
