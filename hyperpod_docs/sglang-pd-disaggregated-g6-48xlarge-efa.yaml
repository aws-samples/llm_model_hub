# SGLang v0.5.8 Prefill-Decode Disaggregated Deployment with EFA/RDMA
# Cluster: HyperPod EKS (2x ml.g6.48xlarge)
# Status: TEMPLATE - Requires g6.48xlarge nodes with EFA enabled
#
# Architecture:
#   Client -> Router (sglang-router) -> Prefill Worker -> Mooncake -> Decode Worker
#                                              |                           |
#                                              +---- KV Cache Transfer ----+
#                                                      (RDMA via EFA)
#
# Hardware (per node):
#   - 8x NVIDIA L4 24GB GPUs
#   - 192 vCPUs
#   - 768 GB Memory
#   - 4x EFA network interfaces (100 Gbps)
#   - Nitro v4 with RDMA Read/Write support
#
# Components:
#   1. Prefill Worker: Handles prompt processing, generates KV cache (8x L4, TP=8)
#   2. Decode Worker: Handles token generation using transferred KV cache (8x L4, TP=8)
#   3. Router (sglang-router): PD-aware load balancer that coordinates prefill and decode
#
# Notes:
#   - EFA enabled with RDMA for high-bandwidth KV cache transfer
#   - Requires EFA device plugin installed (aws-efa-k8s-device-plugin)
#   - Suitable for medium models: Qwen3-30B, Llama-3.1-70B, Mixtral-8x7B
#
# Prerequisites:
#   1. EFA device plugin must be installed:
#      kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-efa-k8s-device-plugin
#   2. Verify EFA resources available:
#      kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.status.allocatable.vpc\.amazonaws\.com/efa}{"\n"}{end}'
#
# Usage:
#   KUBECONFIG=/path/to/kubeconfig kubectl apply -f sglang-pd-disaggregated-g6-48xlarge-efa.yaml
#
# Verify:
#   kubectl get pods -l app=sglang-pd-g6-48x
#   kubectl logs -l role=prefill -f
#
# Test:
#   kubectl port-forward svc/sglang-router-g6-48x-service 8000:8000
#   curl http://localhost:8000/v1/chat/completions -H "Content-Type: application/json" \
#     -d '{"model": "Qwen3-VL-30B-A3B-Instruct", "messages": [{"role": "user", "content": "Hello"}]}'
#
# Cleanup:
#   kubectl delete -f sglang-pd-disaggregated-g6-48xlarge-efa.yaml

---
# Prefill Worker Deployment (g6.48xlarge with EFA)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sglang-prefill-g6-48x
  namespace: default
  labels:
    app: sglang-pd-g6-48x
    role: prefill
spec:
  replicas: 1
  selector:
    matchLabels:
      app: sglang-pd-g6-48x
      role: prefill
  template:
    metadata:
      labels:
        app: sglang-pd-g6-48x
        role: prefill
    spec:
      # hostNetwork: true  # Not needed for TCP transport
      # dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: sglang-prefill
        image: lmsysorg/sglang:v0.5.8
        command:
        - sh
        - -c
        - |
          echo "=========================================="
          echo "Starting SGLang v0.5.8 Prefill Worker"
          echo "Instance: g6.48xlarge with EFA/RDMA"
          echo "=========================================="

          echo "Checking EFA devices..."
          ls -la /dev/infiniband/ 2>/dev/null || echo "No InfiniBand devices found"
          fi_info -p efa 2>/dev/null || echo "fi_info not available"

          echo "Checking model files..."
          ls -la /mnt/s3/ | head -20

          echo "Starting prefill server with TP=8..."
          python3 -m sglang.launch_server \
            --model-path Qwen/Qwen3-VL-30B-A3B-Instruct \
            --served-model-name Qwen3-VL-30B-A3B-Instruct \
            --tp 8 \
            --host 0.0.0.0 \
            --port 30000 \
            --disaggregation-mode prefill \
            --disaggregation-transfer-backend mooncake \
            --disaggregation-bootstrap-port 8998 \
            --trust-remote-code \
            --enable-metrics \
            --mem-fraction-static 0.88 \
            --chunked-prefill-size 4096 \
            --context-length 32768 \
            --log-level info

        env:
        - name: CUDA_VISIBLE_DEVICES
          value: "0,1,2,3,4,5,6,7"
        - name: NCCL_DEBUG
          value: "WARN"
        # Mooncake TCP transport (RDMA not supported on g6.48xlarge)
        - name: MC_GID_INDEX
          value: "0"
        - name: MOONCAKE_TRANSPORT
          value: "tcp"
        # HuggingFace cache (use local writable directory)
        - name: HF_HOME
          value: "/dev/shm/huggingface"
        - name: TRANSFORMERS_CACHE
          value: "/dev/shm/huggingface"

        resources:
          limits:
            nvidia.com/gpu: 8
            # vpc.amazonaws.com/efa: 1  # Disabled - using TCP transport
            cpu: "192"
            memory: "700Gi"
          requests:
            nvidia.com/gpu: 8
            # vpc.amazonaws.com/efa: 1  # Disabled - using TCP transport
            cpu: "96"
            memory: "350Gi"

        ports:
        - name: http
          containerPort: 30000
          protocol: TCP
        - name: bootstrap
          containerPort: 8998
          protocol: TCP
        - name: metrics
          containerPort: 9090
          protocol: TCP

        volumeMounts:
        - name: s3-model
          mountPath: /mnt/s3
        - name: shm
          mountPath: /dev/shm

        livenessProbe:
          httpGet:
            path: /health
            port: 30000
          initialDelaySeconds: 420  # Model loading time
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 10

        readinessProbe:
          httpGet:
            path: /health
            port: 30000
          initialDelaySeconds: 420
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 10

      volumes:
      - name: s3-model
        persistentVolumeClaim:
          claimName: s3-pvc
      - name: shm
        emptyDir:
          medium: Memory
          sizeLimit: 128Gi  # Large shared memory for L4 GPUs

      nodeSelector:
        node.kubernetes.io/instance-type: ml.g6.48xlarge

      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule

      # Anti-affinity: prefill and decode must run on different nodes
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: sglang-pd-g6-48x
                role: decode
            topologyKey: kubernetes.io/hostname

---
# Decode Worker Deployment (g6.48xlarge with EFA)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sglang-decode-g6-48x
  namespace: default
  labels:
    app: sglang-pd-g6-48x
    role: decode
spec:
  replicas: 1
  selector:
    matchLabels:
      app: sglang-pd-g6-48x
      role: decode
  template:
    metadata:
      labels:
        app: sglang-pd-g6-48x
        role: decode
    spec:
      # hostNetwork: true  # Not needed for TCP transport
      # dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: sglang-decode
        image: lmsysorg/sglang:v0.5.8
        command:
        - sh
        - -c
        - |
          echo "=========================================="
          echo "Starting SGLang v0.5.8 Decode Worker"
          echo "Instance: g6.48xlarge with EFA/RDMA"
          echo "=========================================="

          echo "Checking EFA devices..."
          ls -la /dev/infiniband/ 2>/dev/null || echo "No InfiniBand devices found"
          fi_info -p efa 2>/dev/null || echo "fi_info not available"

          echo "Checking model files..."
          ls -la /mnt/s3/ | head -20

          echo "Starting decode server with TP=8..."
          python3 -m sglang.launch_server \
            --model-path Qwen/Qwen3-VL-30B-A3B-Instruct \
            --served-model-name Qwen3-VL-30B-A3B-Instruct \
            --tp 8 \
            --host 0.0.0.0 \
            --port 30001 \
            --disaggregation-mode decode \
            --disaggregation-transfer-backend mooncake \
            --trust-remote-code \
            --enable-metrics \
            --mem-fraction-static 0.88 \
            --max-running-requests 256 \
            --disable-radix-cache \
            --log-level info

        env:
        - name: CUDA_VISIBLE_DEVICES
          value: "0,1,2,3,4,5,6,7"
        - name: NCCL_DEBUG
          value: "WARN"
        # Mooncake TCP transport (RDMA not supported on g6.48xlarge)
        - name: MC_GID_INDEX
          value: "0"
        - name: MOONCAKE_TRANSPORT
          value: "tcp"
        # HuggingFace cache (use local writable directory)
        - name: HF_HOME
          value: "/dev/shm/huggingface"
        - name: TRANSFORMERS_CACHE
          value: "/dev/shm/huggingface"

        resources:
          limits:
            nvidia.com/gpu: 8
            vpc.amazonaws.com/efa: 1
            cpu: "192"
            memory: "700Gi"
          requests:
            nvidia.com/gpu: 8
            # vpc.amazonaws.com/efa: 1  # Disabled - using TCP transport
            cpu: "96"
            memory: "350Gi"

        ports:
        - name: http
          containerPort: 30001
          protocol: TCP
        - name: metrics
          containerPort: 9090
          protocol: TCP

        volumeMounts:
        - name: s3-model
          mountPath: /mnt/s3
        - name: shm
          mountPath: /dev/shm

        livenessProbe:
          httpGet:
            path: /health
            port: 30001
          initialDelaySeconds: 420
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 10

        readinessProbe:
          httpGet:
            path: /health
            port: 30001
          initialDelaySeconds: 420
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 10

      volumes:
      - name: s3-model
        persistentVolumeClaim:
          claimName: s3-pvc
      - name: shm
        emptyDir:
          medium: Memory
          sizeLimit: 128Gi

      nodeSelector:
        node.kubernetes.io/instance-type: ml.g6.48xlarge

      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule

      # Anti-affinity: decode and prefill must run on different nodes
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: sglang-pd-g6-48x
                role: prefill
            topologyKey: kubernetes.io/hostname

---
# Router Deployment (no GPU needed)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sglang-router-g6-48x
  namespace: default
  labels:
    app: sglang-pd-g6-48x
    role: router
spec:
  replicas: 1
  selector:
    matchLabels:
      app: sglang-pd-g6-48x
      role: router
  template:
    metadata:
      labels:
        app: sglang-pd-g6-48x
        role: router
    spec:
      containers:
      - name: sglang-router
        image: lmsysorg/sglang:v0.5.8
        command:
        - sh
        - -c
        - |
          echo "=========================================="
          echo "Starting SGLang v0.5.8 Router"
          echo "=========================================="
          echo "Installing sglang-router package..."
          pip install sglang-router -q

          echo "Waiting for prefill and decode workers to be ready..."
          sleep 90

          echo "Starting router..."
          python3 -m sglang_router.launch_router \
            --host 0.0.0.0 \
            --port 8000 \
            --pd-disaggregation \
            --prefill http://sglang-prefill-g6-48x-service:30000 \
            --decode http://sglang-decode-g6-48x-service:30001

        resources:
          limits:
            cpu: "8"
            memory: "16Gi"
          requests:
            cpu: "4"
            memory: "8Gi"

        ports:
        - name: http
          containerPort: 8000
          protocol: TCP

        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 120
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 5

        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 120
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3

      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule

---
# Prefill Worker Service (internal)
apiVersion: v1
kind: Service
metadata:
  name: sglang-prefill-g6-48x-service
  namespace: default
  labels:
    app: sglang-pd-g6-48x
    role: prefill
spec:
  selector:
    app: sglang-pd-g6-48x
    role: prefill
  ports:
  - name: http
    protocol: TCP
    port: 30000
    targetPort: 30000
  - name: bootstrap
    protocol: TCP
    port: 8998
    targetPort: 8998
  - name: metrics
    protocol: TCP
    port: 9090
    targetPort: 9090
  type: ClusterIP

---
# Decode Worker Service (internal)
apiVersion: v1
kind: Service
metadata:
  name: sglang-decode-g6-48x-service
  namespace: default
  labels:
    app: sglang-pd-g6-48x
    role: decode
spec:
  selector:
    app: sglang-pd-g6-48x
    role: decode
  ports:
  - name: http
    protocol: TCP
    port: 30001
    targetPort: 30001
  - name: metrics
    protocol: TCP
    port: 9090
    targetPort: 9090
  type: ClusterIP

---
# Router Service (main entry point)
apiVersion: v1
kind: Service
metadata:
  name: sglang-router-g6-48x-service
  namespace: default
  labels:
    app: sglang-pd-g6-48x
    role: router
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8000"
spec:
  selector:
    app: sglang-pd-g6-48x
    role: router
  ports:
  - name: http
    protocol: TCP
    port: 8000
    targetPort: 8000
  type: ClusterIP
